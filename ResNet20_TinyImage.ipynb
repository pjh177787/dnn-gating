{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.utils as util\n",
    "\n",
    "import numpy as np\n",
    "import os, time, sys\n",
    "import argparse\n",
    "\n",
    "import utils.pg_utils as q\n",
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data_dir = 'tiny-224/'\n",
    "    num_workers = {'train': 2,'val': 0,'test': 0}\n",
    "    data_transforms = {\n",
    "        'train': transforms.Compose([\n",
    "            transforms.RandomRotation(20),\n",
    "            transforms.RandomHorizontalFlip(0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "        ]),\n",
    "        'val': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "        ]),\n",
    "        'test': transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.4802, 0.4481, 0.3975], [0.2302, 0.2265, 0.2262]),\n",
    "        ])\n",
    "    }\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) \n",
    "                      for x in ['train', 'val', 'test']}\n",
    "    dataloaders = {x: data.DataLoader(image_datasets[x], batch_size=batch_size, \n",
    "                                      shuffle=True, num_workers=num_workers[x], pin_memory=True)\n",
    "                      for x in ['train', 'val', 'test']}\n",
    "    \n",
    "    trainloader = dataloaders['train']\n",
    "    testloader = dataloaders['test']\n",
    "    \n",
    "#     dataset_sizes = [len(trainset), len(testset)]\n",
    "    \n",
    "#     normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "#                                      std=[0.229, 0.224, 0.225])\n",
    "#     transform_train = transforms.Compose([\n",
    "#                     transforms.RandomHorizontalFlip(),\n",
    "#                     transforms.RandomCrop(32, 4),\n",
    "#                     transforms.ToTensor(),\n",
    "#                     normalize\n",
    "#         ])\n",
    "#     transform_test = transforms.Compose([\n",
    "#                     transforms.ToTensor(),\n",
    "#                     normalize\n",
    "#         ])\n",
    "\n",
    "#     # pin_memory=True makes transfering data from host to GPU faster\n",
    "#     trainset = torchvision.datasets.CIFAR10(root='/tmp/cifar10_data', train=True,\n",
    "#                                             download=True, transform=transform_train)\n",
    "#     trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                               shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "#     testset = torchvision.datasets.CIFAR10(root='/tmp/cifar10_data', train=False,\n",
    "#                                            download=True, transform=transform_test)\n",
    "#     testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "#                                              shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "    dataset_sizes = [len(image_datasets['train']), len(image_datasets['test'])]\n",
    "    \n",
    "    return trainloader, testloader, classes, dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "import copy\n",
    "\n",
    "def train_model(trainloader, dataset_sizes, testloader, net, device):\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        print(\"Activate multi GPU support.\")\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    # define the loss function\n",
    "    criterion = (nn.CrossEntropyLoss().cuda() \n",
    "                if torch.cuda.is_available() else nn.CrossEntropyLoss())\n",
    "    # Scale the lr linearly with the batch size. \n",
    "    # Should be 0.1 when batch_size=128\n",
    "    initial_lr = 0.1 * batch_size / 128\n",
    "    # initialize the optimizer\n",
    "    optimizer = optim.SGD(net.parameters(), \n",
    "                          lr=initial_lr, \n",
    "                          momentum=0.9,\n",
    "                          weight_decay=1e-4)\n",
    "    # multiply the lr by 0.1 at 100, 150, and 200 epochs\n",
    "    div = num_epoch // 4\n",
    "    lr_decay_milestones = [div*2, div*3]\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "                        optimizer, \n",
    "                        milestones=lr_decay_milestones, \n",
    "                        gamma=0.1,\n",
    "                        last_epoch=-1)\n",
    "    \n",
    "    # some bookkeeping\n",
    "    since = perf_counter()\n",
    "    liveloss = PlotLosses()\n",
    "    best_acc = 0.0\n",
    "    best = 0\n",
    "    \n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    max_val_acc = 0\n",
    "\n",
    "    for epoch in range(num_epoch): # loop over the dataset multiple times\n",
    "\n",
    "        # set printing functions\n",
    "        batch_time = util.AverageMeter('Time/batch', ':.3f')\n",
    "        losses = util.AverageMeter('Loss', ':6.2f')\n",
    "        top1 = util.AverageMeter('Acc', ':6.2f')\n",
    "        progress = util.ProgressMeter(\n",
    "                        len(trainloader),\n",
    "                        [losses, top1, batch_time],\n",
    "                        prefix=\"Epoch: [{}]\".format(epoch+1)\n",
    "                        )\n",
    "\n",
    "        # switch the model to the training mode\n",
    "        net.train()\n",
    "\n",
    "        print('current learning rate = {}'.format(optimizer.param_groups[0]['lr']))\n",
    "        \n",
    "        # each epoch\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        end = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            for name, param in net.named_parameters():\n",
    "                if 'threshold' in name:\n",
    "                    loss += sigma * torch.norm(param-gtarget)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            _, batch_predicted = torch.max(outputs.data, 1)\n",
    "            batch_accu = 100.0 * (batch_predicted == labels).sum().item() / labels.size(0)\n",
    "            losses.update(loss.item(), labels.size(0))\n",
    "            top1.update(batch_accu, labels.size(0))\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(batch_predicted == labels.data)\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 100 == 99:    \n",
    "                # print statistics every 100 mini-batches each epoch\n",
    "                progress.display(i) # i = batch id in the epoch\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_sizes[0]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[0]\n",
    "        loss_list.append(epoch_loss)\n",
    "        accuracy_list.append(epoch_acc)\n",
    "        \n",
    "        # update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # print test accuracy every epochs\n",
    "        print('epoch {}'.format(epoch+1))\n",
    "        val_loss, val_acc = test_accu(testloader, net, device)\n",
    "        val_loss_list.append(epoch_loss)\n",
    "        val_acc_list.append(epoch_acc)\n",
    "        \n",
    "        if epoch_acc > best_acc:\n",
    "            best_acc = epoch_acc\n",
    "            best = epoch + 1\n",
    "            best_model_wts = copy.deepcopy(net.state_dict())\n",
    "\n",
    "        liveloss.update({\n",
    "                'log loss': epoch_loss,\n",
    "                'val_log loss': val_loss,\n",
    "                'accuracy': epoch_acc,\n",
    "                'val_accuracy': val_acc\n",
    "            })     \n",
    "        liveloss.draw()\n",
    "    \n",
    "    # save the model if required\n",
    "    if save:\n",
    "        print(\"Saving the best trained model.\")\n",
    "        util.save_models(best_model_wts, save_folder, suffix=_ARCH)\n",
    "\n",
    "    time_elapsed = perf_counter() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Validation Accuracy: {}, Epoch: {}'.format(best_acc, best))\n",
    "    \n",
    "    return (loss_list, accuracy_list, val_loss_list, val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accu(testloader, net, device):\n",
    "    net.to(device)\n",
    "    cnt_out = np.zeros(9) # this 9 is hardcoded for ResNet-20\n",
    "    cnt_high = np.zeros(9) # this 9 is hardcoded for ResNet-20\n",
    "    num_out = []\n",
    "    num_high = []\n",
    "    def _report_sparsity(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if isinstance(m, q.PGConv2d):\n",
    "            num_out.append(m.num_out)\n",
    "            num_high.append(m.num_high)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    # switch the model to the evaluation mode\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            \n",
    "            criterion = (nn.CrossEntropyLoss().cuda() \n",
    "                if torch.cuda.is_available() else nn.CrossEntropyLoss())\n",
    "            loss = criterion(outputs, labels)\n",
    "            for name, param in net.named_parameters():\n",
    "                if 'threshold' in name:\n",
    "                    loss += sigma * torch.norm(param-gtarget)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            \"\"\" calculate statistics per PG layer \"\"\"\n",
    "            if pg:\n",
    "                net.apply(_report_sparsity)\n",
    "                cnt_out += np.array(num_out)\n",
    "                cnt_high += np.array(num_high)\n",
    "                num_out = []\n",
    "                num_high = []\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %.1f %%' % (\n",
    "        100 * correct / total))\n",
    "    if pg:\n",
    "        print('Sparsity of the update phase: %.1f %%' % (100-np.sum(cnt_high)*1.0/np.sum(cnt_out)*100))\n",
    "    \n",
    "    val_loss = running_loss / total\n",
    "    val_acc = correct / total\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_test_accu(testloader, classes, net, device):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %.1f %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save at /home/aperture/Git/dnn-gating/save_CIFAR10_model\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epoch = 200\n",
    "_LAST_EPOCH = -1 #last_epoch arg is useful for restart\n",
    "_WEIGHT_DECAY = 1e-4\n",
    "_ARCH = \"resnet-20\"\n",
    "this_file_path = os.path.abspath('./')\n",
    "save_folder = os.path.join(this_file_path, 'save_CIFAR10_model')\n",
    "print('Save at', save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(model_arch, num_classes):\n",
    "    if model_arch == 'resnet-20':\n",
    "        if pg:\n",
    "            import model.pg_cifar10_resnet_s as m\n",
    "            kwargs = {'wbits':wbits, 'abits':abits, \\\n",
    "                      'pred_bits':pbits, 'sparse_bp':sparse_bp, \\\n",
    "                      'pact':pact}\n",
    "            return m.resnet20(num_classes, **kwargs)\n",
    "        else:\n",
    "            import model.quantized_cifar10_resnet as m\n",
    "            kwargs = {'wbits':wbits, 'abits':abits, 'pact':pact}\n",
    "            return m.resnet20(num_classes, **kwargs)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Model architecture is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = None\n",
    "save = True\n",
    "test = False\n",
    "wbits = 8\n",
    "abits = 3\n",
    "pact = True\n",
    "pbits = 2\n",
    "gtarget = 1\n",
    "sparse_bp = True\n",
    "pg = True\n",
    "sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n",
      "Create resnet-20 model.\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): QuantizedConv2d(\n",
      "          16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (quantize_w): TorchQuantize(\n",
      "            (quantize): TorchRoundToBits()\n",
      "          )\n",
      "          (quantize_a): TorchQuantize(\n",
      "            (quantize): TorchRoundToBits()\n",
      "          )\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): QuantizedConv2d(\n",
      "          32, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (quantize_w): TorchQuantize(\n",
      "            (quantize): TorchRoundToBits()\n",
      "          )\n",
      "          (quantize_a): TorchQuantize(\n",
      "            (quantize): TorchRoundToBits()\n",
      "          )\n",
      "        )\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        128, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential(\n",
      "        (0): QuantizedConv2d(\n",
      "          128, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (quantize_w): TorchQuantize(\n",
      "            (quantize): TorchRoundToBits()\n",
      "          )\n",
      "          (quantize_a): TorchQuantize(\n",
      "            (quantize): TorchRoundToBits()\n",
      "          )\n",
      "        )\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): PGConv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (trunc_a): TorchTruncate()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): QuantizedConv2d(\n",
      "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (quantize_w): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "        (quantize_a): TorchQuantize(\n",
      "          (quantize): TorchRoundToBits()\n",
      "        )\n",
      "      )\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): PactReLU()\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=512, out_features=200, bias=True)\n",
      "  (relu): PactReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Available GPUs: {}\".format(torch.cuda.device_count()))\n",
    "\n",
    "print(\"Create {} model.\".format(_ARCH))\n",
    "net = generate_model(_ARCH, num_classes=200)\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data.\n",
      "Dataset sizes: [100000, 5000]\n",
      "Start training.\n",
      "current learning rate = 0.025\n"
     ]
    }
   ],
   "source": [
    "if path:\n",
    "    print(\"@ Load trained model from {}.\".format(path))\n",
    "    net.load_state_dict(torch.load(path))\n",
    "\n",
    "print(\"Loading the data.\")\n",
    "trainloader, testloader, classes, dataset_sizes = load_data()\n",
    "print(\"Dataset sizes:\", dataset_sizes)\n",
    "if test:\n",
    "    print(\"Mode: Test only.\")\n",
    "    test_accu(testloader, net, device)\n",
    "else:\n",
    "    print(\"Start training.\")\n",
    "    train_model(trainloader, dataset_sizes, testloader, net, device)\n",
    "    test_accu(testloader, net, device)\n",
    "#     per_class_test_accu(testloader, classes, net, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
