{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.utils as util\n",
    "\n",
    "import numpy as np\n",
    "import os, time, sys\n",
    "import argparse\n",
    "\n",
    "import utils.pg_utils as q\n",
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10():\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    transform_train = transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomCrop(32, 4),\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "        ])\n",
    "    transform_test = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    normalize\n",
    "        ])\n",
    "\n",
    "    # pin_memory=True makes transfering data from host to GPU faster\n",
    "    trainset = torchvision.datasets.CIFAR10(root='/tmp/cifar10_data', train=True,\n",
    "                                            download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                              shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root='/tmp/cifar10_data', train=False,\n",
    "                                           download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                             shuffle=True, num_workers=2, pin_memory=True)\n",
    "\n",
    "    classes = ('plane', 'car', 'bird', 'cat',\n",
    "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "    return trainloader, testloader, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(model_arch):\n",
    "    if model_arch == 'resnet-20':\n",
    "        if pg:\n",
    "            import model.pg_cifar10_resnet as m\n",
    "            kwargs = {'wbits':wbits, 'abits':abits, \\\n",
    "                      'pred_bits':pbits, 'sparse_bp':sparse_bp, \\\n",
    "                      'pact':pact}\n",
    "            return m.resnet20(**kwargs)\n",
    "        else:\n",
    "            import model.quantized_cifar10_resnet as m\n",
    "            kwargs = {'wbits':wbits, 'abits':abits, 'pact':pact}\n",
    "            return m.resnet20(**kwargs)\n",
    "    else:\n",
    "        raise NotImplementedError(\"Model architecture is not supported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "def train_model(trainloader, testloader, net, device):\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "        print(\"Activate multi GPU support.\")\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    # define the loss function\n",
    "    criterion = (nn.CrossEntropyLoss().cuda() \n",
    "                if torch.cuda.is_available() else nn.CrossEntropyLoss())\n",
    "    # Scale the lr linearly with the batch size. \n",
    "    # Should be 0.1 when batch_size=128\n",
    "    initial_lr = 0.1 * batch_size / 128\n",
    "    # initialize the optimizer\n",
    "    optimizer = optim.SGD(net.parameters(), \n",
    "                          lr=initial_lr, \n",
    "                          momentum=0.9,\n",
    "                          weight_decay=_WEIGHT_DECAY)\n",
    "    # multiply the lr by 0.1 at 100, 150, and 200 epochs\n",
    "    div = num_epoch // 4\n",
    "    lr_decay_milestones = [div*2, div*3]\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(\n",
    "                        optimizer, \n",
    "                        milestones=lr_decay_milestones, \n",
    "                        gamma=0.1,\n",
    "                        last_epoch=_LAST_EPOCH)\n",
    "    \n",
    "    # some bookkeeping\n",
    "    since = perf_counter()\n",
    "    liveloss = PlotLosses()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best = 0\n",
    "    \n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    max_val_acc = 0\n",
    "\n",
    "    for epoch in range(num_epoch): # loop over the dataset multiple times\n",
    "\n",
    "        # set printing functions\n",
    "        batch_time = util.AverageMeter('Time/batch', ':.3f')\n",
    "        losses = util.AverageMeter('Loss', ':6.2f')\n",
    "        top1 = util.AverageMeter('Acc', ':6.2f')\n",
    "        progress = util.ProgressMeter(\n",
    "                        len(trainloader),\n",
    "                        [losses, top1, batch_time],\n",
    "                        prefix=\"Epoch: [{}]\".format(epoch+1)\n",
    "                        )\n",
    "\n",
    "        # switch the model to the training mode\n",
    "        net.train()\n",
    "\n",
    "        print('current learning rate = {}'.format(optimizer.param_groups[0]['lr']))\n",
    "        \n",
    "        # each epoch\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        \n",
    "        end = time.time()\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            for name, param in net.named_parameters():\n",
    "                if 'threshold' in name:\n",
    "                    loss += sigma * torch.norm(param-gtarget)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            _, batch_predicted = torch.max(outputs.data, 1)\n",
    "            batch_accu = 100.0 * (batch_predicted == labels).sum().item() / labels.size(0)\n",
    "            losses.update(loss.item(), labels.size(0))\n",
    "            top1.update(batch_accu, labels.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 50 == 49:    \n",
    "                # print statistics every 100 mini-batches each epoch\n",
    "                progress.display(i) # i = batch id in the epoch\n",
    "\n",
    "        # update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        # print test accuracy every few epochs\n",
    "        if epoch % 10 == 9:\n",
    "            print('epoch {}'.format(epoch+1))\n",
    "            test_accu(testloader, net, device)\n",
    "\n",
    "    # save the model if required\n",
    "    if save:\n",
    "        print(\"Saving the trained model.\")\n",
    "        util.save_models(net.state_dict(), save_folder, suffix=_ARCH)\n",
    "\n",
    "    time_elapsed = perf_counter() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Validation Accuracy: {}, Epoch: {}'.format(best_acc, best))\n",
    "    return (loss_list, accuracy_list, val_loss_list, val_acc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accu(testloader, net, device):\n",
    "    net.to(device)\n",
    "    cnt_out = np.zeros(9) # this 9 is hardcoded for ResNet-20\n",
    "    cnt_high = np.zeros(9) # this 9 is hardcoded for ResNet-20\n",
    "    num_out = []\n",
    "    num_high = []\n",
    "    def _report_sparsity(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if isinstance(m, q.PGConv2d):\n",
    "            num_out.append(m.num_out)\n",
    "            num_high.append(m.num_high)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # switch the model to the evaluation mode\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            \"\"\" calculate statistics per PG layer \"\"\"\n",
    "            if pg:\n",
    "                net.apply(_report_sparsity)\n",
    "                cnt_out += np.array(num_out)\n",
    "                cnt_high += np.array(num_high)\n",
    "                num_out = []\n",
    "                num_high = []\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %.1f %%' % (\n",
    "        100 * correct / total))\n",
    "    if pg:\n",
    "        print('Sparsity of the update phase: %.1f %%' % (100-np.sum(cnt_high)*1.0/np.sum(cnt_out)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_test_accu(testloader, classes, net, device):\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(4):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %.1f %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save at /home/aperture/Git/save_CIFAR10_model\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_epoch = 200\n",
    "_LAST_EPOCH = -1 #last_epoch arg is useful for restart\n",
    "_WEIGHT_DECAY = 1e-4\n",
    "_ARCH = \"resnet-20\"\n",
    "this_file_path = os.path.dirname(os.path.abspath('.'))\n",
    "save_folder = os.path.join(this_file_path, 'save_CIFAR10_model')\n",
    "print('Save at', save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = None\n",
    "save = True\n",
    "test = False\n",
    "wbits = 8\n",
    "abits = 3\n",
    "pact = True\n",
    "pbits = 2\n",
    "gtarget = 1\n",
    "sparse_bp = True\n",
    "pg = True\n",
    "sigma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: 1\n",
      "Create resnet-20 model.\n",
      "Loading the data.\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Start training.\n",
      "current learning rate = 0.025\n",
      "Epoch: [1][  49/1563]\tLoss   2.56\tAcc  15.62\tTime/batch 0.060\n",
      "Epoch: [1][  99/1563]\tLoss   2.36\tAcc  19.78\tTime/batch 0.057\n",
      "Epoch: [1][ 149/1563]\tLoss   2.24\tAcc  22.50\tTime/batch 0.057\n",
      "Epoch: [1][ 199/1563]\tLoss   2.16\tAcc  24.72\tTime/batch 0.057\n",
      "Epoch: [1][ 249/1563]\tLoss   2.10\tAcc  26.26\tTime/batch 0.056\n",
      "Epoch: [1][ 299/1563]\tLoss   2.05\tAcc  27.35\tTime/batch 0.056\n",
      "Epoch: [1][ 349/1563]\tLoss   2.02\tAcc  28.48\tTime/batch 0.056\n",
      "Epoch: [1][ 399/1563]\tLoss   1.99\tAcc  29.49\tTime/batch 0.056\n",
      "Epoch: [1][ 449/1563]\tLoss   1.96\tAcc  30.34\tTime/batch 0.056\n",
      "Epoch: [1][ 499/1563]\tLoss   1.93\tAcc  31.21\tTime/batch 0.056\n",
      "Epoch: [1][ 549/1563]\tLoss   1.91\tAcc  31.82\tTime/batch 0.056\n",
      "Epoch: [1][ 599/1563]\tLoss   1.89\tAcc  32.69\tTime/batch 0.056\n",
      "Epoch: [1][ 649/1563]\tLoss   1.86\tAcc  33.60\tTime/batch 0.056\n",
      "Epoch: [1][ 699/1563]\tLoss   1.84\tAcc  34.29\tTime/batch 0.056\n",
      "Epoch: [1][ 749/1563]\tLoss   1.82\tAcc  35.06\tTime/batch 0.056\n",
      "Epoch: [1][ 799/1563]\tLoss   1.80\tAcc  35.80\tTime/batch 0.056\n",
      "Epoch: [1][ 849/1563]\tLoss   1.79\tAcc  36.57\tTime/batch 0.056\n",
      "Epoch: [1][ 899/1563]\tLoss   1.77\tAcc  37.08\tTime/batch 0.056\n",
      "Epoch: [1][ 949/1563]\tLoss   1.75\tAcc  37.73\tTime/batch 0.056\n",
      "Epoch: [1][ 999/1563]\tLoss   1.74\tAcc  38.42\tTime/batch 0.056\n",
      "Epoch: [1][1049/1563]\tLoss   1.72\tAcc  38.97\tTime/batch 0.056\n",
      "Epoch: [1][1099/1563]\tLoss   1.71\tAcc  39.52\tTime/batch 0.056\n",
      "Epoch: [1][1149/1563]\tLoss   1.69\tAcc  40.11\tTime/batch 0.056\n",
      "Epoch: [1][1199/1563]\tLoss   1.68\tAcc  40.53\tTime/batch 0.056\n",
      "Epoch: [1][1249/1563]\tLoss   1.67\tAcc  40.92\tTime/batch 0.056\n",
      "Epoch: [1][1299/1563]\tLoss   1.66\tAcc  41.35\tTime/batch 0.056\n",
      "Epoch: [1][1349/1563]\tLoss   1.65\tAcc  41.81\tTime/batch 0.056\n",
      "Epoch: [1][1399/1563]\tLoss   1.64\tAcc  42.11\tTime/batch 0.056\n",
      "Epoch: [1][1449/1563]\tLoss   1.63\tAcc  42.47\tTime/batch 0.056\n",
      "Epoch: [1][1499/1563]\tLoss   1.62\tAcc  42.92\tTime/batch 0.056\n",
      "Epoch: [1][1549/1563]\tLoss   1.60\tAcc  43.35\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [2][  49/1563]\tLoss   1.21\tAcc  58.94\tTime/batch 0.057\n",
      "Epoch: [2][  99/1563]\tLoss   1.23\tAcc  58.41\tTime/batch 0.057\n",
      "Epoch: [2][ 149/1563]\tLoss   1.23\tAcc  57.98\tTime/batch 0.057\n",
      "Epoch: [2][ 199/1563]\tLoss   1.23\tAcc  58.12\tTime/batch 0.057\n",
      "Epoch: [2][ 249/1563]\tLoss   1.22\tAcc  58.23\tTime/batch 0.057\n",
      "Epoch: [2][ 299/1563]\tLoss   1.22\tAcc  58.28\tTime/batch 0.057\n",
      "Epoch: [2][ 349/1563]\tLoss   1.22\tAcc  58.57\tTime/batch 0.057\n",
      "Epoch: [2][ 399/1563]\tLoss   1.22\tAcc  58.63\tTime/batch 0.057\n",
      "Epoch: [2][ 449/1563]\tLoss   1.21\tAcc  58.85\tTime/batch 0.057\n",
      "Epoch: [2][ 499/1563]\tLoss   1.20\tAcc  59.14\tTime/batch 0.057\n",
      "Epoch: [2][ 549/1563]\tLoss   1.19\tAcc  59.34\tTime/batch 0.057\n",
      "Epoch: [2][ 599/1563]\tLoss   1.19\tAcc  59.57\tTime/batch 0.057\n",
      "Epoch: [2][ 649/1563]\tLoss   1.19\tAcc  59.67\tTime/batch 0.057\n",
      "Epoch: [2][ 699/1563]\tLoss   1.18\tAcc  59.83\tTime/batch 0.057\n",
      "Epoch: [2][ 749/1563]\tLoss   1.17\tAcc  60.17\tTime/batch 0.057\n",
      "Epoch: [2][ 799/1563]\tLoss   1.17\tAcc  60.16\tTime/batch 0.057\n",
      "Epoch: [2][ 849/1563]\tLoss   1.17\tAcc  60.30\tTime/batch 0.057\n",
      "Epoch: [2][ 899/1563]\tLoss   1.16\tAcc  60.38\tTime/batch 0.057\n",
      "Epoch: [2][ 949/1563]\tLoss   1.16\tAcc  60.49\tTime/batch 0.057\n",
      "Epoch: [2][ 999/1563]\tLoss   1.16\tAcc  60.66\tTime/batch 0.057\n",
      "Epoch: [2][1049/1563]\tLoss   1.15\tAcc  60.74\tTime/batch 0.057\n",
      "Epoch: [2][1099/1563]\tLoss   1.15\tAcc  60.89\tTime/batch 0.057\n",
      "Epoch: [2][1149/1563]\tLoss   1.14\tAcc  61.08\tTime/batch 0.057\n",
      "Epoch: [2][1199/1563]\tLoss   1.14\tAcc  61.18\tTime/batch 0.057\n",
      "Epoch: [2][1249/1563]\tLoss   1.14\tAcc  61.34\tTime/batch 0.057\n",
      "Epoch: [2][1299/1563]\tLoss   1.13\tAcc  61.48\tTime/batch 0.057\n",
      "Epoch: [2][1349/1563]\tLoss   1.12\tAcc  61.75\tTime/batch 0.057\n",
      "Epoch: [2][1399/1563]\tLoss   1.12\tAcc  61.92\tTime/batch 0.057\n",
      "Epoch: [2][1449/1563]\tLoss   1.12\tAcc  62.06\tTime/batch 0.057\n",
      "Epoch: [2][1499/1563]\tLoss   1.11\tAcc  62.25\tTime/batch 0.057\n",
      "Epoch: [2][1549/1563]\tLoss   1.11\tAcc  62.36\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [3][  49/1563]\tLoss   0.96\tAcc  66.12\tTime/batch 0.058\n",
      "Epoch: [3][  99/1563]\tLoss   0.96\tAcc  66.56\tTime/batch 0.057\n",
      "Epoch: [3][ 149/1563]\tLoss   0.96\tAcc  66.65\tTime/batch 0.057\n",
      "Epoch: [3][ 199/1563]\tLoss   0.95\tAcc  67.11\tTime/batch 0.057\n",
      "Epoch: [3][ 249/1563]\tLoss   0.95\tAcc  67.35\tTime/batch 0.057\n",
      "Epoch: [3][ 299/1563]\tLoss   0.96\tAcc  67.33\tTime/batch 0.057\n",
      "Epoch: [3][ 349/1563]\tLoss   0.96\tAcc  67.22\tTime/batch 0.057\n",
      "Epoch: [3][ 399/1563]\tLoss   0.96\tAcc  67.40\tTime/batch 0.057\n",
      "Epoch: [3][ 449/1563]\tLoss   0.95\tAcc  67.63\tTime/batch 0.057\n",
      "Epoch: [3][ 499/1563]\tLoss   0.95\tAcc  67.85\tTime/batch 0.057\n",
      "Epoch: [3][ 549/1563]\tLoss   0.95\tAcc  67.95\tTime/batch 0.057\n",
      "Epoch: [3][ 599/1563]\tLoss   0.94\tAcc  68.21\tTime/batch 0.057\n",
      "Epoch: [3][ 649/1563]\tLoss   0.94\tAcc  68.40\tTime/batch 0.057\n",
      "Epoch: [3][ 699/1563]\tLoss   0.94\tAcc  68.54\tTime/batch 0.057\n",
      "Epoch: [3][ 749/1563]\tLoss   0.93\tAcc  68.68\tTime/batch 0.057\n",
      "Epoch: [3][ 799/1563]\tLoss   0.93\tAcc  68.82\tTime/batch 0.057\n",
      "Epoch: [3][ 849/1563]\tLoss   0.93\tAcc  68.88\tTime/batch 0.057\n",
      "Epoch: [3][ 899/1563]\tLoss   0.93\tAcc  68.94\tTime/batch 0.057\n",
      "Epoch: [3][ 949/1563]\tLoss   0.92\tAcc  69.04\tTime/batch 0.057\n",
      "Epoch: [3][ 999/1563]\tLoss   0.92\tAcc  69.04\tTime/batch 0.057\n",
      "Epoch: [3][1049/1563]\tLoss   0.92\tAcc  69.08\tTime/batch 0.057\n",
      "Epoch: [3][1099/1563]\tLoss   0.92\tAcc  69.24\tTime/batch 0.057\n",
      "Epoch: [3][1149/1563]\tLoss   0.92\tAcc  69.25\tTime/batch 0.057\n",
      "Epoch: [3][1199/1563]\tLoss   0.92\tAcc  69.40\tTime/batch 0.057\n",
      "Epoch: [3][1249/1563]\tLoss   0.91\tAcc  69.49\tTime/batch 0.057\n",
      "Epoch: [3][1299/1563]\tLoss   0.91\tAcc  69.56\tTime/batch 0.057\n",
      "Epoch: [3][1349/1563]\tLoss   0.91\tAcc  69.63\tTime/batch 0.057\n",
      "Epoch: [3][1399/1563]\tLoss   0.91\tAcc  69.72\tTime/batch 0.057\n",
      "Epoch: [3][1449/1563]\tLoss   0.90\tAcc  69.78\tTime/batch 0.057\n",
      "Epoch: [3][1499/1563]\tLoss   0.90\tAcc  69.87\tTime/batch 0.057\n",
      "Epoch: [3][1549/1563]\tLoss   0.90\tAcc  69.90\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [4][  49/1563]\tLoss   0.79\tAcc  73.88\tTime/batch 0.057\n",
      "Epoch: [4][  99/1563]\tLoss   0.77\tAcc  74.78\tTime/batch 0.057\n",
      "Epoch: [4][ 149/1563]\tLoss   0.79\tAcc  74.04\tTime/batch 0.057\n",
      "Epoch: [4][ 199/1563]\tLoss   0.79\tAcc  74.30\tTime/batch 0.057\n",
      "Epoch: [4][ 249/1563]\tLoss   0.79\tAcc  74.16\tTime/batch 0.057\n",
      "Epoch: [4][ 299/1563]\tLoss   0.79\tAcc  74.09\tTime/batch 0.056\n",
      "Epoch: [4][ 349/1563]\tLoss   0.79\tAcc  74.12\tTime/batch 0.056\n",
      "Epoch: [4][ 399/1563]\tLoss   0.80\tAcc  73.96\tTime/batch 0.056\n",
      "Epoch: [4][ 449/1563]\tLoss   0.80\tAcc  73.99\tTime/batch 0.056\n",
      "Epoch: [4][ 499/1563]\tLoss   0.80\tAcc  73.96\tTime/batch 0.056\n",
      "Epoch: [4][ 549/1563]\tLoss   0.80\tAcc  73.89\tTime/batch 0.056\n",
      "Epoch: [4][ 599/1563]\tLoss   0.80\tAcc  73.74\tTime/batch 0.057\n",
      "Epoch: [4][ 649/1563]\tLoss   0.80\tAcc  73.75\tTime/batch 0.057\n",
      "Epoch: [4][ 699/1563]\tLoss   0.80\tAcc  73.82\tTime/batch 0.057\n",
      "Epoch: [4][ 749/1563]\tLoss   0.80\tAcc  73.87\tTime/batch 0.057\n",
      "Epoch: [4][ 799/1563]\tLoss   0.80\tAcc  73.74\tTime/batch 0.057\n",
      "Epoch: [4][ 849/1563]\tLoss   0.80\tAcc  73.80\tTime/batch 0.057\n",
      "Epoch: [4][ 899/1563]\tLoss   0.80\tAcc  73.81\tTime/batch 0.057\n",
      "Epoch: [4][ 949/1563]\tLoss   0.80\tAcc  73.74\tTime/batch 0.057\n",
      "Epoch: [4][ 999/1563]\tLoss   0.80\tAcc  73.70\tTime/batch 0.057\n",
      "Epoch: [4][1049/1563]\tLoss   0.80\tAcc  73.76\tTime/batch 0.057\n",
      "Epoch: [4][1099/1563]\tLoss   0.80\tAcc  73.83\tTime/batch 0.057\n",
      "Epoch: [4][1149/1563]\tLoss   0.79\tAcc  73.90\tTime/batch 0.057\n",
      "Epoch: [4][1199/1563]\tLoss   0.80\tAcc  73.89\tTime/batch 0.057\n",
      "Epoch: [4][1249/1563]\tLoss   0.79\tAcc  73.93\tTime/batch 0.057\n",
      "Epoch: [4][1299/1563]\tLoss   0.79\tAcc  73.97\tTime/batch 0.057\n",
      "Epoch: [4][1349/1563]\tLoss   0.79\tAcc  74.02\tTime/batch 0.057\n",
      "Epoch: [4][1399/1563]\tLoss   0.79\tAcc  74.01\tTime/batch 0.057\n",
      "Epoch: [4][1449/1563]\tLoss   0.79\tAcc  74.03\tTime/batch 0.057\n",
      "Epoch: [4][1499/1563]\tLoss   0.79\tAcc  74.08\tTime/batch 0.057\n",
      "Epoch: [4][1549/1563]\tLoss   0.79\tAcc  74.11\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [5][  49/1563]\tLoss   0.77\tAcc  74.94\tTime/batch 0.057\n",
      "Epoch: [5][  99/1563]\tLoss   0.76\tAcc  74.75\tTime/batch 0.057\n",
      "Epoch: [5][ 149/1563]\tLoss   0.75\tAcc  75.19\tTime/batch 0.056\n",
      "Epoch: [5][ 199/1563]\tLoss   0.75\tAcc  75.16\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5][ 249/1563]\tLoss   0.75\tAcc  75.33\tTime/batch 0.056\n",
      "Epoch: [5][ 299/1563]\tLoss   0.74\tAcc  75.92\tTime/batch 0.056\n",
      "Epoch: [5][ 349/1563]\tLoss   0.74\tAcc  75.84\tTime/batch 0.056\n",
      "Epoch: [5][ 399/1563]\tLoss   0.73\tAcc  76.03\tTime/batch 0.056\n",
      "Epoch: [5][ 449/1563]\tLoss   0.74\tAcc  75.97\tTime/batch 0.056\n",
      "Epoch: [5][ 499/1563]\tLoss   0.74\tAcc  75.96\tTime/batch 0.056\n",
      "Epoch: [5][ 549/1563]\tLoss   0.73\tAcc  75.98\tTime/batch 0.056\n",
      "Epoch: [5][ 599/1563]\tLoss   0.74\tAcc  75.98\tTime/batch 0.056\n",
      "Epoch: [5][ 649/1563]\tLoss   0.74\tAcc  75.88\tTime/batch 0.056\n",
      "Epoch: [5][ 699/1563]\tLoss   0.74\tAcc  75.97\tTime/batch 0.056\n",
      "Epoch: [5][ 749/1563]\tLoss   0.74\tAcc  75.96\tTime/batch 0.056\n",
      "Epoch: [5][ 799/1563]\tLoss   0.73\tAcc  76.05\tTime/batch 0.056\n",
      "Epoch: [5][ 849/1563]\tLoss   0.73\tAcc  76.10\tTime/batch 0.056\n",
      "Epoch: [5][ 899/1563]\tLoss   0.73\tAcc  76.12\tTime/batch 0.056\n",
      "Epoch: [5][ 949/1563]\tLoss   0.73\tAcc  76.21\tTime/batch 0.056\n",
      "Epoch: [5][ 999/1563]\tLoss   0.73\tAcc  76.21\tTime/batch 0.056\n",
      "Epoch: [5][1049/1563]\tLoss   0.73\tAcc  76.24\tTime/batch 0.056\n",
      "Epoch: [5][1099/1563]\tLoss   0.72\tAcc  76.28\tTime/batch 0.056\n",
      "Epoch: [5][1149/1563]\tLoss   0.72\tAcc  76.34\tTime/batch 0.056\n",
      "Epoch: [5][1199/1563]\tLoss   0.72\tAcc  76.40\tTime/batch 0.056\n",
      "Epoch: [5][1249/1563]\tLoss   0.72\tAcc  76.43\tTime/batch 0.056\n",
      "Epoch: [5][1299/1563]\tLoss   0.72\tAcc  76.43\tTime/batch 0.056\n",
      "Epoch: [5][1349/1563]\tLoss   0.72\tAcc  76.44\tTime/batch 0.056\n",
      "Epoch: [5][1399/1563]\tLoss   0.72\tAcc  76.43\tTime/batch 0.056\n",
      "Epoch: [5][1449/1563]\tLoss   0.72\tAcc  76.47\tTime/batch 0.056\n",
      "Epoch: [5][1499/1563]\tLoss   0.72\tAcc  76.49\tTime/batch 0.056\n",
      "Epoch: [5][1549/1563]\tLoss   0.72\tAcc  76.46\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [6][  49/1563]\tLoss   0.69\tAcc  75.75\tTime/batch 0.057\n",
      "Epoch: [6][  99/1563]\tLoss   0.67\tAcc  77.16\tTime/batch 0.057\n",
      "Epoch: [6][ 149/1563]\tLoss   0.66\tAcc  78.17\tTime/batch 0.057\n",
      "Epoch: [6][ 199/1563]\tLoss   0.67\tAcc  77.86\tTime/batch 0.056\n",
      "Epoch: [6][ 249/1563]\tLoss   0.68\tAcc  77.60\tTime/batch 0.056\n",
      "Epoch: [6][ 299/1563]\tLoss   0.68\tAcc  77.70\tTime/batch 0.056\n",
      "Epoch: [6][ 349/1563]\tLoss   0.67\tAcc  77.89\tTime/batch 0.056\n",
      "Epoch: [6][ 399/1563]\tLoss   0.67\tAcc  77.97\tTime/batch 0.056\n",
      "Epoch: [6][ 449/1563]\tLoss   0.67\tAcc  77.90\tTime/batch 0.056\n",
      "Epoch: [6][ 499/1563]\tLoss   0.67\tAcc  77.78\tTime/batch 0.056\n",
      "Epoch: [6][ 549/1563]\tLoss   0.67\tAcc  77.73\tTime/batch 0.056\n",
      "Epoch: [6][ 599/1563]\tLoss   0.67\tAcc  77.90\tTime/batch 0.056\n",
      "Epoch: [6][ 649/1563]\tLoss   0.67\tAcc  77.99\tTime/batch 0.056\n",
      "Epoch: [6][ 699/1563]\tLoss   0.67\tAcc  77.83\tTime/batch 0.056\n",
      "Epoch: [6][ 749/1563]\tLoss   0.67\tAcc  77.88\tTime/batch 0.056\n",
      "Epoch: [6][ 799/1563]\tLoss   0.67\tAcc  77.86\tTime/batch 0.056\n",
      "Epoch: [6][ 849/1563]\tLoss   0.67\tAcc  77.94\tTime/batch 0.056\n",
      "Epoch: [6][ 899/1563]\tLoss   0.67\tAcc  77.96\tTime/batch 0.056\n",
      "Epoch: [6][ 949/1563]\tLoss   0.67\tAcc  78.04\tTime/batch 0.056\n",
      "Epoch: [6][ 999/1563]\tLoss   0.67\tAcc  78.03\tTime/batch 0.056\n",
      "Epoch: [6][1049/1563]\tLoss   0.67\tAcc  78.03\tTime/batch 0.056\n",
      "Epoch: [6][1099/1563]\tLoss   0.67\tAcc  78.07\tTime/batch 0.056\n",
      "Epoch: [6][1149/1563]\tLoss   0.67\tAcc  78.07\tTime/batch 0.056\n",
      "Epoch: [6][1199/1563]\tLoss   0.67\tAcc  78.13\tTime/batch 0.056\n",
      "Epoch: [6][1249/1563]\tLoss   0.67\tAcc  78.17\tTime/batch 0.056\n",
      "Epoch: [6][1299/1563]\tLoss   0.66\tAcc  78.21\tTime/batch 0.056\n",
      "Epoch: [6][1349/1563]\tLoss   0.67\tAcc  78.14\tTime/batch 0.056\n",
      "Epoch: [6][1399/1563]\tLoss   0.67\tAcc  78.15\tTime/batch 0.056\n",
      "Epoch: [6][1449/1563]\tLoss   0.66\tAcc  78.21\tTime/batch 0.056\n",
      "Epoch: [6][1499/1563]\tLoss   0.67\tAcc  78.16\tTime/batch 0.056\n",
      "Epoch: [6][1549/1563]\tLoss   0.67\tAcc  78.20\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [7][  49/1563]\tLoss   0.66\tAcc  77.75\tTime/batch 0.058\n",
      "Epoch: [7][  99/1563]\tLoss   0.62\tAcc  79.06\tTime/batch 0.058\n",
      "Epoch: [7][ 149/1563]\tLoss   0.63\tAcc  78.69\tTime/batch 0.057\n",
      "Epoch: [7][ 199/1563]\tLoss   0.64\tAcc  79.00\tTime/batch 0.057\n",
      "Epoch: [7][ 249/1563]\tLoss   0.63\tAcc  79.31\tTime/batch 0.057\n",
      "Epoch: [7][ 299/1563]\tLoss   0.63\tAcc  79.31\tTime/batch 0.057\n",
      "Epoch: [7][ 349/1563]\tLoss   0.63\tAcc  79.42\tTime/batch 0.057\n",
      "Epoch: [7][ 399/1563]\tLoss   0.63\tAcc  79.56\tTime/batch 0.057\n",
      "Epoch: [7][ 449/1563]\tLoss   0.63\tAcc  79.44\tTime/batch 0.057\n",
      "Epoch: [7][ 499/1563]\tLoss   0.63\tAcc  79.34\tTime/batch 0.057\n",
      "Epoch: [7][ 549/1563]\tLoss   0.63\tAcc  79.45\tTime/batch 0.057\n",
      "Epoch: [7][ 599/1563]\tLoss   0.62\tAcc  79.58\tTime/batch 0.057\n",
      "Epoch: [7][ 649/1563]\tLoss   0.62\tAcc  79.56\tTime/batch 0.057\n",
      "Epoch: [7][ 699/1563]\tLoss   0.62\tAcc  79.50\tTime/batch 0.057\n",
      "Epoch: [7][ 749/1563]\tLoss   0.63\tAcc  79.40\tTime/batch 0.057\n",
      "Epoch: [7][ 799/1563]\tLoss   0.63\tAcc  79.33\tTime/batch 0.057\n",
      "Epoch: [7][ 849/1563]\tLoss   0.63\tAcc  79.38\tTime/batch 0.057\n",
      "Epoch: [7][ 899/1563]\tLoss   0.63\tAcc  79.38\tTime/batch 0.057\n",
      "Epoch: [7][ 949/1563]\tLoss   0.62\tAcc  79.50\tTime/batch 0.057\n",
      "Epoch: [7][ 999/1563]\tLoss   0.62\tAcc  79.46\tTime/batch 0.057\n",
      "Epoch: [7][1049/1563]\tLoss   0.62\tAcc  79.50\tTime/batch 0.057\n",
      "Epoch: [7][1099/1563]\tLoss   0.62\tAcc  79.55\tTime/batch 0.057\n",
      "Epoch: [7][1149/1563]\tLoss   0.62\tAcc  79.55\tTime/batch 0.057\n",
      "Epoch: [7][1199/1563]\tLoss   0.62\tAcc  79.53\tTime/batch 0.057\n",
      "Epoch: [7][1249/1563]\tLoss   0.62\tAcc  79.53\tTime/batch 0.057\n",
      "Epoch: [7][1299/1563]\tLoss   0.62\tAcc  79.54\tTime/batch 0.057\n",
      "Epoch: [7][1349/1563]\tLoss   0.62\tAcc  79.55\tTime/batch 0.057\n",
      "Epoch: [7][1399/1563]\tLoss   0.63\tAcc  79.50\tTime/batch 0.057\n",
      "Epoch: [7][1449/1563]\tLoss   0.62\tAcc  79.51\tTime/batch 0.057\n",
      "Epoch: [7][1499/1563]\tLoss   0.63\tAcc  79.49\tTime/batch 0.057\n",
      "Epoch: [7][1549/1563]\tLoss   0.62\tAcc  79.53\tTime/batch 0.058\n",
      "current learning rate = 0.025\n",
      "Epoch: [8][  49/1563]\tLoss   0.54\tAcc  82.81\tTime/batch 0.058\n",
      "Epoch: [8][  99/1563]\tLoss   0.57\tAcc  81.53\tTime/batch 0.058\n",
      "Epoch: [8][ 149/1563]\tLoss   0.59\tAcc  80.88\tTime/batch 0.058\n",
      "Epoch: [8][ 199/1563]\tLoss   0.60\tAcc  80.45\tTime/batch 0.058\n",
      "Epoch: [8][ 249/1563]\tLoss   0.60\tAcc  80.36\tTime/batch 0.058\n",
      "Epoch: [8][ 299/1563]\tLoss   0.60\tAcc  80.44\tTime/batch 0.058\n",
      "Epoch: [8][ 349/1563]\tLoss   0.60\tAcc  80.34\tTime/batch 0.058\n",
      "Epoch: [8][ 399/1563]\tLoss   0.60\tAcc  80.27\tTime/batch 0.058\n",
      "Epoch: [8][ 449/1563]\tLoss   0.60\tAcc  80.22\tTime/batch 0.058\n",
      "Epoch: [8][ 499/1563]\tLoss   0.60\tAcc  80.14\tTime/batch 0.058\n",
      "Epoch: [8][ 549/1563]\tLoss   0.60\tAcc  80.03\tTime/batch 0.058\n",
      "Epoch: [8][ 599/1563]\tLoss   0.60\tAcc  80.02\tTime/batch 0.058\n",
      "Epoch: [8][ 649/1563]\tLoss   0.60\tAcc  80.03\tTime/batch 0.058\n",
      "Epoch: [8][ 699/1563]\tLoss   0.60\tAcc  80.05\tTime/batch 0.058\n",
      "Epoch: [8][ 749/1563]\tLoss   0.60\tAcc  80.06\tTime/batch 0.058\n",
      "Epoch: [8][ 799/1563]\tLoss   0.60\tAcc  80.17\tTime/batch 0.058\n",
      "Epoch: [8][ 849/1563]\tLoss   0.60\tAcc  80.31\tTime/batch 0.058\n",
      "Epoch: [8][ 899/1563]\tLoss   0.60\tAcc  80.23\tTime/batch 0.058\n",
      "Epoch: [8][ 949/1563]\tLoss   0.60\tAcc  80.22\tTime/batch 0.057\n",
      "Epoch: [8][ 999/1563]\tLoss   0.60\tAcc  80.23\tTime/batch 0.057\n",
      "Epoch: [8][1049/1563]\tLoss   0.60\tAcc  80.35\tTime/batch 0.057\n",
      "Epoch: [8][1099/1563]\tLoss   0.60\tAcc  80.38\tTime/batch 0.057\n",
      "Epoch: [8][1149/1563]\tLoss   0.60\tAcc  80.41\tTime/batch 0.057\n",
      "Epoch: [8][1199/1563]\tLoss   0.60\tAcc  80.42\tTime/batch 0.057\n",
      "Epoch: [8][1249/1563]\tLoss   0.60\tAcc  80.41\tTime/batch 0.057\n",
      "Epoch: [8][1299/1563]\tLoss   0.60\tAcc  80.47\tTime/batch 0.057\n",
      "Epoch: [8][1349/1563]\tLoss   0.59\tAcc  80.47\tTime/batch 0.057\n",
      "Epoch: [8][1399/1563]\tLoss   0.60\tAcc  80.42\tTime/batch 0.057\n",
      "Epoch: [8][1449/1563]\tLoss   0.60\tAcc  80.39\tTime/batch 0.057\n",
      "Epoch: [8][1499/1563]\tLoss   0.60\tAcc  80.41\tTime/batch 0.057\n",
      "Epoch: [8][1549/1563]\tLoss   0.60\tAcc  80.48\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [9][  49/1563]\tLoss   0.59\tAcc  80.25\tTime/batch 0.058\n",
      "Epoch: [9][  99/1563]\tLoss   0.57\tAcc  81.44\tTime/batch 0.057\n",
      "Epoch: [9][ 149/1563]\tLoss   0.57\tAcc  81.58\tTime/batch 0.057\n",
      "Epoch: [9][ 199/1563]\tLoss   0.57\tAcc  81.47\tTime/batch 0.057\n",
      "Epoch: [9][ 249/1563]\tLoss   0.57\tAcc  81.42\tTime/batch 0.057\n",
      "Epoch: [9][ 299/1563]\tLoss   0.57\tAcc  81.35\tTime/batch 0.057\n",
      "Epoch: [9][ 349/1563]\tLoss   0.57\tAcc  81.48\tTime/batch 0.057\n",
      "Epoch: [9][ 399/1563]\tLoss   0.57\tAcc  81.52\tTime/batch 0.057\n",
      "Epoch: [9][ 449/1563]\tLoss   0.57\tAcc  81.49\tTime/batch 0.057\n",
      "Epoch: [9][ 499/1563]\tLoss   0.57\tAcc  81.44\tTime/batch 0.057\n",
      "Epoch: [9][ 549/1563]\tLoss   0.57\tAcc  81.43\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9][ 599/1563]\tLoss   0.57\tAcc  81.38\tTime/batch 0.057\n",
      "Epoch: [9][ 649/1563]\tLoss   0.57\tAcc  81.23\tTime/batch 0.057\n",
      "Epoch: [9][ 699/1563]\tLoss   0.57\tAcc  81.13\tTime/batch 0.057\n",
      "Epoch: [9][ 749/1563]\tLoss   0.57\tAcc  81.22\tTime/batch 0.057\n",
      "Epoch: [9][ 799/1563]\tLoss   0.57\tAcc  81.32\tTime/batch 0.057\n",
      "Epoch: [9][ 849/1563]\tLoss   0.57\tAcc  81.26\tTime/batch 0.057\n",
      "Epoch: [9][ 899/1563]\tLoss   0.57\tAcc  81.26\tTime/batch 0.057\n",
      "Epoch: [9][ 949/1563]\tLoss   0.57\tAcc  81.41\tTime/batch 0.057\n",
      "Epoch: [9][ 999/1563]\tLoss   0.57\tAcc  81.43\tTime/batch 0.057\n",
      "Epoch: [9][1049/1563]\tLoss   0.57\tAcc  81.39\tTime/batch 0.057\n",
      "Epoch: [9][1099/1563]\tLoss   0.57\tAcc  81.44\tTime/batch 0.057\n",
      "Epoch: [9][1149/1563]\tLoss   0.57\tAcc  81.43\tTime/batch 0.057\n",
      "Epoch: [9][1199/1563]\tLoss   0.57\tAcc  81.40\tTime/batch 0.057\n",
      "Epoch: [9][1249/1563]\tLoss   0.57\tAcc  81.39\tTime/batch 0.057\n",
      "Epoch: [9][1299/1563]\tLoss   0.57\tAcc  81.36\tTime/batch 0.057\n",
      "Epoch: [9][1349/1563]\tLoss   0.57\tAcc  81.39\tTime/batch 0.057\n",
      "Epoch: [9][1399/1563]\tLoss   0.57\tAcc  81.41\tTime/batch 0.057\n",
      "Epoch: [9][1449/1563]\tLoss   0.57\tAcc  81.38\tTime/batch 0.057\n",
      "Epoch: [9][1499/1563]\tLoss   0.57\tAcc  81.39\tTime/batch 0.057\n",
      "Epoch: [9][1549/1563]\tLoss   0.57\tAcc  81.40\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [10][  49/1563]\tLoss   0.54\tAcc  82.81\tTime/batch 0.057\n",
      "Epoch: [10][  99/1563]\tLoss   0.55\tAcc  82.09\tTime/batch 0.057\n",
      "Epoch: [10][ 149/1563]\tLoss   0.55\tAcc  82.17\tTime/batch 0.057\n",
      "Epoch: [10][ 199/1563]\tLoss   0.55\tAcc  82.28\tTime/batch 0.057\n",
      "Epoch: [10][ 249/1563]\tLoss   0.55\tAcc  82.03\tTime/batch 0.057\n",
      "Epoch: [10][ 299/1563]\tLoss   0.55\tAcc  81.99\tTime/batch 0.057\n",
      "Epoch: [10][ 349/1563]\tLoss   0.55\tAcc  82.04\tTime/batch 0.057\n",
      "Epoch: [10][ 399/1563]\tLoss   0.54\tAcc  82.30\tTime/batch 0.057\n",
      "Epoch: [10][ 449/1563]\tLoss   0.55\tAcc  82.26\tTime/batch 0.057\n",
      "Epoch: [10][ 499/1563]\tLoss   0.55\tAcc  82.21\tTime/batch 0.057\n",
      "Epoch: [10][ 549/1563]\tLoss   0.55\tAcc  82.23\tTime/batch 0.057\n",
      "Epoch: [10][ 599/1563]\tLoss   0.55\tAcc  82.11\tTime/batch 0.057\n",
      "Epoch: [10][ 649/1563]\tLoss   0.55\tAcc  82.12\tTime/batch 0.057\n",
      "Epoch: [10][ 699/1563]\tLoss   0.55\tAcc  82.14\tTime/batch 0.057\n",
      "Epoch: [10][ 749/1563]\tLoss   0.54\tAcc  82.14\tTime/batch 0.057\n",
      "Epoch: [10][ 799/1563]\tLoss   0.54\tAcc  82.17\tTime/batch 0.057\n",
      "Epoch: [10][ 849/1563]\tLoss   0.54\tAcc  82.23\tTime/batch 0.057\n",
      "Epoch: [10][ 899/1563]\tLoss   0.54\tAcc  82.20\tTime/batch 0.057\n",
      "Epoch: [10][ 949/1563]\tLoss   0.54\tAcc  82.12\tTime/batch 0.057\n",
      "Epoch: [10][ 999/1563]\tLoss   0.54\tAcc  82.04\tTime/batch 0.057\n",
      "Epoch: [10][1049/1563]\tLoss   0.54\tAcc  82.04\tTime/batch 0.057\n",
      "Epoch: [10][1099/1563]\tLoss   0.55\tAcc  82.02\tTime/batch 0.057\n",
      "Epoch: [10][1149/1563]\tLoss   0.54\tAcc  82.04\tTime/batch 0.057\n",
      "Epoch: [10][1199/1563]\tLoss   0.55\tAcc  82.03\tTime/batch 0.057\n",
      "Epoch: [10][1249/1563]\tLoss   0.55\tAcc  82.01\tTime/batch 0.057\n",
      "Epoch: [10][1299/1563]\tLoss   0.55\tAcc  82.03\tTime/batch 0.057\n",
      "Epoch: [10][1349/1563]\tLoss   0.55\tAcc  81.99\tTime/batch 0.057\n",
      "Epoch: [10][1399/1563]\tLoss   0.55\tAcc  81.95\tTime/batch 0.057\n",
      "Epoch: [10][1449/1563]\tLoss   0.55\tAcc  81.95\tTime/batch 0.057\n",
      "Epoch: [10][1499/1563]\tLoss   0.55\tAcc  81.96\tTime/batch 0.057\n",
      "Epoch: [10][1549/1563]\tLoss   0.55\tAcc  81.97\tTime/batch 0.057\n",
      "epoch 10\n",
      "Accuracy of the network on the 10000 test images: 81.8 %\n",
      "Sparsity of the update phase: 63.5 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [11][  49/1563]\tLoss   0.48\tAcc  83.81\tTime/batch 0.057\n",
      "Epoch: [11][  99/1563]\tLoss   0.50\tAcc  83.34\tTime/batch 0.057\n",
      "Epoch: [11][ 149/1563]\tLoss   0.50\tAcc  83.81\tTime/batch 0.057\n",
      "Epoch: [11][ 199/1563]\tLoss   0.50\tAcc  83.61\tTime/batch 0.057\n",
      "Epoch: [11][ 249/1563]\tLoss   0.51\tAcc  83.10\tTime/batch 0.057\n",
      "Epoch: [11][ 299/1563]\tLoss   0.51\tAcc  83.04\tTime/batch 0.057\n",
      "Epoch: [11][ 349/1563]\tLoss   0.51\tAcc  83.10\tTime/batch 0.057\n",
      "Epoch: [11][ 399/1563]\tLoss   0.51\tAcc  82.98\tTime/batch 0.057\n",
      "Epoch: [11][ 449/1563]\tLoss   0.51\tAcc  82.82\tTime/batch 0.057\n",
      "Epoch: [11][ 499/1563]\tLoss   0.51\tAcc  82.74\tTime/batch 0.057\n",
      "Epoch: [11][ 549/1563]\tLoss   0.52\tAcc  82.72\tTime/batch 0.057\n",
      "Epoch: [11][ 599/1563]\tLoss   0.52\tAcc  82.71\tTime/batch 0.057\n",
      "Epoch: [11][ 649/1563]\tLoss   0.52\tAcc  82.73\tTime/batch 0.057\n",
      "Epoch: [11][ 699/1563]\tLoss   0.52\tAcc  82.70\tTime/batch 0.057\n",
      "Epoch: [11][ 749/1563]\tLoss   0.52\tAcc  82.72\tTime/batch 0.057\n",
      "Epoch: [11][ 799/1563]\tLoss   0.52\tAcc  82.73\tTime/batch 0.057\n",
      "Epoch: [11][ 849/1563]\tLoss   0.52\tAcc  82.72\tTime/batch 0.057\n",
      "Epoch: [11][ 899/1563]\tLoss   0.52\tAcc  82.79\tTime/batch 0.057\n",
      "Epoch: [11][ 949/1563]\tLoss   0.52\tAcc  82.83\tTime/batch 0.057\n",
      "Epoch: [11][ 999/1563]\tLoss   0.52\tAcc  82.84\tTime/batch 0.057\n",
      "Epoch: [11][1049/1563]\tLoss   0.52\tAcc  82.77\tTime/batch 0.057\n",
      "Epoch: [11][1099/1563]\tLoss   0.52\tAcc  82.69\tTime/batch 0.057\n",
      "Epoch: [11][1149/1563]\tLoss   0.52\tAcc  82.69\tTime/batch 0.057\n",
      "Epoch: [11][1199/1563]\tLoss   0.52\tAcc  82.66\tTime/batch 0.057\n",
      "Epoch: [11][1249/1563]\tLoss   0.52\tAcc  82.64\tTime/batch 0.057\n",
      "Epoch: [11][1299/1563]\tLoss   0.52\tAcc  82.68\tTime/batch 0.057\n",
      "Epoch: [11][1349/1563]\tLoss   0.52\tAcc  82.64\tTime/batch 0.057\n",
      "Epoch: [11][1399/1563]\tLoss   0.52\tAcc  82.66\tTime/batch 0.057\n",
      "Epoch: [11][1449/1563]\tLoss   0.52\tAcc  82.66\tTime/batch 0.057\n",
      "Epoch: [11][1499/1563]\tLoss   0.52\tAcc  82.64\tTime/batch 0.057\n",
      "Epoch: [11][1549/1563]\tLoss   0.52\tAcc  82.57\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [12][  49/1563]\tLoss   0.46\tAcc  83.50\tTime/batch 0.058\n",
      "Epoch: [12][  99/1563]\tLoss   0.48\tAcc  84.12\tTime/batch 0.058\n",
      "Epoch: [12][ 149/1563]\tLoss   0.48\tAcc  83.79\tTime/batch 0.057\n",
      "Epoch: [12][ 199/1563]\tLoss   0.48\tAcc  83.73\tTime/batch 0.057\n",
      "Epoch: [12][ 249/1563]\tLoss   0.50\tAcc  83.38\tTime/batch 0.057\n",
      "Epoch: [12][ 299/1563]\tLoss   0.50\tAcc  83.31\tTime/batch 0.057\n",
      "Epoch: [12][ 349/1563]\tLoss   0.50\tAcc  83.15\tTime/batch 0.057\n",
      "Epoch: [12][ 399/1563]\tLoss   0.51\tAcc  82.87\tTime/batch 0.057\n",
      "Epoch: [12][ 449/1563]\tLoss   0.51\tAcc  83.02\tTime/batch 0.057\n",
      "Epoch: [12][ 499/1563]\tLoss   0.51\tAcc  82.97\tTime/batch 0.057\n",
      "Epoch: [12][ 549/1563]\tLoss   0.52\tAcc  82.86\tTime/batch 0.057\n",
      "Epoch: [12][ 599/1563]\tLoss   0.52\tAcc  82.76\tTime/batch 0.057\n",
      "Epoch: [12][ 649/1563]\tLoss   0.52\tAcc  82.81\tTime/batch 0.057\n",
      "Epoch: [12][ 699/1563]\tLoss   0.52\tAcc  82.77\tTime/batch 0.057\n",
      "Epoch: [12][ 749/1563]\tLoss   0.52\tAcc  82.68\tTime/batch 0.057\n",
      "Epoch: [12][ 799/1563]\tLoss   0.52\tAcc  82.74\tTime/batch 0.057\n",
      "Epoch: [12][ 849/1563]\tLoss   0.52\tAcc  82.77\tTime/batch 0.057\n",
      "Epoch: [12][ 899/1563]\tLoss   0.52\tAcc  82.82\tTime/batch 0.057\n",
      "Epoch: [12][ 949/1563]\tLoss   0.52\tAcc  82.84\tTime/batch 0.057\n",
      "Epoch: [12][ 999/1563]\tLoss   0.51\tAcc  82.93\tTime/batch 0.057\n",
      "Epoch: [12][1049/1563]\tLoss   0.51\tAcc  82.98\tTime/batch 0.057\n",
      "Epoch: [12][1099/1563]\tLoss   0.51\tAcc  83.00\tTime/batch 0.057\n",
      "Epoch: [12][1149/1563]\tLoss   0.51\tAcc  83.04\tTime/batch 0.057\n",
      "Epoch: [12][1199/1563]\tLoss   0.51\tAcc  83.05\tTime/batch 0.057\n",
      "Epoch: [12][1249/1563]\tLoss   0.51\tAcc  83.16\tTime/batch 0.057\n",
      "Epoch: [12][1299/1563]\tLoss   0.51\tAcc  83.12\tTime/batch 0.057\n",
      "Epoch: [12][1349/1563]\tLoss   0.51\tAcc  83.06\tTime/batch 0.057\n",
      "Epoch: [12][1399/1563]\tLoss   0.51\tAcc  83.11\tTime/batch 0.057\n",
      "Epoch: [12][1449/1563]\tLoss   0.51\tAcc  83.12\tTime/batch 0.057\n",
      "Epoch: [12][1499/1563]\tLoss   0.51\tAcc  83.10\tTime/batch 0.057\n",
      "Epoch: [12][1549/1563]\tLoss   0.51\tAcc  83.14\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [13][  49/1563]\tLoss   0.45\tAcc  84.94\tTime/batch 0.058\n",
      "Epoch: [13][  99/1563]\tLoss   0.49\tAcc  83.56\tTime/batch 0.057\n",
      "Epoch: [13][ 149/1563]\tLoss   0.48\tAcc  83.88\tTime/batch 0.057\n",
      "Epoch: [13][ 199/1563]\tLoss   0.49\tAcc  83.92\tTime/batch 0.057\n",
      "Epoch: [13][ 249/1563]\tLoss   0.50\tAcc  83.70\tTime/batch 0.057\n",
      "Epoch: [13][ 299/1563]\tLoss   0.49\tAcc  83.82\tTime/batch 0.057\n",
      "Epoch: [13][ 349/1563]\tLoss   0.49\tAcc  83.94\tTime/batch 0.057\n",
      "Epoch: [13][ 399/1563]\tLoss   0.49\tAcc  83.85\tTime/batch 0.057\n",
      "Epoch: [13][ 449/1563]\tLoss   0.49\tAcc  83.72\tTime/batch 0.057\n",
      "Epoch: [13][ 499/1563]\tLoss   0.49\tAcc  83.79\tTime/batch 0.057\n",
      "Epoch: [13][ 549/1563]\tLoss   0.49\tAcc  83.89\tTime/batch 0.057\n",
      "Epoch: [13][ 599/1563]\tLoss   0.49\tAcc  83.88\tTime/batch 0.057\n",
      "Epoch: [13][ 649/1563]\tLoss   0.49\tAcc  84.03\tTime/batch 0.057\n",
      "Epoch: [13][ 699/1563]\tLoss   0.49\tAcc  83.98\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [13][ 749/1563]\tLoss   0.49\tAcc  83.95\tTime/batch 0.057\n",
      "Epoch: [13][ 799/1563]\tLoss   0.49\tAcc  84.00\tTime/batch 0.057\n",
      "Epoch: [13][ 849/1563]\tLoss   0.49\tAcc  84.02\tTime/batch 0.057\n",
      "Epoch: [13][ 899/1563]\tLoss   0.49\tAcc  83.96\tTime/batch 0.057\n",
      "Epoch: [13][ 949/1563]\tLoss   0.49\tAcc  83.97\tTime/batch 0.057\n",
      "Epoch: [13][ 999/1563]\tLoss   0.49\tAcc  83.85\tTime/batch 0.057\n",
      "Epoch: [13][1049/1563]\tLoss   0.49\tAcc  83.79\tTime/batch 0.057\n",
      "Epoch: [13][1099/1563]\tLoss   0.49\tAcc  83.75\tTime/batch 0.057\n",
      "Epoch: [13][1149/1563]\tLoss   0.49\tAcc  83.72\tTime/batch 0.057\n",
      "Epoch: [13][1199/1563]\tLoss   0.49\tAcc  83.77\tTime/batch 0.057\n",
      "Epoch: [13][1249/1563]\tLoss   0.49\tAcc  83.78\tTime/batch 0.057\n",
      "Epoch: [13][1299/1563]\tLoss   0.49\tAcc  83.82\tTime/batch 0.057\n",
      "Epoch: [13][1349/1563]\tLoss   0.49\tAcc  83.81\tTime/batch 0.057\n",
      "Epoch: [13][1399/1563]\tLoss   0.49\tAcc  83.82\tTime/batch 0.057\n",
      "Epoch: [13][1449/1563]\tLoss   0.49\tAcc  83.85\tTime/batch 0.057\n",
      "Epoch: [13][1499/1563]\tLoss   0.49\tAcc  83.84\tTime/batch 0.057\n",
      "Epoch: [13][1549/1563]\tLoss   0.49\tAcc  83.87\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [14][  49/1563]\tLoss   0.47\tAcc  84.19\tTime/batch 0.058\n",
      "Epoch: [14][  99/1563]\tLoss   0.48\tAcc  83.47\tTime/batch 0.057\n",
      "Epoch: [14][ 149/1563]\tLoss   0.47\tAcc  83.96\tTime/batch 0.057\n",
      "Epoch: [14][ 199/1563]\tLoss   0.47\tAcc  83.95\tTime/batch 0.057\n",
      "Epoch: [14][ 249/1563]\tLoss   0.47\tAcc  83.89\tTime/batch 0.057\n",
      "Epoch: [14][ 299/1563]\tLoss   0.48\tAcc  83.86\tTime/batch 0.057\n",
      "Epoch: [14][ 349/1563]\tLoss   0.48\tAcc  83.79\tTime/batch 0.057\n",
      "Epoch: [14][ 399/1563]\tLoss   0.48\tAcc  83.88\tTime/batch 0.057\n",
      "Epoch: [14][ 449/1563]\tLoss   0.48\tAcc  83.74\tTime/batch 0.057\n",
      "Epoch: [14][ 499/1563]\tLoss   0.48\tAcc  83.70\tTime/batch 0.057\n",
      "Epoch: [14][ 549/1563]\tLoss   0.48\tAcc  83.81\tTime/batch 0.057\n",
      "Epoch: [14][ 599/1563]\tLoss   0.48\tAcc  83.82\tTime/batch 0.057\n",
      "Epoch: [14][ 649/1563]\tLoss   0.48\tAcc  83.86\tTime/batch 0.057\n",
      "Epoch: [14][ 699/1563]\tLoss   0.48\tAcc  83.94\tTime/batch 0.057\n",
      "Epoch: [14][ 749/1563]\tLoss   0.48\tAcc  84.00\tTime/batch 0.057\n",
      "Epoch: [14][ 799/1563]\tLoss   0.48\tAcc  84.01\tTime/batch 0.057\n",
      "Epoch: [14][ 849/1563]\tLoss   0.48\tAcc  83.97\tTime/batch 0.057\n",
      "Epoch: [14][ 899/1563]\tLoss   0.48\tAcc  83.95\tTime/batch 0.057\n",
      "Epoch: [14][ 949/1563]\tLoss   0.48\tAcc  84.03\tTime/batch 0.057\n",
      "Epoch: [14][ 999/1563]\tLoss   0.48\tAcc  83.92\tTime/batch 0.057\n",
      "Epoch: [14][1049/1563]\tLoss   0.48\tAcc  83.91\tTime/batch 0.057\n",
      "Epoch: [14][1099/1563]\tLoss   0.48\tAcc  83.95\tTime/batch 0.057\n",
      "Epoch: [14][1149/1563]\tLoss   0.48\tAcc  83.97\tTime/batch 0.057\n",
      "Epoch: [14][1199/1563]\tLoss   0.48\tAcc  84.01\tTime/batch 0.057\n",
      "Epoch: [14][1249/1563]\tLoss   0.48\tAcc  84.04\tTime/batch 0.057\n",
      "Epoch: [14][1299/1563]\tLoss   0.48\tAcc  84.06\tTime/batch 0.057\n",
      "Epoch: [14][1349/1563]\tLoss   0.47\tAcc  84.09\tTime/batch 0.057\n",
      "Epoch: [14][1399/1563]\tLoss   0.48\tAcc  84.07\tTime/batch 0.057\n",
      "Epoch: [14][1449/1563]\tLoss   0.47\tAcc  84.09\tTime/batch 0.057\n",
      "Epoch: [14][1499/1563]\tLoss   0.48\tAcc  84.06\tTime/batch 0.057\n",
      "Epoch: [14][1549/1563]\tLoss   0.48\tAcc  84.09\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [15][  49/1563]\tLoss   0.46\tAcc  84.81\tTime/batch 0.057\n",
      "Epoch: [15][  99/1563]\tLoss   0.46\tAcc  84.44\tTime/batch 0.057\n",
      "Epoch: [15][ 149/1563]\tLoss   0.47\tAcc  84.29\tTime/batch 0.057\n",
      "Epoch: [15][ 199/1563]\tLoss   0.46\tAcc  84.64\tTime/batch 0.057\n",
      "Epoch: [15][ 249/1563]\tLoss   0.47\tAcc  84.58\tTime/batch 0.057\n",
      "Epoch: [15][ 299/1563]\tLoss   0.47\tAcc  84.32\tTime/batch 0.057\n",
      "Epoch: [15][ 349/1563]\tLoss   0.47\tAcc  84.36\tTime/batch 0.057\n",
      "Epoch: [15][ 399/1563]\tLoss   0.47\tAcc  84.29\tTime/batch 0.057\n",
      "Epoch: [15][ 449/1563]\tLoss   0.46\tAcc  84.55\tTime/batch 0.057\n",
      "Epoch: [15][ 499/1563]\tLoss   0.46\tAcc  84.50\tTime/batch 0.057\n",
      "Epoch: [15][ 549/1563]\tLoss   0.46\tAcc  84.55\tTime/batch 0.057\n",
      "Epoch: [15][ 599/1563]\tLoss   0.46\tAcc  84.59\tTime/batch 0.057\n",
      "Epoch: [15][ 649/1563]\tLoss   0.46\tAcc  84.69\tTime/batch 0.057\n",
      "Epoch: [15][ 699/1563]\tLoss   0.46\tAcc  84.67\tTime/batch 0.057\n",
      "Epoch: [15][ 749/1563]\tLoss   0.46\tAcc  84.77\tTime/batch 0.057\n",
      "Epoch: [15][ 799/1563]\tLoss   0.46\tAcc  84.76\tTime/batch 0.057\n",
      "Epoch: [15][ 849/1563]\tLoss   0.46\tAcc  84.72\tTime/batch 0.057\n",
      "Epoch: [15][ 899/1563]\tLoss   0.46\tAcc  84.71\tTime/batch 0.057\n",
      "Epoch: [15][ 949/1563]\tLoss   0.46\tAcc  84.63\tTime/batch 0.057\n",
      "Epoch: [15][ 999/1563]\tLoss   0.46\tAcc  84.60\tTime/batch 0.057\n",
      "Epoch: [15][1049/1563]\tLoss   0.46\tAcc  84.63\tTime/batch 0.057\n",
      "Epoch: [15][1099/1563]\tLoss   0.46\tAcc  84.64\tTime/batch 0.057\n",
      "Epoch: [15][1149/1563]\tLoss   0.46\tAcc  84.62\tTime/batch 0.057\n",
      "Epoch: [15][1199/1563]\tLoss   0.46\tAcc  84.58\tTime/batch 0.057\n",
      "Epoch: [15][1249/1563]\tLoss   0.46\tAcc  84.63\tTime/batch 0.057\n",
      "Epoch: [15][1299/1563]\tLoss   0.46\tAcc  84.60\tTime/batch 0.057\n",
      "Epoch: [15][1349/1563]\tLoss   0.46\tAcc  84.59\tTime/batch 0.057\n",
      "Epoch: [15][1399/1563]\tLoss   0.46\tAcc  84.57\tTime/batch 0.057\n",
      "Epoch: [15][1449/1563]\tLoss   0.46\tAcc  84.53\tTime/batch 0.057\n",
      "Epoch: [15][1499/1563]\tLoss   0.46\tAcc  84.46\tTime/batch 0.057\n",
      "Epoch: [15][1549/1563]\tLoss   0.46\tAcc  84.48\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [16][  49/1563]\tLoss   0.46\tAcc  84.25\tTime/batch 0.058\n",
      "Epoch: [16][  99/1563]\tLoss   0.46\tAcc  85.03\tTime/batch 0.058\n",
      "Epoch: [16][ 149/1563]\tLoss   0.46\tAcc  85.02\tTime/batch 0.057\n",
      "Epoch: [16][ 199/1563]\tLoss   0.45\tAcc  85.05\tTime/batch 0.057\n",
      "Epoch: [16][ 249/1563]\tLoss   0.45\tAcc  85.17\tTime/batch 0.057\n",
      "Epoch: [16][ 299/1563]\tLoss   0.45\tAcc  85.28\tTime/batch 0.057\n",
      "Epoch: [16][ 349/1563]\tLoss   0.45\tAcc  85.13\tTime/batch 0.057\n",
      "Epoch: [16][ 399/1563]\tLoss   0.45\tAcc  85.17\tTime/batch 0.057\n",
      "Epoch: [16][ 449/1563]\tLoss   0.45\tAcc  85.05\tTime/batch 0.057\n",
      "Epoch: [16][ 499/1563]\tLoss   0.45\tAcc  85.09\tTime/batch 0.057\n",
      "Epoch: [16][ 549/1563]\tLoss   0.45\tAcc  84.99\tTime/batch 0.057\n",
      "Epoch: [16][ 599/1563]\tLoss   0.45\tAcc  85.02\tTime/batch 0.057\n",
      "Epoch: [16][ 649/1563]\tLoss   0.45\tAcc  85.09\tTime/batch 0.057\n",
      "Epoch: [16][ 699/1563]\tLoss   0.45\tAcc  85.03\tTime/batch 0.057\n",
      "Epoch: [16][ 749/1563]\tLoss   0.45\tAcc  85.11\tTime/batch 0.057\n",
      "Epoch: [16][ 799/1563]\tLoss   0.45\tAcc  85.10\tTime/batch 0.057\n",
      "Epoch: [16][ 849/1563]\tLoss   0.45\tAcc  84.90\tTime/batch 0.057\n",
      "Epoch: [16][ 899/1563]\tLoss   0.45\tAcc  84.92\tTime/batch 0.057\n",
      "Epoch: [16][ 949/1563]\tLoss   0.45\tAcc  84.94\tTime/batch 0.057\n",
      "Epoch: [16][ 999/1563]\tLoss   0.45\tAcc  84.95\tTime/batch 0.057\n",
      "Epoch: [16][1049/1563]\tLoss   0.45\tAcc  84.95\tTime/batch 0.057\n",
      "Epoch: [16][1099/1563]\tLoss   0.45\tAcc  84.96\tTime/batch 0.057\n",
      "Epoch: [16][1149/1563]\tLoss   0.45\tAcc  85.01\tTime/batch 0.057\n",
      "Epoch: [16][1199/1563]\tLoss   0.45\tAcc  84.97\tTime/batch 0.057\n",
      "Epoch: [16][1249/1563]\tLoss   0.45\tAcc  84.92\tTime/batch 0.057\n",
      "Epoch: [16][1299/1563]\tLoss   0.45\tAcc  84.89\tTime/batch 0.057\n",
      "Epoch: [16][1349/1563]\tLoss   0.45\tAcc  84.89\tTime/batch 0.057\n",
      "Epoch: [16][1399/1563]\tLoss   0.45\tAcc  84.92\tTime/batch 0.057\n",
      "Epoch: [16][1449/1563]\tLoss   0.45\tAcc  84.97\tTime/batch 0.057\n",
      "Epoch: [16][1499/1563]\tLoss   0.45\tAcc  84.97\tTime/batch 0.057\n",
      "Epoch: [16][1549/1563]\tLoss   0.45\tAcc  85.01\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [17][  49/1563]\tLoss   0.42\tAcc  86.50\tTime/batch 0.058\n",
      "Epoch: [17][  99/1563]\tLoss   0.42\tAcc  86.47\tTime/batch 0.057\n",
      "Epoch: [17][ 149/1563]\tLoss   0.44\tAcc  85.79\tTime/batch 0.057\n",
      "Epoch: [17][ 199/1563]\tLoss   0.43\tAcc  85.69\tTime/batch 0.057\n",
      "Epoch: [17][ 249/1563]\tLoss   0.43\tAcc  85.72\tTime/batch 0.057\n",
      "Epoch: [17][ 299/1563]\tLoss   0.43\tAcc  85.78\tTime/batch 0.057\n",
      "Epoch: [17][ 349/1563]\tLoss   0.44\tAcc  85.46\tTime/batch 0.057\n",
      "Epoch: [17][ 399/1563]\tLoss   0.44\tAcc  85.45\tTime/batch 0.057\n",
      "Epoch: [17][ 449/1563]\tLoss   0.44\tAcc  85.37\tTime/batch 0.057\n",
      "Epoch: [17][ 499/1563]\tLoss   0.43\tAcc  85.42\tTime/batch 0.057\n",
      "Epoch: [17][ 549/1563]\tLoss   0.44\tAcc  85.36\tTime/batch 0.057\n",
      "Epoch: [17][ 599/1563]\tLoss   0.44\tAcc  85.19\tTime/batch 0.057\n",
      "Epoch: [17][ 649/1563]\tLoss   0.44\tAcc  85.17\tTime/batch 0.057\n",
      "Epoch: [17][ 699/1563]\tLoss   0.44\tAcc  85.11\tTime/batch 0.057\n",
      "Epoch: [17][ 749/1563]\tLoss   0.44\tAcc  85.09\tTime/batch 0.057\n",
      "Epoch: [17][ 799/1563]\tLoss   0.44\tAcc  85.00\tTime/batch 0.057\n",
      "Epoch: [17][ 849/1563]\tLoss   0.44\tAcc  85.08\tTime/batch 0.057\n",
      "Epoch: [17][ 899/1563]\tLoss   0.44\tAcc  85.05\tTime/batch 0.057\n",
      "Epoch: [17][ 949/1563]\tLoss   0.45\tAcc  84.92\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17][ 999/1563]\tLoss   0.45\tAcc  84.96\tTime/batch 0.057\n",
      "Epoch: [17][1049/1563]\tLoss   0.44\tAcc  85.00\tTime/batch 0.057\n",
      "Epoch: [17][1099/1563]\tLoss   0.44\tAcc  85.02\tTime/batch 0.057\n",
      "Epoch: [17][1149/1563]\tLoss   0.44\tAcc  85.02\tTime/batch 0.057\n",
      "Epoch: [17][1199/1563]\tLoss   0.44\tAcc  85.02\tTime/batch 0.057\n",
      "Epoch: [17][1249/1563]\tLoss   0.45\tAcc  84.97\tTime/batch 0.057\n",
      "Epoch: [17][1299/1563]\tLoss   0.44\tAcc  85.04\tTime/batch 0.057\n",
      "Epoch: [17][1349/1563]\tLoss   0.44\tAcc  85.02\tTime/batch 0.057\n",
      "Epoch: [17][1399/1563]\tLoss   0.45\tAcc  84.99\tTime/batch 0.057\n",
      "Epoch: [17][1449/1563]\tLoss   0.44\tAcc  84.98\tTime/batch 0.057\n",
      "Epoch: [17][1499/1563]\tLoss   0.44\tAcc  84.99\tTime/batch 0.057\n",
      "Epoch: [17][1549/1563]\tLoss   0.44\tAcc  85.03\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [18][  49/1563]\tLoss   0.44\tAcc  85.81\tTime/batch 0.057\n",
      "Epoch: [18][  99/1563]\tLoss   0.43\tAcc  86.16\tTime/batch 0.057\n",
      "Epoch: [18][ 149/1563]\tLoss   0.42\tAcc  86.42\tTime/batch 0.057\n",
      "Epoch: [18][ 199/1563]\tLoss   0.42\tAcc  86.06\tTime/batch 0.057\n",
      "Epoch: [18][ 249/1563]\tLoss   0.42\tAcc  85.66\tTime/batch 0.057\n",
      "Epoch: [18][ 299/1563]\tLoss   0.43\tAcc  85.56\tTime/batch 0.057\n",
      "Epoch: [18][ 349/1563]\tLoss   0.42\tAcc  85.68\tTime/batch 0.057\n",
      "Epoch: [18][ 399/1563]\tLoss   0.43\tAcc  85.58\tTime/batch 0.057\n",
      "Epoch: [18][ 449/1563]\tLoss   0.42\tAcc  85.69\tTime/batch 0.057\n",
      "Epoch: [18][ 499/1563]\tLoss   0.42\tAcc  85.62\tTime/batch 0.057\n",
      "Epoch: [18][ 549/1563]\tLoss   0.43\tAcc  85.57\tTime/batch 0.057\n",
      "Epoch: [18][ 599/1563]\tLoss   0.43\tAcc  85.64\tTime/batch 0.057\n",
      "Epoch: [18][ 649/1563]\tLoss   0.43\tAcc  85.59\tTime/batch 0.057\n",
      "Epoch: [18][ 699/1563]\tLoss   0.43\tAcc  85.67\tTime/batch 0.057\n",
      "Epoch: [18][ 749/1563]\tLoss   0.43\tAcc  85.60\tTime/batch 0.057\n",
      "Epoch: [18][ 799/1563]\tLoss   0.43\tAcc  85.50\tTime/batch 0.057\n",
      "Epoch: [18][ 849/1563]\tLoss   0.43\tAcc  85.43\tTime/batch 0.057\n",
      "Epoch: [18][ 899/1563]\tLoss   0.43\tAcc  85.48\tTime/batch 0.057\n",
      "Epoch: [18][ 949/1563]\tLoss   0.43\tAcc  85.53\tTime/batch 0.057\n",
      "Epoch: [18][ 999/1563]\tLoss   0.43\tAcc  85.54\tTime/batch 0.057\n",
      "Epoch: [18][1049/1563]\tLoss   0.43\tAcc  85.54\tTime/batch 0.057\n",
      "Epoch: [18][1099/1563]\tLoss   0.43\tAcc  85.50\tTime/batch 0.057\n",
      "Epoch: [18][1149/1563]\tLoss   0.43\tAcc  85.51\tTime/batch 0.057\n",
      "Epoch: [18][1199/1563]\tLoss   0.43\tAcc  85.55\tTime/batch 0.057\n",
      "Epoch: [18][1249/1563]\tLoss   0.43\tAcc  85.54\tTime/batch 0.057\n",
      "Epoch: [18][1299/1563]\tLoss   0.43\tAcc  85.51\tTime/batch 0.057\n",
      "Epoch: [18][1349/1563]\tLoss   0.43\tAcc  85.48\tTime/batch 0.057\n",
      "Epoch: [18][1399/1563]\tLoss   0.43\tAcc  85.53\tTime/batch 0.057\n",
      "Epoch: [18][1449/1563]\tLoss   0.43\tAcc  85.49\tTime/batch 0.057\n",
      "Epoch: [18][1499/1563]\tLoss   0.43\tAcc  85.52\tTime/batch 0.057\n",
      "Epoch: [18][1549/1563]\tLoss   0.43\tAcc  85.51\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [19][  49/1563]\tLoss   0.39\tAcc  86.44\tTime/batch 0.058\n",
      "Epoch: [19][  99/1563]\tLoss   0.41\tAcc  86.22\tTime/batch 0.058\n",
      "Epoch: [19][ 149/1563]\tLoss   0.40\tAcc  86.46\tTime/batch 0.057\n",
      "Epoch: [19][ 199/1563]\tLoss   0.40\tAcc  86.31\tTime/batch 0.057\n",
      "Epoch: [19][ 249/1563]\tLoss   0.41\tAcc  86.11\tTime/batch 0.057\n",
      "Epoch: [19][ 299/1563]\tLoss   0.41\tAcc  85.88\tTime/batch 0.057\n",
      "Epoch: [19][ 349/1563]\tLoss   0.42\tAcc  85.65\tTime/batch 0.057\n",
      "Epoch: [19][ 399/1563]\tLoss   0.42\tAcc  85.78\tTime/batch 0.057\n",
      "Epoch: [19][ 449/1563]\tLoss   0.42\tAcc  85.81\tTime/batch 0.057\n",
      "Epoch: [19][ 499/1563]\tLoss   0.42\tAcc  85.70\tTime/batch 0.057\n",
      "Epoch: [19][ 549/1563]\tLoss   0.42\tAcc  85.60\tTime/batch 0.057\n",
      "Epoch: [19][ 599/1563]\tLoss   0.42\tAcc  85.65\tTime/batch 0.057\n",
      "Epoch: [19][ 649/1563]\tLoss   0.42\tAcc  85.66\tTime/batch 0.057\n",
      "Epoch: [19][ 699/1563]\tLoss   0.42\tAcc  85.63\tTime/batch 0.057\n",
      "Epoch: [19][ 749/1563]\tLoss   0.42\tAcc  85.65\tTime/batch 0.057\n",
      "Epoch: [19][ 799/1563]\tLoss   0.42\tAcc  85.60\tTime/batch 0.057\n",
      "Epoch: [19][ 849/1563]\tLoss   0.42\tAcc  85.57\tTime/batch 0.057\n",
      "Epoch: [19][ 899/1563]\tLoss   0.42\tAcc  85.59\tTime/batch 0.057\n",
      "Epoch: [19][ 949/1563]\tLoss   0.42\tAcc  85.66\tTime/batch 0.057\n",
      "Epoch: [19][ 999/1563]\tLoss   0.42\tAcc  85.59\tTime/batch 0.057\n",
      "Epoch: [19][1049/1563]\tLoss   0.42\tAcc  85.54\tTime/batch 0.057\n",
      "Epoch: [19][1099/1563]\tLoss   0.42\tAcc  85.54\tTime/batch 0.057\n",
      "Epoch: [19][1149/1563]\tLoss   0.42\tAcc  85.54\tTime/batch 0.057\n",
      "Epoch: [19][1199/1563]\tLoss   0.42\tAcc  85.55\tTime/batch 0.057\n",
      "Epoch: [19][1249/1563]\tLoss   0.42\tAcc  85.59\tTime/batch 0.057\n",
      "Epoch: [19][1299/1563]\tLoss   0.42\tAcc  85.61\tTime/batch 0.057\n",
      "Epoch: [19][1349/1563]\tLoss   0.42\tAcc  85.66\tTime/batch 0.057\n",
      "Epoch: [19][1399/1563]\tLoss   0.42\tAcc  85.66\tTime/batch 0.057\n",
      "Epoch: [19][1449/1563]\tLoss   0.42\tAcc  85.70\tTime/batch 0.057\n",
      "Epoch: [19][1499/1563]\tLoss   0.42\tAcc  85.66\tTime/batch 0.057\n",
      "Epoch: [19][1549/1563]\tLoss   0.42\tAcc  85.65\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [20][  49/1563]\tLoss   0.42\tAcc  85.94\tTime/batch 0.058\n",
      "Epoch: [20][  99/1563]\tLoss   0.41\tAcc  86.28\tTime/batch 0.058\n",
      "Epoch: [20][ 149/1563]\tLoss   0.41\tAcc  86.29\tTime/batch 0.058\n",
      "Epoch: [20][ 199/1563]\tLoss   0.41\tAcc  86.34\tTime/batch 0.057\n",
      "Epoch: [20][ 249/1563]\tLoss   0.40\tAcc  86.58\tTime/batch 0.057\n",
      "Epoch: [20][ 299/1563]\tLoss   0.40\tAcc  86.48\tTime/batch 0.057\n",
      "Epoch: [20][ 349/1563]\tLoss   0.41\tAcc  86.37\tTime/batch 0.057\n",
      "Epoch: [20][ 399/1563]\tLoss   0.41\tAcc  86.11\tTime/batch 0.057\n",
      "Epoch: [20][ 449/1563]\tLoss   0.41\tAcc  86.01\tTime/batch 0.057\n",
      "Epoch: [20][ 499/1563]\tLoss   0.41\tAcc  86.25\tTime/batch 0.057\n",
      "Epoch: [20][ 549/1563]\tLoss   0.41\tAcc  86.27\tTime/batch 0.057\n",
      "Epoch: [20][ 599/1563]\tLoss   0.41\tAcc  86.23\tTime/batch 0.057\n",
      "Epoch: [20][ 649/1563]\tLoss   0.41\tAcc  86.24\tTime/batch 0.057\n",
      "Epoch: [20][ 699/1563]\tLoss   0.41\tAcc  86.20\tTime/batch 0.057\n",
      "Epoch: [20][ 749/1563]\tLoss   0.41\tAcc  86.12\tTime/batch 0.057\n",
      "Epoch: [20][ 799/1563]\tLoss   0.41\tAcc  86.07\tTime/batch 0.057\n",
      "Epoch: [20][ 849/1563]\tLoss   0.41\tAcc  86.09\tTime/batch 0.057\n",
      "Epoch: [20][ 899/1563]\tLoss   0.41\tAcc  86.11\tTime/batch 0.057\n",
      "Epoch: [20][ 949/1563]\tLoss   0.41\tAcc  86.02\tTime/batch 0.057\n",
      "Epoch: [20][ 999/1563]\tLoss   0.41\tAcc  86.03\tTime/batch 0.057\n",
      "Epoch: [20][1049/1563]\tLoss   0.41\tAcc  86.07\tTime/batch 0.057\n",
      "Epoch: [20][1099/1563]\tLoss   0.41\tAcc  86.12\tTime/batch 0.057\n",
      "Epoch: [20][1149/1563]\tLoss   0.41\tAcc  86.15\tTime/batch 0.057\n",
      "Epoch: [20][1199/1563]\tLoss   0.41\tAcc  86.08\tTime/batch 0.057\n",
      "Epoch: [20][1249/1563]\tLoss   0.41\tAcc  86.05\tTime/batch 0.057\n",
      "Epoch: [20][1299/1563]\tLoss   0.41\tAcc  86.03\tTime/batch 0.057\n",
      "Epoch: [20][1349/1563]\tLoss   0.41\tAcc  86.03\tTime/batch 0.057\n",
      "Epoch: [20][1399/1563]\tLoss   0.41\tAcc  85.99\tTime/batch 0.057\n",
      "Epoch: [20][1449/1563]\tLoss   0.42\tAcc  85.94\tTime/batch 0.057\n",
      "Epoch: [20][1499/1563]\tLoss   0.42\tAcc  85.96\tTime/batch 0.057\n",
      "Epoch: [20][1549/1563]\tLoss   0.41\tAcc  85.94\tTime/batch 0.057\n",
      "epoch 20\n",
      "Accuracy of the network on the 10000 test images: 83.6 %\n",
      "Sparsity of the update phase: 66.0 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [21][  49/1563]\tLoss   0.39\tAcc  86.38\tTime/batch 0.058\n",
      "Epoch: [21][  99/1563]\tLoss   0.39\tAcc  86.91\tTime/batch 0.057\n",
      "Epoch: [21][ 149/1563]\tLoss   0.39\tAcc  86.54\tTime/batch 0.057\n",
      "Epoch: [21][ 199/1563]\tLoss   0.39\tAcc  86.53\tTime/batch 0.057\n",
      "Epoch: [21][ 249/1563]\tLoss   0.40\tAcc  86.47\tTime/batch 0.057\n",
      "Epoch: [21][ 299/1563]\tLoss   0.40\tAcc  86.41\tTime/batch 0.057\n",
      "Epoch: [21][ 349/1563]\tLoss   0.40\tAcc  86.23\tTime/batch 0.057\n",
      "Epoch: [21][ 399/1563]\tLoss   0.40\tAcc  86.20\tTime/batch 0.057\n",
      "Epoch: [21][ 449/1563]\tLoss   0.40\tAcc  86.19\tTime/batch 0.057\n",
      "Epoch: [21][ 499/1563]\tLoss   0.40\tAcc  86.16\tTime/batch 0.057\n",
      "Epoch: [21][ 549/1563]\tLoss   0.40\tAcc  86.18\tTime/batch 0.057\n",
      "Epoch: [21][ 599/1563]\tLoss   0.40\tAcc  86.14\tTime/batch 0.057\n",
      "Epoch: [21][ 649/1563]\tLoss   0.40\tAcc  86.09\tTime/batch 0.057\n",
      "Epoch: [21][ 699/1563]\tLoss   0.40\tAcc  86.04\tTime/batch 0.057\n",
      "Epoch: [21][ 749/1563]\tLoss   0.40\tAcc  86.05\tTime/batch 0.057\n",
      "Epoch: [21][ 799/1563]\tLoss   0.41\tAcc  85.92\tTime/batch 0.057\n",
      "Epoch: [21][ 849/1563]\tLoss   0.41\tAcc  85.87\tTime/batch 0.057\n",
      "Epoch: [21][ 899/1563]\tLoss   0.41\tAcc  85.93\tTime/batch 0.057\n",
      "Epoch: [21][ 949/1563]\tLoss   0.41\tAcc  85.93\tTime/batch 0.057\n",
      "Epoch: [21][ 999/1563]\tLoss   0.41\tAcc  85.97\tTime/batch 0.057\n",
      "Epoch: [21][1049/1563]\tLoss   0.41\tAcc  85.98\tTime/batch 0.057\n",
      "Epoch: [21][1099/1563]\tLoss   0.41\tAcc  85.95\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [21][1149/1563]\tLoss   0.41\tAcc  85.92\tTime/batch 0.057\n",
      "Epoch: [21][1199/1563]\tLoss   0.41\tAcc  85.97\tTime/batch 0.057\n",
      "Epoch: [21][1249/1563]\tLoss   0.41\tAcc  85.95\tTime/batch 0.057\n",
      "Epoch: [21][1299/1563]\tLoss   0.41\tAcc  85.93\tTime/batch 0.057\n",
      "Epoch: [21][1349/1563]\tLoss   0.41\tAcc  85.94\tTime/batch 0.057\n",
      "Epoch: [21][1399/1563]\tLoss   0.41\tAcc  85.89\tTime/batch 0.057\n",
      "Epoch: [21][1449/1563]\tLoss   0.41\tAcc  85.91\tTime/batch 0.057\n",
      "Epoch: [21][1499/1563]\tLoss   0.41\tAcc  85.90\tTime/batch 0.056\n",
      "Epoch: [21][1549/1563]\tLoss   0.41\tAcc  85.86\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [22][  49/1563]\tLoss   0.39\tAcc  85.81\tTime/batch 0.057\n",
      "Epoch: [22][  99/1563]\tLoss   0.37\tAcc  86.69\tTime/batch 0.057\n",
      "Epoch: [22][ 149/1563]\tLoss   0.38\tAcc  86.21\tTime/batch 0.057\n",
      "Epoch: [22][ 199/1563]\tLoss   0.37\tAcc  86.73\tTime/batch 0.057\n",
      "Epoch: [22][ 249/1563]\tLoss   0.38\tAcc  86.51\tTime/batch 0.056\n",
      "Epoch: [22][ 299/1563]\tLoss   0.38\tAcc  86.67\tTime/batch 0.056\n",
      "Epoch: [22][ 349/1563]\tLoss   0.38\tAcc  86.77\tTime/batch 0.056\n",
      "Epoch: [22][ 399/1563]\tLoss   0.38\tAcc  86.86\tTime/batch 0.056\n",
      "Epoch: [22][ 449/1563]\tLoss   0.39\tAcc  86.67\tTime/batch 0.056\n",
      "Epoch: [22][ 499/1563]\tLoss   0.39\tAcc  86.68\tTime/batch 0.056\n",
      "Epoch: [22][ 549/1563]\tLoss   0.39\tAcc  86.59\tTime/batch 0.056\n",
      "Epoch: [22][ 599/1563]\tLoss   0.39\tAcc  86.47\tTime/batch 0.056\n",
      "Epoch: [22][ 649/1563]\tLoss   0.40\tAcc  86.43\tTime/batch 0.056\n",
      "Epoch: [22][ 699/1563]\tLoss   0.40\tAcc  86.42\tTime/batch 0.056\n",
      "Epoch: [22][ 749/1563]\tLoss   0.40\tAcc  86.45\tTime/batch 0.056\n",
      "Epoch: [22][ 799/1563]\tLoss   0.40\tAcc  86.46\tTime/batch 0.056\n",
      "Epoch: [22][ 849/1563]\tLoss   0.40\tAcc  86.39\tTime/batch 0.056\n",
      "Epoch: [22][ 899/1563]\tLoss   0.40\tAcc  86.43\tTime/batch 0.056\n",
      "Epoch: [22][ 949/1563]\tLoss   0.39\tAcc  86.46\tTime/batch 0.056\n",
      "Epoch: [22][ 999/1563]\tLoss   0.39\tAcc  86.48\tTime/batch 0.056\n",
      "Epoch: [22][1049/1563]\tLoss   0.39\tAcc  86.51\tTime/batch 0.056\n",
      "Epoch: [22][1099/1563]\tLoss   0.39\tAcc  86.51\tTime/batch 0.056\n",
      "Epoch: [22][1149/1563]\tLoss   0.40\tAcc  86.45\tTime/batch 0.056\n",
      "Epoch: [22][1199/1563]\tLoss   0.40\tAcc  86.39\tTime/batch 0.056\n",
      "Epoch: [22][1249/1563]\tLoss   0.40\tAcc  86.37\tTime/batch 0.056\n",
      "Epoch: [22][1299/1563]\tLoss   0.40\tAcc  86.38\tTime/batch 0.056\n",
      "Epoch: [22][1349/1563]\tLoss   0.40\tAcc  86.39\tTime/batch 0.056\n",
      "Epoch: [22][1399/1563]\tLoss   0.40\tAcc  86.38\tTime/batch 0.056\n",
      "Epoch: [22][1449/1563]\tLoss   0.40\tAcc  86.38\tTime/batch 0.056\n",
      "Epoch: [22][1499/1563]\tLoss   0.40\tAcc  86.33\tTime/batch 0.056\n",
      "Epoch: [22][1549/1563]\tLoss   0.40\tAcc  86.30\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [23][  49/1563]\tLoss   0.40\tAcc  86.38\tTime/batch 0.057\n",
      "Epoch: [23][  99/1563]\tLoss   0.38\tAcc  86.84\tTime/batch 0.057\n",
      "Epoch: [23][ 149/1563]\tLoss   0.39\tAcc  86.65\tTime/batch 0.057\n",
      "Epoch: [23][ 199/1563]\tLoss   0.38\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [23][ 249/1563]\tLoss   0.38\tAcc  86.90\tTime/batch 0.057\n",
      "Epoch: [23][ 299/1563]\tLoss   0.37\tAcc  87.11\tTime/batch 0.057\n",
      "Epoch: [23][ 349/1563]\tLoss   0.38\tAcc  86.94\tTime/batch 0.057\n",
      "Epoch: [23][ 399/1563]\tLoss   0.38\tAcc  86.79\tTime/batch 0.057\n",
      "Epoch: [23][ 449/1563]\tLoss   0.38\tAcc  86.88\tTime/batch 0.057\n",
      "Epoch: [23][ 499/1563]\tLoss   0.38\tAcc  86.74\tTime/batch 0.057\n",
      "Epoch: [23][ 549/1563]\tLoss   0.38\tAcc  86.77\tTime/batch 0.057\n",
      "Epoch: [23][ 599/1563]\tLoss   0.38\tAcc  86.84\tTime/batch 0.057\n",
      "Epoch: [23][ 649/1563]\tLoss   0.38\tAcc  86.86\tTime/batch 0.057\n",
      "Epoch: [23][ 699/1563]\tLoss   0.38\tAcc  86.84\tTime/batch 0.057\n",
      "Epoch: [23][ 749/1563]\tLoss   0.39\tAcc  86.77\tTime/batch 0.057\n",
      "Epoch: [23][ 799/1563]\tLoss   0.39\tAcc  86.62\tTime/batch 0.057\n",
      "Epoch: [23][ 849/1563]\tLoss   0.39\tAcc  86.59\tTime/batch 0.057\n",
      "Epoch: [23][ 899/1563]\tLoss   0.39\tAcc  86.60\tTime/batch 0.057\n",
      "Epoch: [23][ 949/1563]\tLoss   0.39\tAcc  86.63\tTime/batch 0.057\n",
      "Epoch: [23][ 999/1563]\tLoss   0.39\tAcc  86.58\tTime/batch 0.057\n",
      "Epoch: [23][1049/1563]\tLoss   0.39\tAcc  86.63\tTime/batch 0.057\n",
      "Epoch: [23][1099/1563]\tLoss   0.39\tAcc  86.57\tTime/batch 0.057\n",
      "Epoch: [23][1149/1563]\tLoss   0.39\tAcc  86.56\tTime/batch 0.057\n",
      "Epoch: [23][1199/1563]\tLoss   0.39\tAcc  86.55\tTime/batch 0.057\n",
      "Epoch: [23][1249/1563]\tLoss   0.39\tAcc  86.53\tTime/batch 0.057\n",
      "Epoch: [23][1299/1563]\tLoss   0.39\tAcc  86.55\tTime/batch 0.057\n",
      "Epoch: [23][1349/1563]\tLoss   0.39\tAcc  86.47\tTime/batch 0.057\n",
      "Epoch: [23][1399/1563]\tLoss   0.39\tAcc  86.48\tTime/batch 0.057\n",
      "Epoch: [23][1449/1563]\tLoss   0.39\tAcc  86.48\tTime/batch 0.057\n",
      "Epoch: [23][1499/1563]\tLoss   0.39\tAcc  86.47\tTime/batch 0.057\n",
      "Epoch: [23][1549/1563]\tLoss   0.39\tAcc  86.50\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [24][  49/1563]\tLoss   0.40\tAcc  85.94\tTime/batch 0.057\n",
      "Epoch: [24][  99/1563]\tLoss   0.38\tAcc  86.91\tTime/batch 0.057\n",
      "Epoch: [24][ 149/1563]\tLoss   0.39\tAcc  86.98\tTime/batch 0.057\n",
      "Epoch: [24][ 199/1563]\tLoss   0.39\tAcc  86.77\tTime/batch 0.057\n",
      "Epoch: [24][ 249/1563]\tLoss   0.38\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [24][ 299/1563]\tLoss   0.39\tAcc  86.73\tTime/batch 0.057\n",
      "Epoch: [24][ 349/1563]\tLoss   0.39\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [24][ 399/1563]\tLoss   0.38\tAcc  86.87\tTime/batch 0.057\n",
      "Epoch: [24][ 449/1563]\tLoss   0.38\tAcc  87.08\tTime/batch 0.057\n",
      "Epoch: [24][ 499/1563]\tLoss   0.38\tAcc  86.96\tTime/batch 0.057\n",
      "Epoch: [24][ 549/1563]\tLoss   0.38\tAcc  86.97\tTime/batch 0.057\n",
      "Epoch: [24][ 599/1563]\tLoss   0.38\tAcc  87.15\tTime/batch 0.057\n",
      "Epoch: [24][ 649/1563]\tLoss   0.38\tAcc  87.21\tTime/batch 0.057\n",
      "Epoch: [24][ 699/1563]\tLoss   0.38\tAcc  87.12\tTime/batch 0.057\n",
      "Epoch: [24][ 749/1563]\tLoss   0.38\tAcc  87.10\tTime/batch 0.057\n",
      "Epoch: [24][ 799/1563]\tLoss   0.38\tAcc  86.91\tTime/batch 0.057\n",
      "Epoch: [24][ 849/1563]\tLoss   0.38\tAcc  86.98\tTime/batch 0.057\n",
      "Epoch: [24][ 899/1563]\tLoss   0.39\tAcc  86.98\tTime/batch 0.057\n",
      "Epoch: [24][ 949/1563]\tLoss   0.38\tAcc  86.96\tTime/batch 0.057\n",
      "Epoch: [24][ 999/1563]\tLoss   0.39\tAcc  86.94\tTime/batch 0.057\n",
      "Epoch: [24][1049/1563]\tLoss   0.38\tAcc  87.01\tTime/batch 0.057\n",
      "Epoch: [24][1099/1563]\tLoss   0.38\tAcc  86.98\tTime/batch 0.057\n",
      "Epoch: [24][1149/1563]\tLoss   0.38\tAcc  86.97\tTime/batch 0.057\n",
      "Epoch: [24][1199/1563]\tLoss   0.38\tAcc  86.92\tTime/batch 0.057\n",
      "Epoch: [24][1249/1563]\tLoss   0.38\tAcc  86.94\tTime/batch 0.057\n",
      "Epoch: [24][1299/1563]\tLoss   0.39\tAcc  86.87\tTime/batch 0.057\n",
      "Epoch: [24][1349/1563]\tLoss   0.39\tAcc  86.86\tTime/batch 0.057\n",
      "Epoch: [24][1399/1563]\tLoss   0.39\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [24][1449/1563]\tLoss   0.38\tAcc  86.91\tTime/batch 0.057\n",
      "Epoch: [24][1499/1563]\tLoss   0.39\tAcc  86.85\tTime/batch 0.057\n",
      "Epoch: [24][1549/1563]\tLoss   0.39\tAcc  86.85\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [25][  49/1563]\tLoss   0.39\tAcc  87.12\tTime/batch 0.058\n",
      "Epoch: [25][  99/1563]\tLoss   0.38\tAcc  87.28\tTime/batch 0.057\n",
      "Epoch: [25][ 149/1563]\tLoss   0.36\tAcc  87.85\tTime/batch 0.057\n",
      "Epoch: [25][ 199/1563]\tLoss   0.37\tAcc  87.38\tTime/batch 0.057\n",
      "Epoch: [25][ 249/1563]\tLoss   0.37\tAcc  87.28\tTime/batch 0.057\n",
      "Epoch: [25][ 299/1563]\tLoss   0.38\tAcc  87.15\tTime/batch 0.057\n",
      "Epoch: [25][ 349/1563]\tLoss   0.38\tAcc  87.09\tTime/batch 0.057\n",
      "Epoch: [25][ 399/1563]\tLoss   0.38\tAcc  87.06\tTime/batch 0.057\n",
      "Epoch: [25][ 449/1563]\tLoss   0.38\tAcc  87.19\tTime/batch 0.057\n",
      "Epoch: [25][ 499/1563]\tLoss   0.38\tAcc  87.08\tTime/batch 0.057\n",
      "Epoch: [25][ 549/1563]\tLoss   0.38\tAcc  87.05\tTime/batch 0.057\n",
      "Epoch: [25][ 599/1563]\tLoss   0.38\tAcc  86.99\tTime/batch 0.057\n",
      "Epoch: [25][ 649/1563]\tLoss   0.38\tAcc  86.99\tTime/batch 0.057\n",
      "Epoch: [25][ 699/1563]\tLoss   0.38\tAcc  86.94\tTime/batch 0.057\n",
      "Epoch: [25][ 749/1563]\tLoss   0.38\tAcc  86.97\tTime/batch 0.057\n",
      "Epoch: [25][ 799/1563]\tLoss   0.38\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [25][ 849/1563]\tLoss   0.38\tAcc  86.88\tTime/batch 0.057\n",
      "Epoch: [25][ 899/1563]\tLoss   0.38\tAcc  86.75\tTime/batch 0.057\n",
      "Epoch: [25][ 949/1563]\tLoss   0.38\tAcc  86.76\tTime/batch 0.057\n",
      "Epoch: [25][ 999/1563]\tLoss   0.38\tAcc  86.76\tTime/batch 0.057\n",
      "Epoch: [25][1049/1563]\tLoss   0.38\tAcc  86.88\tTime/batch 0.057\n",
      "Epoch: [25][1099/1563]\tLoss   0.38\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [25][1149/1563]\tLoss   0.38\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [25][1199/1563]\tLoss   0.38\tAcc  86.89\tTime/batch 0.057\n",
      "Epoch: [25][1249/1563]\tLoss   0.38\tAcc  86.88\tTime/batch 0.057\n",
      "Epoch: [25][1299/1563]\tLoss   0.38\tAcc  86.91\tTime/batch 0.057\n",
      "Epoch: [25][1349/1563]\tLoss   0.38\tAcc  86.91\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [25][1399/1563]\tLoss   0.38\tAcc  86.92\tTime/batch 0.057\n",
      "Epoch: [25][1449/1563]\tLoss   0.38\tAcc  86.87\tTime/batch 0.057\n",
      "Epoch: [25][1499/1563]\tLoss   0.38\tAcc  86.86\tTime/batch 0.057\n",
      "Epoch: [25][1549/1563]\tLoss   0.38\tAcc  86.85\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [26][  49/1563]\tLoss   0.41\tAcc  85.94\tTime/batch 0.057\n",
      "Epoch: [26][  99/1563]\tLoss   0.39\tAcc  86.75\tTime/batch 0.057\n",
      "Epoch: [26][ 149/1563]\tLoss   0.38\tAcc  86.69\tTime/batch 0.057\n",
      "Epoch: [26][ 199/1563]\tLoss   0.38\tAcc  86.70\tTime/batch 0.057\n",
      "Epoch: [26][ 249/1563]\tLoss   0.37\tAcc  86.92\tTime/batch 0.057\n",
      "Epoch: [26][ 299/1563]\tLoss   0.36\tAcc  87.20\tTime/batch 0.057\n",
      "Epoch: [26][ 349/1563]\tLoss   0.36\tAcc  87.28\tTime/batch 0.057\n",
      "Epoch: [26][ 399/1563]\tLoss   0.36\tAcc  87.23\tTime/batch 0.057\n",
      "Epoch: [26][ 449/1563]\tLoss   0.36\tAcc  87.30\tTime/batch 0.057\n",
      "Epoch: [26][ 499/1563]\tLoss   0.36\tAcc  87.34\tTime/batch 0.057\n",
      "Epoch: [26][ 549/1563]\tLoss   0.36\tAcc  87.27\tTime/batch 0.057\n",
      "Epoch: [26][ 599/1563]\tLoss   0.36\tAcc  87.28\tTime/batch 0.057\n",
      "Epoch: [26][ 649/1563]\tLoss   0.36\tAcc  87.30\tTime/batch 0.057\n",
      "Epoch: [26][ 699/1563]\tLoss   0.36\tAcc  87.37\tTime/batch 0.057\n",
      "Epoch: [26][ 749/1563]\tLoss   0.36\tAcc  87.29\tTime/batch 0.057\n",
      "Epoch: [26][ 799/1563]\tLoss   0.37\tAcc  87.24\tTime/batch 0.057\n",
      "Epoch: [26][ 849/1563]\tLoss   0.37\tAcc  87.11\tTime/batch 0.057\n",
      "Epoch: [26][ 899/1563]\tLoss   0.37\tAcc  87.07\tTime/batch 0.057\n",
      "Epoch: [26][ 949/1563]\tLoss   0.37\tAcc  87.06\tTime/batch 0.057\n",
      "Epoch: [26][ 999/1563]\tLoss   0.37\tAcc  87.05\tTime/batch 0.057\n",
      "Epoch: [26][1049/1563]\tLoss   0.37\tAcc  87.01\tTime/batch 0.057\n",
      "Epoch: [26][1099/1563]\tLoss   0.37\tAcc  87.01\tTime/batch 0.057\n",
      "Epoch: [26][1149/1563]\tLoss   0.37\tAcc  87.06\tTime/batch 0.057\n",
      "Epoch: [26][1199/1563]\tLoss   0.37\tAcc  87.11\tTime/batch 0.057\n",
      "Epoch: [26][1249/1563]\tLoss   0.37\tAcc  87.13\tTime/batch 0.057\n",
      "Epoch: [26][1299/1563]\tLoss   0.37\tAcc  87.06\tTime/batch 0.057\n",
      "Epoch: [26][1349/1563]\tLoss   0.37\tAcc  87.07\tTime/batch 0.057\n",
      "Epoch: [26][1399/1563]\tLoss   0.37\tAcc  87.05\tTime/batch 0.057\n",
      "Epoch: [26][1449/1563]\tLoss   0.38\tAcc  87.02\tTime/batch 0.057\n",
      "Epoch: [26][1499/1563]\tLoss   0.38\tAcc  87.01\tTime/batch 0.057\n",
      "Epoch: [26][1549/1563]\tLoss   0.38\tAcc  86.98\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [27][  49/1563]\tLoss   0.34\tAcc  89.12\tTime/batch 0.058\n",
      "Epoch: [27][  99/1563]\tLoss   0.35\tAcc  88.12\tTime/batch 0.057\n",
      "Epoch: [27][ 149/1563]\tLoss   0.35\tAcc  87.75\tTime/batch 0.057\n",
      "Epoch: [27][ 199/1563]\tLoss   0.36\tAcc  87.59\tTime/batch 0.057\n",
      "Epoch: [27][ 249/1563]\tLoss   0.36\tAcc  87.42\tTime/batch 0.057\n",
      "Epoch: [27][ 299/1563]\tLoss   0.36\tAcc  87.49\tTime/batch 0.057\n",
      "Epoch: [27][ 349/1563]\tLoss   0.36\tAcc  87.57\tTime/batch 0.057\n",
      "Epoch: [27][ 399/1563]\tLoss   0.36\tAcc  87.63\tTime/batch 0.057\n",
      "Epoch: [27][ 449/1563]\tLoss   0.36\tAcc  87.67\tTime/batch 0.057\n",
      "Epoch: [27][ 499/1563]\tLoss   0.36\tAcc  87.61\tTime/batch 0.057\n",
      "Epoch: [27][ 549/1563]\tLoss   0.37\tAcc  87.47\tTime/batch 0.057\n",
      "Epoch: [27][ 599/1563]\tLoss   0.37\tAcc  87.39\tTime/batch 0.057\n",
      "Epoch: [27][ 649/1563]\tLoss   0.37\tAcc  87.35\tTime/batch 0.057\n",
      "Epoch: [27][ 699/1563]\tLoss   0.36\tAcc  87.48\tTime/batch 0.057\n",
      "Epoch: [27][ 749/1563]\tLoss   0.37\tAcc  87.41\tTime/batch 0.057\n",
      "Epoch: [27][ 799/1563]\tLoss   0.37\tAcc  87.43\tTime/batch 0.057\n",
      "Epoch: [27][ 849/1563]\tLoss   0.37\tAcc  87.48\tTime/batch 0.057\n",
      "Epoch: [27][ 899/1563]\tLoss   0.37\tAcc  87.43\tTime/batch 0.057\n",
      "Epoch: [27][ 949/1563]\tLoss   0.37\tAcc  87.44\tTime/batch 0.057\n",
      "Epoch: [27][ 999/1563]\tLoss   0.37\tAcc  87.40\tTime/batch 0.057\n",
      "Epoch: [27][1049/1563]\tLoss   0.37\tAcc  87.36\tTime/batch 0.057\n",
      "Epoch: [27][1099/1563]\tLoss   0.37\tAcc  87.38\tTime/batch 0.057\n",
      "Epoch: [27][1149/1563]\tLoss   0.37\tAcc  87.35\tTime/batch 0.057\n",
      "Epoch: [27][1199/1563]\tLoss   0.37\tAcc  87.33\tTime/batch 0.057\n",
      "Epoch: [27][1249/1563]\tLoss   0.37\tAcc  87.32\tTime/batch 0.057\n",
      "Epoch: [27][1299/1563]\tLoss   0.37\tAcc  87.33\tTime/batch 0.057\n",
      "Epoch: [27][1349/1563]\tLoss   0.37\tAcc  87.31\tTime/batch 0.057\n",
      "Epoch: [27][1399/1563]\tLoss   0.37\tAcc  87.29\tTime/batch 0.057\n",
      "Epoch: [27][1449/1563]\tLoss   0.37\tAcc  87.26\tTime/batch 0.057\n",
      "Epoch: [27][1499/1563]\tLoss   0.37\tAcc  87.26\tTime/batch 0.057\n",
      "Epoch: [27][1549/1563]\tLoss   0.37\tAcc  87.21\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [28][  49/1563]\tLoss   0.31\tAcc  89.56\tTime/batch 0.058\n",
      "Epoch: [28][  99/1563]\tLoss   0.34\tAcc  88.41\tTime/batch 0.058\n",
      "Epoch: [28][ 149/1563]\tLoss   0.34\tAcc  88.38\tTime/batch 0.057\n",
      "Epoch: [28][ 199/1563]\tLoss   0.34\tAcc  88.36\tTime/batch 0.057\n",
      "Epoch: [28][ 249/1563]\tLoss   0.34\tAcc  88.55\tTime/batch 0.057\n",
      "Epoch: [28][ 299/1563]\tLoss   0.34\tAcc  88.43\tTime/batch 0.057\n",
      "Epoch: [28][ 349/1563]\tLoss   0.34\tAcc  88.21\tTime/batch 0.057\n",
      "Epoch: [28][ 399/1563]\tLoss   0.35\tAcc  88.22\tTime/batch 0.057\n",
      "Epoch: [28][ 449/1563]\tLoss   0.35\tAcc  88.10\tTime/batch 0.057\n",
      "Epoch: [28][ 499/1563]\tLoss   0.36\tAcc  87.82\tTime/batch 0.057\n",
      "Epoch: [28][ 549/1563]\tLoss   0.36\tAcc  87.83\tTime/batch 0.057\n",
      "Epoch: [28][ 599/1563]\tLoss   0.36\tAcc  87.69\tTime/batch 0.057\n",
      "Epoch: [28][ 649/1563]\tLoss   0.36\tAcc  87.76\tTime/batch 0.057\n",
      "Epoch: [28][ 699/1563]\tLoss   0.36\tAcc  87.60\tTime/batch 0.057\n",
      "Epoch: [28][ 749/1563]\tLoss   0.36\tAcc  87.58\tTime/batch 0.057\n",
      "Epoch: [28][ 799/1563]\tLoss   0.36\tAcc  87.48\tTime/batch 0.057\n",
      "Epoch: [28][ 849/1563]\tLoss   0.36\tAcc  87.51\tTime/batch 0.057\n",
      "Epoch: [28][ 899/1563]\tLoss   0.36\tAcc  87.50\tTime/batch 0.057\n",
      "Epoch: [28][ 949/1563]\tLoss   0.37\tAcc  87.40\tTime/batch 0.057\n",
      "Epoch: [28][ 999/1563]\tLoss   0.37\tAcc  87.33\tTime/batch 0.057\n",
      "Epoch: [28][1049/1563]\tLoss   0.37\tAcc  87.31\tTime/batch 0.057\n",
      "Epoch: [28][1099/1563]\tLoss   0.37\tAcc  87.27\tTime/batch 0.057\n",
      "Epoch: [28][1149/1563]\tLoss   0.37\tAcc  87.30\tTime/batch 0.057\n",
      "Epoch: [28][1199/1563]\tLoss   0.37\tAcc  87.33\tTime/batch 0.057\n",
      "Epoch: [28][1249/1563]\tLoss   0.37\tAcc  87.39\tTime/batch 0.057\n",
      "Epoch: [28][1299/1563]\tLoss   0.37\tAcc  87.41\tTime/batch 0.057\n",
      "Epoch: [28][1349/1563]\tLoss   0.37\tAcc  87.40\tTime/batch 0.057\n",
      "Epoch: [28][1399/1563]\tLoss   0.37\tAcc  87.39\tTime/batch 0.057\n",
      "Epoch: [28][1449/1563]\tLoss   0.37\tAcc  87.37\tTime/batch 0.057\n",
      "Epoch: [28][1499/1563]\tLoss   0.37\tAcc  87.38\tTime/batch 0.057\n",
      "Epoch: [28][1549/1563]\tLoss   0.37\tAcc  87.35\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [29][  49/1563]\tLoss   0.35\tAcc  88.31\tTime/batch 0.058\n",
      "Epoch: [29][  99/1563]\tLoss   0.33\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [29][ 149/1563]\tLoss   0.34\tAcc  88.15\tTime/batch 0.057\n",
      "Epoch: [29][ 199/1563]\tLoss   0.33\tAcc  88.28\tTime/batch 0.057\n",
      "Epoch: [29][ 249/1563]\tLoss   0.35\tAcc  87.97\tTime/batch 0.057\n",
      "Epoch: [29][ 299/1563]\tLoss   0.35\tAcc  88.01\tTime/batch 0.057\n",
      "Epoch: [29][ 349/1563]\tLoss   0.35\tAcc  87.99\tTime/batch 0.057\n",
      "Epoch: [29][ 399/1563]\tLoss   0.35\tAcc  87.98\tTime/batch 0.057\n",
      "Epoch: [29][ 449/1563]\tLoss   0.36\tAcc  87.87\tTime/batch 0.057\n",
      "Epoch: [29][ 499/1563]\tLoss   0.36\tAcc  87.84\tTime/batch 0.057\n",
      "Epoch: [29][ 549/1563]\tLoss   0.36\tAcc  87.80\tTime/batch 0.057\n",
      "Epoch: [29][ 599/1563]\tLoss   0.36\tAcc  87.74\tTime/batch 0.057\n",
      "Epoch: [29][ 649/1563]\tLoss   0.36\tAcc  87.83\tTime/batch 0.057\n",
      "Epoch: [29][ 699/1563]\tLoss   0.36\tAcc  87.84\tTime/batch 0.057\n",
      "Epoch: [29][ 749/1563]\tLoss   0.36\tAcc  87.79\tTime/batch 0.057\n",
      "Epoch: [29][ 799/1563]\tLoss   0.36\tAcc  87.79\tTime/batch 0.057\n",
      "Epoch: [29][ 849/1563]\tLoss   0.36\tAcc  87.77\tTime/batch 0.057\n",
      "Epoch: [29][ 899/1563]\tLoss   0.36\tAcc  87.78\tTime/batch 0.057\n",
      "Epoch: [29][ 949/1563]\tLoss   0.36\tAcc  87.79\tTime/batch 0.057\n",
      "Epoch: [29][ 999/1563]\tLoss   0.36\tAcc  87.84\tTime/batch 0.057\n",
      "Epoch: [29][1049/1563]\tLoss   0.36\tAcc  87.86\tTime/batch 0.057\n",
      "Epoch: [29][1099/1563]\tLoss   0.36\tAcc  87.80\tTime/batch 0.057\n",
      "Epoch: [29][1149/1563]\tLoss   0.36\tAcc  87.73\tTime/batch 0.057\n",
      "Epoch: [29][1199/1563]\tLoss   0.36\tAcc  87.71\tTime/batch 0.057\n",
      "Epoch: [29][1249/1563]\tLoss   0.36\tAcc  87.76\tTime/batch 0.057\n",
      "Epoch: [29][1299/1563]\tLoss   0.36\tAcc  87.75\tTime/batch 0.057\n",
      "Epoch: [29][1349/1563]\tLoss   0.36\tAcc  87.77\tTime/batch 0.057\n",
      "Epoch: [29][1399/1563]\tLoss   0.36\tAcc  87.74\tTime/batch 0.057\n",
      "Epoch: [29][1449/1563]\tLoss   0.36\tAcc  87.72\tTime/batch 0.057\n",
      "Epoch: [29][1499/1563]\tLoss   0.36\tAcc  87.73\tTime/batch 0.057\n",
      "Epoch: [29][1549/1563]\tLoss   0.36\tAcc  87.73\tTime/batch 0.057\n",
      "current learning rate = 0.025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [30][  49/1563]\tLoss   0.34\tAcc  88.19\tTime/batch 0.057\n",
      "Epoch: [30][  99/1563]\tLoss   0.34\tAcc  88.47\tTime/batch 0.057\n",
      "Epoch: [30][ 149/1563]\tLoss   0.34\tAcc  88.35\tTime/batch 0.057\n",
      "Epoch: [30][ 199/1563]\tLoss   0.35\tAcc  88.16\tTime/batch 0.057\n",
      "Epoch: [30][ 249/1563]\tLoss   0.34\tAcc  88.20\tTime/batch 0.057\n",
      "Epoch: [30][ 299/1563]\tLoss   0.35\tAcc  87.99\tTime/batch 0.057\n",
      "Epoch: [30][ 349/1563]\tLoss   0.35\tAcc  87.99\tTime/batch 0.057\n",
      "Epoch: [30][ 399/1563]\tLoss   0.35\tAcc  87.81\tTime/batch 0.057\n",
      "Epoch: [30][ 449/1563]\tLoss   0.35\tAcc  87.86\tTime/batch 0.057\n",
      "Epoch: [30][ 499/1563]\tLoss   0.35\tAcc  87.80\tTime/batch 0.057\n",
      "Epoch: [30][ 549/1563]\tLoss   0.35\tAcc  87.88\tTime/batch 0.057\n",
      "Epoch: [30][ 599/1563]\tLoss   0.35\tAcc  87.90\tTime/batch 0.057\n",
      "Epoch: [30][ 649/1563]\tLoss   0.35\tAcc  87.83\tTime/batch 0.057\n",
      "Epoch: [30][ 699/1563]\tLoss   0.35\tAcc  87.87\tTime/batch 0.057\n",
      "Epoch: [30][ 749/1563]\tLoss   0.35\tAcc  87.78\tTime/batch 0.057\n",
      "Epoch: [30][ 799/1563]\tLoss   0.35\tAcc  87.68\tTime/batch 0.057\n",
      "Epoch: [30][ 849/1563]\tLoss   0.35\tAcc  87.67\tTime/batch 0.057\n",
      "Epoch: [30][ 899/1563]\tLoss   0.35\tAcc  87.74\tTime/batch 0.057\n",
      "Epoch: [30][ 949/1563]\tLoss   0.35\tAcc  87.81\tTime/batch 0.057\n",
      "Epoch: [30][ 999/1563]\tLoss   0.35\tAcc  87.82\tTime/batch 0.057\n",
      "Epoch: [30][1049/1563]\tLoss   0.35\tAcc  87.81\tTime/batch 0.057\n",
      "Epoch: [30][1099/1563]\tLoss   0.35\tAcc  87.84\tTime/batch 0.057\n",
      "Epoch: [30][1149/1563]\tLoss   0.35\tAcc  87.84\tTime/batch 0.057\n",
      "Epoch: [30][1199/1563]\tLoss   0.35\tAcc  87.78\tTime/batch 0.057\n",
      "Epoch: [30][1249/1563]\tLoss   0.35\tAcc  87.75\tTime/batch 0.057\n",
      "Epoch: [30][1299/1563]\tLoss   0.35\tAcc  87.76\tTime/batch 0.057\n",
      "Epoch: [30][1349/1563]\tLoss   0.35\tAcc  87.70\tTime/batch 0.057\n",
      "Epoch: [30][1399/1563]\tLoss   0.36\tAcc  87.64\tTime/batch 0.057\n",
      "Epoch: [30][1449/1563]\tLoss   0.36\tAcc  87.64\tTime/batch 0.057\n",
      "Epoch: [30][1499/1563]\tLoss   0.36\tAcc  87.60\tTime/batch 0.057\n",
      "Epoch: [30][1549/1563]\tLoss   0.36\tAcc  87.59\tTime/batch 0.057\n",
      "epoch 30\n",
      "Accuracy of the network on the 10000 test images: 85.2 %\n",
      "Sparsity of the update phase: 68.0 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [31][  49/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.058\n",
      "Epoch: [31][  99/1563]\tLoss   0.31\tAcc  89.19\tTime/batch 0.057\n",
      "Epoch: [31][ 149/1563]\tLoss   0.33\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [31][ 199/1563]\tLoss   0.34\tAcc  88.77\tTime/batch 0.057\n",
      "Epoch: [31][ 249/1563]\tLoss   0.34\tAcc  88.66\tTime/batch 0.057\n",
      "Epoch: [31][ 299/1563]\tLoss   0.34\tAcc  88.41\tTime/batch 0.057\n",
      "Epoch: [31][ 349/1563]\tLoss   0.35\tAcc  88.34\tTime/batch 0.057\n",
      "Epoch: [31][ 399/1563]\tLoss   0.34\tAcc  88.39\tTime/batch 0.057\n",
      "Epoch: [31][ 449/1563]\tLoss   0.34\tAcc  88.28\tTime/batch 0.057\n",
      "Epoch: [31][ 499/1563]\tLoss   0.34\tAcc  88.22\tTime/batch 0.057\n",
      "Epoch: [31][ 549/1563]\tLoss   0.34\tAcc  88.26\tTime/batch 0.057\n",
      "Epoch: [31][ 599/1563]\tLoss   0.34\tAcc  88.25\tTime/batch 0.057\n",
      "Epoch: [31][ 649/1563]\tLoss   0.34\tAcc  88.28\tTime/batch 0.057\n",
      "Epoch: [31][ 699/1563]\tLoss   0.34\tAcc  88.24\tTime/batch 0.057\n",
      "Epoch: [31][ 749/1563]\tLoss   0.34\tAcc  88.14\tTime/batch 0.057\n",
      "Epoch: [31][ 799/1563]\tLoss   0.34\tAcc  88.07\tTime/batch 0.057\n",
      "Epoch: [31][ 849/1563]\tLoss   0.35\tAcc  88.05\tTime/batch 0.057\n",
      "Epoch: [31][ 899/1563]\tLoss   0.35\tAcc  87.98\tTime/batch 0.057\n",
      "Epoch: [31][ 949/1563]\tLoss   0.35\tAcc  87.99\tTime/batch 0.057\n",
      "Epoch: [31][ 999/1563]\tLoss   0.35\tAcc  87.95\tTime/batch 0.057\n",
      "Epoch: [31][1049/1563]\tLoss   0.35\tAcc  87.93\tTime/batch 0.057\n",
      "Epoch: [31][1099/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [31][1149/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [31][1199/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [31][1249/1563]\tLoss   0.35\tAcc  87.86\tTime/batch 0.057\n",
      "Epoch: [31][1299/1563]\tLoss   0.35\tAcc  87.80\tTime/batch 0.058\n",
      "Epoch: [31][1349/1563]\tLoss   0.35\tAcc  87.77\tTime/batch 0.058\n",
      "Epoch: [31][1399/1563]\tLoss   0.35\tAcc  87.77\tTime/batch 0.058\n",
      "Epoch: [31][1449/1563]\tLoss   0.35\tAcc  87.76\tTime/batch 0.058\n",
      "Epoch: [31][1499/1563]\tLoss   0.35\tAcc  87.74\tTime/batch 0.058\n",
      "Epoch: [31][1549/1563]\tLoss   0.35\tAcc  87.73\tTime/batch 0.058\n",
      "current learning rate = 0.025\n",
      "Epoch: [32][  49/1563]\tLoss   0.36\tAcc  87.62\tTime/batch 0.058\n",
      "Epoch: [32][  99/1563]\tLoss   0.35\tAcc  88.12\tTime/batch 0.058\n",
      "Epoch: [32][ 149/1563]\tLoss   0.34\tAcc  88.29\tTime/batch 0.058\n",
      "Epoch: [32][ 199/1563]\tLoss   0.34\tAcc  88.19\tTime/batch 0.057\n",
      "Epoch: [32][ 249/1563]\tLoss   0.34\tAcc  88.30\tTime/batch 0.057\n",
      "Epoch: [32][ 299/1563]\tLoss   0.34\tAcc  88.33\tTime/batch 0.057\n",
      "Epoch: [32][ 349/1563]\tLoss   0.34\tAcc  88.25\tTime/batch 0.057\n",
      "Epoch: [32][ 399/1563]\tLoss   0.34\tAcc  88.17\tTime/batch 0.057\n",
      "Epoch: [32][ 449/1563]\tLoss   0.34\tAcc  88.10\tTime/batch 0.057\n",
      "Epoch: [32][ 499/1563]\tLoss   0.34\tAcc  88.09\tTime/batch 0.057\n",
      "Epoch: [32][ 549/1563]\tLoss   0.34\tAcc  88.09\tTime/batch 0.057\n",
      "Epoch: [32][ 599/1563]\tLoss   0.34\tAcc  88.12\tTime/batch 0.057\n",
      "Epoch: [32][ 649/1563]\tLoss   0.34\tAcc  88.10\tTime/batch 0.057\n",
      "Epoch: [32][ 699/1563]\tLoss   0.34\tAcc  88.04\tTime/batch 0.057\n",
      "Epoch: [32][ 749/1563]\tLoss   0.34\tAcc  88.08\tTime/batch 0.057\n",
      "Epoch: [32][ 799/1563]\tLoss   0.34\tAcc  88.04\tTime/batch 0.057\n",
      "Epoch: [32][ 849/1563]\tLoss   0.35\tAcc  88.06\tTime/batch 0.057\n",
      "Epoch: [32][ 899/1563]\tLoss   0.35\tAcc  87.99\tTime/batch 0.057\n",
      "Epoch: [32][ 949/1563]\tLoss   0.35\tAcc  88.02\tTime/batch 0.057\n",
      "Epoch: [32][ 999/1563]\tLoss   0.35\tAcc  88.02\tTime/batch 0.057\n",
      "Epoch: [32][1049/1563]\tLoss   0.35\tAcc  88.01\tTime/batch 0.057\n",
      "Epoch: [32][1099/1563]\tLoss   0.35\tAcc  87.94\tTime/batch 0.057\n",
      "Epoch: [32][1149/1563]\tLoss   0.35\tAcc  87.93\tTime/batch 0.057\n",
      "Epoch: [32][1199/1563]\tLoss   0.35\tAcc  87.92\tTime/batch 0.057\n",
      "Epoch: [32][1249/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [32][1299/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [32][1349/1563]\tLoss   0.35\tAcc  87.92\tTime/batch 0.057\n",
      "Epoch: [32][1399/1563]\tLoss   0.35\tAcc  87.90\tTime/batch 0.057\n",
      "Epoch: [32][1449/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [32][1499/1563]\tLoss   0.35\tAcc  87.88\tTime/batch 0.057\n",
      "Epoch: [32][1549/1563]\tLoss   0.35\tAcc  87.87\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [33][  49/1563]\tLoss   0.33\tAcc  89.19\tTime/batch 0.057\n",
      "Epoch: [33][  99/1563]\tLoss   0.32\tAcc  89.25\tTime/batch 0.057\n",
      "Epoch: [33][ 149/1563]\tLoss   0.33\tAcc  89.17\tTime/batch 0.057\n",
      "Epoch: [33][ 199/1563]\tLoss   0.33\tAcc  88.97\tTime/batch 0.056\n",
      "Epoch: [33][ 249/1563]\tLoss   0.33\tAcc  88.90\tTime/batch 0.056\n",
      "Epoch: [33][ 299/1563]\tLoss   0.33\tAcc  88.71\tTime/batch 0.056\n",
      "Epoch: [33][ 349/1563]\tLoss   0.33\tAcc  88.46\tTime/batch 0.056\n",
      "Epoch: [33][ 399/1563]\tLoss   0.34\tAcc  88.35\tTime/batch 0.056\n",
      "Epoch: [33][ 449/1563]\tLoss   0.34\tAcc  88.48\tTime/batch 0.056\n",
      "Epoch: [33][ 499/1563]\tLoss   0.34\tAcc  88.40\tTime/batch 0.056\n",
      "Epoch: [33][ 549/1563]\tLoss   0.34\tAcc  88.23\tTime/batch 0.056\n",
      "Epoch: [33][ 599/1563]\tLoss   0.34\tAcc  88.14\tTime/batch 0.056\n",
      "Epoch: [33][ 649/1563]\tLoss   0.35\tAcc  88.00\tTime/batch 0.056\n",
      "Epoch: [33][ 699/1563]\tLoss   0.35\tAcc  88.03\tTime/batch 0.056\n",
      "Epoch: [33][ 749/1563]\tLoss   0.35\tAcc  88.00\tTime/batch 0.056\n",
      "Epoch: [33][ 799/1563]\tLoss   0.35\tAcc  87.98\tTime/batch 0.056\n",
      "Epoch: [33][ 849/1563]\tLoss   0.35\tAcc  88.00\tTime/batch 0.056\n",
      "Epoch: [33][ 899/1563]\tLoss   0.35\tAcc  87.98\tTime/batch 0.056\n",
      "Epoch: [33][ 949/1563]\tLoss   0.35\tAcc  87.96\tTime/batch 0.056\n",
      "Epoch: [33][ 999/1563]\tLoss   0.35\tAcc  87.97\tTime/batch 0.056\n",
      "Epoch: [33][1049/1563]\tLoss   0.34\tAcc  87.99\tTime/batch 0.056\n",
      "Epoch: [33][1099/1563]\tLoss   0.35\tAcc  87.92\tTime/batch 0.057\n",
      "Epoch: [33][1149/1563]\tLoss   0.35\tAcc  87.92\tTime/batch 0.057\n",
      "Epoch: [33][1199/1563]\tLoss   0.35\tAcc  87.84\tTime/batch 0.057\n",
      "Epoch: [33][1249/1563]\tLoss   0.35\tAcc  87.89\tTime/batch 0.057\n",
      "Epoch: [33][1299/1563]\tLoss   0.35\tAcc  87.94\tTime/batch 0.057\n",
      "Epoch: [33][1349/1563]\tLoss   0.35\tAcc  87.94\tTime/batch 0.057\n",
      "Epoch: [33][1399/1563]\tLoss   0.35\tAcc  87.92\tTime/batch 0.057\n",
      "Epoch: [33][1449/1563]\tLoss   0.35\tAcc  87.98\tTime/batch 0.057\n",
      "Epoch: [33][1499/1563]\tLoss   0.35\tAcc  87.98\tTime/batch 0.057\n",
      "Epoch: [33][1549/1563]\tLoss   0.35\tAcc  87.97\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [34][  49/1563]\tLoss   0.36\tAcc  87.25\tTime/batch 0.058\n",
      "Epoch: [34][  99/1563]\tLoss   0.35\tAcc  87.56\tTime/batch 0.058\n",
      "Epoch: [34][ 149/1563]\tLoss   0.35\tAcc  87.96\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [34][ 199/1563]\tLoss   0.34\tAcc  88.41\tTime/batch 0.057\n",
      "Epoch: [34][ 249/1563]\tLoss   0.34\tAcc  88.17\tTime/batch 0.057\n",
      "Epoch: [34][ 299/1563]\tLoss   0.34\tAcc  88.30\tTime/batch 0.057\n",
      "Epoch: [34][ 349/1563]\tLoss   0.33\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [34][ 399/1563]\tLoss   0.33\tAcc  88.44\tTime/batch 0.057\n",
      "Epoch: [34][ 449/1563]\tLoss   0.33\tAcc  88.39\tTime/batch 0.057\n",
      "Epoch: [34][ 499/1563]\tLoss   0.34\tAcc  88.36\tTime/batch 0.057\n",
      "Epoch: [34][ 549/1563]\tLoss   0.34\tAcc  88.34\tTime/batch 0.057\n",
      "Epoch: [34][ 599/1563]\tLoss   0.34\tAcc  88.39\tTime/batch 0.057\n",
      "Epoch: [34][ 649/1563]\tLoss   0.34\tAcc  88.36\tTime/batch 0.057\n",
      "Epoch: [34][ 699/1563]\tLoss   0.34\tAcc  88.45\tTime/batch 0.057\n",
      "Epoch: [34][ 749/1563]\tLoss   0.34\tAcc  88.43\tTime/batch 0.057\n",
      "Epoch: [34][ 799/1563]\tLoss   0.34\tAcc  88.36\tTime/batch 0.057\n",
      "Epoch: [34][ 849/1563]\tLoss   0.34\tAcc  88.31\tTime/batch 0.057\n",
      "Epoch: [34][ 899/1563]\tLoss   0.34\tAcc  88.27\tTime/batch 0.057\n",
      "Epoch: [34][ 949/1563]\tLoss   0.34\tAcc  88.27\tTime/batch 0.057\n",
      "Epoch: [34][ 999/1563]\tLoss   0.34\tAcc  88.25\tTime/batch 0.057\n",
      "Epoch: [34][1049/1563]\tLoss   0.34\tAcc  88.15\tTime/batch 0.057\n",
      "Epoch: [34][1099/1563]\tLoss   0.34\tAcc  88.11\tTime/batch 0.057\n",
      "Epoch: [34][1149/1563]\tLoss   0.34\tAcc  88.14\tTime/batch 0.057\n",
      "Epoch: [34][1199/1563]\tLoss   0.34\tAcc  88.17\tTime/batch 0.057\n",
      "Epoch: [34][1249/1563]\tLoss   0.34\tAcc  88.13\tTime/batch 0.057\n",
      "Epoch: [34][1299/1563]\tLoss   0.34\tAcc  88.10\tTime/batch 0.057\n",
      "Epoch: [34][1349/1563]\tLoss   0.34\tAcc  88.06\tTime/batch 0.057\n",
      "Epoch: [34][1399/1563]\tLoss   0.34\tAcc  88.11\tTime/batch 0.057\n",
      "Epoch: [34][1449/1563]\tLoss   0.34\tAcc  88.11\tTime/batch 0.057\n",
      "Epoch: [34][1499/1563]\tLoss   0.34\tAcc  88.14\tTime/batch 0.057\n",
      "Epoch: [34][1549/1563]\tLoss   0.34\tAcc  88.11\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [35][  49/1563]\tLoss   0.34\tAcc  87.75\tTime/batch 0.057\n",
      "Epoch: [35][  99/1563]\tLoss   0.33\tAcc  87.94\tTime/batch 0.057\n",
      "Epoch: [35][ 149/1563]\tLoss   0.32\tAcc  88.56\tTime/batch 0.056\n",
      "Epoch: [35][ 199/1563]\tLoss   0.32\tAcc  88.58\tTime/batch 0.056\n",
      "Epoch: [35][ 249/1563]\tLoss   0.32\tAcc  88.69\tTime/batch 0.056\n",
      "Epoch: [35][ 299/1563]\tLoss   0.33\tAcc  88.49\tTime/batch 0.056\n",
      "Epoch: [35][ 349/1563]\tLoss   0.33\tAcc  88.40\tTime/batch 0.056\n",
      "Epoch: [35][ 399/1563]\tLoss   0.33\tAcc  88.42\tTime/batch 0.056\n",
      "Epoch: [35][ 449/1563]\tLoss   0.33\tAcc  88.31\tTime/batch 0.056\n",
      "Epoch: [35][ 499/1563]\tLoss   0.33\tAcc  88.40\tTime/batch 0.056\n",
      "Epoch: [35][ 549/1563]\tLoss   0.34\tAcc  88.38\tTime/batch 0.056\n",
      "Epoch: [35][ 599/1563]\tLoss   0.33\tAcc  88.45\tTime/batch 0.056\n",
      "Epoch: [35][ 649/1563]\tLoss   0.33\tAcc  88.41\tTime/batch 0.056\n",
      "Epoch: [35][ 699/1563]\tLoss   0.33\tAcc  88.40\tTime/batch 0.056\n",
      "Epoch: [35][ 749/1563]\tLoss   0.34\tAcc  88.43\tTime/batch 0.056\n",
      "Epoch: [35][ 799/1563]\tLoss   0.34\tAcc  88.39\tTime/batch 0.056\n",
      "Epoch: [35][ 849/1563]\tLoss   0.34\tAcc  88.48\tTime/batch 0.057\n",
      "Epoch: [35][ 899/1563]\tLoss   0.34\tAcc  88.41\tTime/batch 0.057\n",
      "Epoch: [35][ 949/1563]\tLoss   0.34\tAcc  88.41\tTime/batch 0.057\n",
      "Epoch: [35][ 999/1563]\tLoss   0.34\tAcc  88.37\tTime/batch 0.057\n",
      "Epoch: [35][1049/1563]\tLoss   0.34\tAcc  88.35\tTime/batch 0.057\n",
      "Epoch: [35][1099/1563]\tLoss   0.33\tAcc  88.44\tTime/batch 0.057\n",
      "Epoch: [35][1149/1563]\tLoss   0.34\tAcc  88.44\tTime/batch 0.057\n",
      "Epoch: [35][1199/1563]\tLoss   0.34\tAcc  88.39\tTime/batch 0.057\n",
      "Epoch: [35][1249/1563]\tLoss   0.34\tAcc  88.38\tTime/batch 0.057\n",
      "Epoch: [35][1299/1563]\tLoss   0.34\tAcc  88.38\tTime/batch 0.057\n",
      "Epoch: [35][1349/1563]\tLoss   0.33\tAcc  88.40\tTime/batch 0.057\n",
      "Epoch: [35][1399/1563]\tLoss   0.33\tAcc  88.48\tTime/batch 0.057\n",
      "Epoch: [35][1449/1563]\tLoss   0.33\tAcc  88.47\tTime/batch 0.057\n",
      "Epoch: [35][1499/1563]\tLoss   0.33\tAcc  88.46\tTime/batch 0.057\n",
      "Epoch: [35][1549/1563]\tLoss   0.33\tAcc  88.44\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [36][  49/1563]\tLoss   0.34\tAcc  88.94\tTime/batch 0.058\n",
      "Epoch: [36][  99/1563]\tLoss   0.33\tAcc  88.50\tTime/batch 0.058\n",
      "Epoch: [36][ 149/1563]\tLoss   0.34\tAcc  88.48\tTime/batch 0.057\n",
      "Epoch: [36][ 199/1563]\tLoss   0.34\tAcc  88.19\tTime/batch 0.057\n",
      "Epoch: [36][ 249/1563]\tLoss   0.34\tAcc  88.25\tTime/batch 0.057\n",
      "Epoch: [36][ 299/1563]\tLoss   0.33\tAcc  88.35\tTime/batch 0.057\n",
      "Epoch: [36][ 349/1563]\tLoss   0.33\tAcc  88.65\tTime/batch 0.057\n",
      "Epoch: [36][ 399/1563]\tLoss   0.33\tAcc  88.74\tTime/batch 0.057\n",
      "Epoch: [36][ 449/1563]\tLoss   0.33\tAcc  88.71\tTime/batch 0.057\n",
      "Epoch: [36][ 499/1563]\tLoss   0.33\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [36][ 549/1563]\tLoss   0.33\tAcc  88.85\tTime/batch 0.057\n",
      "Epoch: [36][ 599/1563]\tLoss   0.33\tAcc  88.86\tTime/batch 0.057\n",
      "Epoch: [36][ 649/1563]\tLoss   0.33\tAcc  88.68\tTime/batch 0.057\n",
      "Epoch: [36][ 699/1563]\tLoss   0.33\tAcc  88.71\tTime/batch 0.057\n",
      "Epoch: [36][ 749/1563]\tLoss   0.33\tAcc  88.64\tTime/batch 0.057\n",
      "Epoch: [36][ 799/1563]\tLoss   0.33\tAcc  88.68\tTime/batch 0.057\n",
      "Epoch: [36][ 849/1563]\tLoss   0.33\tAcc  88.68\tTime/batch 0.057\n",
      "Epoch: [36][ 899/1563]\tLoss   0.33\tAcc  88.63\tTime/batch 0.057\n",
      "Epoch: [36][ 949/1563]\tLoss   0.33\tAcc  88.71\tTime/batch 0.057\n",
      "Epoch: [36][ 999/1563]\tLoss   0.33\tAcc  88.65\tTime/batch 0.056\n",
      "Epoch: [36][1049/1563]\tLoss   0.33\tAcc  88.68\tTime/batch 0.056\n",
      "Epoch: [36][1099/1563]\tLoss   0.33\tAcc  88.62\tTime/batch 0.056\n",
      "Epoch: [36][1149/1563]\tLoss   0.33\tAcc  88.63\tTime/batch 0.056\n",
      "Epoch: [36][1199/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.056\n",
      "Epoch: [36][1249/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.056\n",
      "Epoch: [36][1299/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.056\n",
      "Epoch: [36][1349/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.056\n",
      "Epoch: [36][1399/1563]\tLoss   0.33\tAcc  88.57\tTime/batch 0.056\n",
      "Epoch: [36][1449/1563]\tLoss   0.33\tAcc  88.53\tTime/batch 0.056\n",
      "Epoch: [36][1499/1563]\tLoss   0.33\tAcc  88.47\tTime/batch 0.056\n",
      "Epoch: [36][1549/1563]\tLoss   0.34\tAcc  88.44\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [37][  49/1563]\tLoss   0.32\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [37][  99/1563]\tLoss   0.32\tAcc  88.97\tTime/batch 0.057\n",
      "Epoch: [37][ 149/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [37][ 199/1563]\tLoss   0.32\tAcc  88.97\tTime/batch 0.057\n",
      "Epoch: [37][ 249/1563]\tLoss   0.32\tAcc  88.83\tTime/batch 0.057\n",
      "Epoch: [37][ 299/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [37][ 349/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [37][ 399/1563]\tLoss   0.33\tAcc  88.69\tTime/batch 0.057\n",
      "Epoch: [37][ 449/1563]\tLoss   0.34\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [37][ 499/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.056\n",
      "Epoch: [37][ 549/1563]\tLoss   0.33\tAcc  88.64\tTime/batch 0.056\n",
      "Epoch: [37][ 599/1563]\tLoss   0.33\tAcc  88.72\tTime/batch 0.056\n",
      "Epoch: [37][ 649/1563]\tLoss   0.33\tAcc  88.69\tTime/batch 0.056\n",
      "Epoch: [37][ 699/1563]\tLoss   0.33\tAcc  88.67\tTime/batch 0.057\n",
      "Epoch: [37][ 749/1563]\tLoss   0.33\tAcc  88.65\tTime/batch 0.057\n",
      "Epoch: [37][ 799/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [37][ 849/1563]\tLoss   0.33\tAcc  88.58\tTime/batch 0.057\n",
      "Epoch: [37][ 899/1563]\tLoss   0.33\tAcc  88.62\tTime/batch 0.057\n",
      "Epoch: [37][ 949/1563]\tLoss   0.33\tAcc  88.63\tTime/batch 0.057\n",
      "Epoch: [37][ 999/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [37][1049/1563]\tLoss   0.33\tAcc  88.59\tTime/batch 0.057\n",
      "Epoch: [37][1099/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [37][1149/1563]\tLoss   0.33\tAcc  88.58\tTime/batch 0.057\n",
      "Epoch: [37][1199/1563]\tLoss   0.33\tAcc  88.59\tTime/batch 0.057\n",
      "Epoch: [37][1249/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.057\n",
      "Epoch: [37][1299/1563]\tLoss   0.33\tAcc  88.55\tTime/batch 0.057\n",
      "Epoch: [37][1349/1563]\tLoss   0.33\tAcc  88.54\tTime/batch 0.057\n",
      "Epoch: [37][1399/1563]\tLoss   0.33\tAcc  88.52\tTime/batch 0.057\n",
      "Epoch: [37][1449/1563]\tLoss   0.33\tAcc  88.50\tTime/batch 0.057\n",
      "Epoch: [37][1499/1563]\tLoss   0.33\tAcc  88.49\tTime/batch 0.057\n",
      "Epoch: [37][1549/1563]\tLoss   0.33\tAcc  88.49\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [38][  49/1563]\tLoss   0.32\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [38][  99/1563]\tLoss   0.34\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [38][ 149/1563]\tLoss   0.32\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [38][ 199/1563]\tLoss   0.32\tAcc  88.84\tTime/batch 0.057\n",
      "Epoch: [38][ 249/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "Epoch: [38][ 299/1563]\tLoss   0.32\tAcc  88.99\tTime/batch 0.057\n",
      "Epoch: [38][ 349/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [38][ 399/1563]\tLoss   0.33\tAcc  88.74\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [38][ 449/1563]\tLoss   0.33\tAcc  88.65\tTime/batch 0.057\n",
      "Epoch: [38][ 499/1563]\tLoss   0.33\tAcc  88.76\tTime/batch 0.057\n",
      "Epoch: [38][ 549/1563]\tLoss   0.32\tAcc  88.80\tTime/batch 0.057\n",
      "Epoch: [38][ 599/1563]\tLoss   0.32\tAcc  88.73\tTime/batch 0.057\n",
      "Epoch: [38][ 649/1563]\tLoss   0.32\tAcc  88.74\tTime/batch 0.057\n",
      "Epoch: [38][ 699/1563]\tLoss   0.33\tAcc  88.74\tTime/batch 0.057\n",
      "Epoch: [38][ 749/1563]\tLoss   0.33\tAcc  88.54\tTime/batch 0.057\n",
      "Epoch: [38][ 799/1563]\tLoss   0.33\tAcc  88.59\tTime/batch 0.057\n",
      "Epoch: [38][ 849/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [38][ 899/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.057\n",
      "Epoch: [38][ 949/1563]\tLoss   0.33\tAcc  88.57\tTime/batch 0.057\n",
      "Epoch: [38][ 999/1563]\tLoss   0.33\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [38][1049/1563]\tLoss   0.33\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [38][1099/1563]\tLoss   0.33\tAcc  88.59\tTime/batch 0.057\n",
      "Epoch: [38][1149/1563]\tLoss   0.33\tAcc  88.62\tTime/batch 0.057\n",
      "Epoch: [38][1199/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [38][1249/1563]\tLoss   0.33\tAcc  88.62\tTime/batch 0.057\n",
      "Epoch: [38][1299/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [38][1349/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [38][1399/1563]\tLoss   0.33\tAcc  88.62\tTime/batch 0.056\n",
      "Epoch: [38][1449/1563]\tLoss   0.33\tAcc  88.59\tTime/batch 0.056\n",
      "Epoch: [38][1499/1563]\tLoss   0.33\tAcc  88.59\tTime/batch 0.056\n",
      "Epoch: [38][1549/1563]\tLoss   0.33\tAcc  88.60\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [39][  49/1563]\tLoss   0.33\tAcc  88.94\tTime/batch 0.058\n",
      "Epoch: [39][  99/1563]\tLoss   0.32\tAcc  89.06\tTime/batch 0.057\n",
      "Epoch: [39][ 149/1563]\tLoss   0.31\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [39][ 199/1563]\tLoss   0.31\tAcc  89.34\tTime/batch 0.057\n",
      "Epoch: [39][ 249/1563]\tLoss   0.31\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [39][ 299/1563]\tLoss   0.31\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [39][ 349/1563]\tLoss   0.31\tAcc  89.38\tTime/batch 0.057\n",
      "Epoch: [39][ 399/1563]\tLoss   0.32\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [39][ 449/1563]\tLoss   0.32\tAcc  89.06\tTime/batch 0.057\n",
      "Epoch: [39][ 499/1563]\tLoss   0.32\tAcc  89.08\tTime/batch 0.057\n",
      "Epoch: [39][ 549/1563]\tLoss   0.32\tAcc  89.03\tTime/batch 0.057\n",
      "Epoch: [39][ 599/1563]\tLoss   0.32\tAcc  89.04\tTime/batch 0.057\n",
      "Epoch: [39][ 649/1563]\tLoss   0.32\tAcc  88.99\tTime/batch 0.057\n",
      "Epoch: [39][ 699/1563]\tLoss   0.32\tAcc  89.07\tTime/batch 0.057\n",
      "Epoch: [39][ 749/1563]\tLoss   0.32\tAcc  89.13\tTime/batch 0.057\n",
      "Epoch: [39][ 799/1563]\tLoss   0.32\tAcc  89.23\tTime/batch 0.057\n",
      "Epoch: [39][ 849/1563]\tLoss   0.32\tAcc  89.15\tTime/batch 0.057\n",
      "Epoch: [39][ 899/1563]\tLoss   0.32\tAcc  89.10\tTime/batch 0.057\n",
      "Epoch: [39][ 949/1563]\tLoss   0.32\tAcc  89.08\tTime/batch 0.057\n",
      "Epoch: [39][ 999/1563]\tLoss   0.32\tAcc  89.08\tTime/batch 0.057\n",
      "Epoch: [39][1049/1563]\tLoss   0.32\tAcc  89.03\tTime/batch 0.057\n",
      "Epoch: [39][1099/1563]\tLoss   0.32\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [39][1149/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [39][1199/1563]\tLoss   0.32\tAcc  88.88\tTime/batch 0.057\n",
      "Epoch: [39][1249/1563]\tLoss   0.32\tAcc  88.88\tTime/batch 0.057\n",
      "Epoch: [39][1299/1563]\tLoss   0.32\tAcc  88.82\tTime/batch 0.057\n",
      "Epoch: [39][1349/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [39][1399/1563]\tLoss   0.32\tAcc  88.78\tTime/batch 0.057\n",
      "Epoch: [39][1449/1563]\tLoss   0.32\tAcc  88.76\tTime/batch 0.057\n",
      "Epoch: [39][1499/1563]\tLoss   0.32\tAcc  88.76\tTime/batch 0.057\n",
      "Epoch: [39][1549/1563]\tLoss   0.32\tAcc  88.76\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [40][  49/1563]\tLoss   0.32\tAcc  88.25\tTime/batch 0.057\n",
      "Epoch: [40][  99/1563]\tLoss   0.31\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [40][ 149/1563]\tLoss   0.32\tAcc  88.79\tTime/batch 0.057\n",
      "Epoch: [40][ 199/1563]\tLoss   0.33\tAcc  88.17\tTime/batch 0.056\n",
      "Epoch: [40][ 249/1563]\tLoss   0.33\tAcc  88.39\tTime/batch 0.056\n",
      "Epoch: [40][ 299/1563]\tLoss   0.33\tAcc  88.46\tTime/batch 0.056\n",
      "Epoch: [40][ 349/1563]\tLoss   0.33\tAcc  88.58\tTime/batch 0.056\n",
      "Epoch: [40][ 399/1563]\tLoss   0.32\tAcc  88.73\tTime/batch 0.056\n",
      "Epoch: [40][ 449/1563]\tLoss   0.33\tAcc  88.51\tTime/batch 0.056\n",
      "Epoch: [40][ 499/1563]\tLoss   0.33\tAcc  88.50\tTime/batch 0.056\n",
      "Epoch: [40][ 549/1563]\tLoss   0.33\tAcc  88.52\tTime/batch 0.056\n",
      "Epoch: [40][ 599/1563]\tLoss   0.33\tAcc  88.58\tTime/batch 0.056\n",
      "Epoch: [40][ 649/1563]\tLoss   0.33\tAcc  88.66\tTime/batch 0.056\n",
      "Epoch: [40][ 699/1563]\tLoss   0.33\tAcc  88.72\tTime/batch 0.056\n",
      "Epoch: [40][ 749/1563]\tLoss   0.33\tAcc  88.62\tTime/batch 0.056\n",
      "Epoch: [40][ 799/1563]\tLoss   0.33\tAcc  88.71\tTime/batch 0.056\n",
      "Epoch: [40][ 849/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.056\n",
      "Epoch: [40][ 899/1563]\tLoss   0.33\tAcc  88.53\tTime/batch 0.056\n",
      "Epoch: [40][ 949/1563]\tLoss   0.33\tAcc  88.50\tTime/batch 0.056\n",
      "Epoch: [40][ 999/1563]\tLoss   0.33\tAcc  88.52\tTime/batch 0.056\n",
      "Epoch: [40][1049/1563]\tLoss   0.33\tAcc  88.48\tTime/batch 0.056\n",
      "Epoch: [40][1099/1563]\tLoss   0.33\tAcc  88.53\tTime/batch 0.056\n",
      "Epoch: [40][1149/1563]\tLoss   0.33\tAcc  88.56\tTime/batch 0.056\n",
      "Epoch: [40][1199/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.056\n",
      "Epoch: [40][1249/1563]\tLoss   0.33\tAcc  88.63\tTime/batch 0.056\n",
      "Epoch: [40][1299/1563]\tLoss   0.33\tAcc  88.68\tTime/batch 0.056\n",
      "Epoch: [40][1349/1563]\tLoss   0.33\tAcc  88.69\tTime/batch 0.056\n",
      "Epoch: [40][1399/1563]\tLoss   0.33\tAcc  88.65\tTime/batch 0.056\n",
      "Epoch: [40][1449/1563]\tLoss   0.33\tAcc  88.61\tTime/batch 0.056\n",
      "Epoch: [40][1499/1563]\tLoss   0.33\tAcc  88.56\tTime/batch 0.056\n",
      "Epoch: [40][1549/1563]\tLoss   0.33\tAcc  88.51\tTime/batch 0.056\n",
      "epoch 40\n",
      "Accuracy of the network on the 10000 test images: 86.0 %\n",
      "Sparsity of the update phase: 67.7 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [41][  49/1563]\tLoss   0.32\tAcc  89.75\tTime/batch 0.058\n",
      "Epoch: [41][  99/1563]\tLoss   0.33\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [41][ 149/1563]\tLoss   0.33\tAcc  89.04\tTime/batch 0.057\n",
      "Epoch: [41][ 199/1563]\tLoss   0.32\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [41][ 249/1563]\tLoss   0.32\tAcc  89.16\tTime/batch 0.057\n",
      "Epoch: [41][ 299/1563]\tLoss   0.32\tAcc  89.11\tTime/batch 0.057\n",
      "Epoch: [41][ 349/1563]\tLoss   0.32\tAcc  89.08\tTime/batch 0.057\n",
      "Epoch: [41][ 399/1563]\tLoss   0.32\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [41][ 449/1563]\tLoss   0.32\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [41][ 499/1563]\tLoss   0.32\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [41][ 549/1563]\tLoss   0.32\tAcc  89.14\tTime/batch 0.057\n",
      "Epoch: [41][ 599/1563]\tLoss   0.32\tAcc  88.90\tTime/batch 0.057\n",
      "Epoch: [41][ 649/1563]\tLoss   0.32\tAcc  88.93\tTime/batch 0.057\n",
      "Epoch: [41][ 699/1563]\tLoss   0.32\tAcc  88.88\tTime/batch 0.057\n",
      "Epoch: [41][ 749/1563]\tLoss   0.32\tAcc  88.78\tTime/batch 0.057\n",
      "Epoch: [41][ 799/1563]\tLoss   0.32\tAcc  88.82\tTime/batch 0.057\n",
      "Epoch: [41][ 849/1563]\tLoss   0.32\tAcc  88.76\tTime/batch 0.057\n",
      "Epoch: [41][ 899/1563]\tLoss   0.32\tAcc  88.82\tTime/batch 0.057\n",
      "Epoch: [41][ 949/1563]\tLoss   0.32\tAcc  88.82\tTime/batch 0.057\n",
      "Epoch: [41][ 999/1563]\tLoss   0.32\tAcc  88.87\tTime/batch 0.057\n",
      "Epoch: [41][1049/1563]\tLoss   0.32\tAcc  88.76\tTime/batch 0.057\n",
      "Epoch: [41][1099/1563]\tLoss   0.32\tAcc  88.75\tTime/batch 0.057\n",
      "Epoch: [41][1149/1563]\tLoss   0.32\tAcc  88.77\tTime/batch 0.057\n",
      "Epoch: [41][1199/1563]\tLoss   0.32\tAcc  88.73\tTime/batch 0.057\n",
      "Epoch: [41][1249/1563]\tLoss   0.32\tAcc  88.72\tTime/batch 0.057\n",
      "Epoch: [41][1299/1563]\tLoss   0.32\tAcc  88.69\tTime/batch 0.057\n",
      "Epoch: [41][1349/1563]\tLoss   0.32\tAcc  88.71\tTime/batch 0.057\n",
      "Epoch: [41][1399/1563]\tLoss   0.33\tAcc  88.67\tTime/batch 0.057\n",
      "Epoch: [41][1449/1563]\tLoss   0.33\tAcc  88.66\tTime/batch 0.057\n",
      "Epoch: [41][1499/1563]\tLoss   0.33\tAcc  88.67\tTime/batch 0.057\n",
      "Epoch: [41][1549/1563]\tLoss   0.32\tAcc  88.67\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [42][  49/1563]\tLoss   0.30\tAcc  88.94\tTime/batch 0.058\n",
      "Epoch: [42][  99/1563]\tLoss   0.30\tAcc  89.31\tTime/batch 0.058\n",
      "Epoch: [42][ 149/1563]\tLoss   0.30\tAcc  89.17\tTime/batch 0.057\n",
      "Epoch: [42][ 199/1563]\tLoss   0.30\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [42][ 249/1563]\tLoss   0.30\tAcc  89.38\tTime/batch 0.057\n",
      "Epoch: [42][ 299/1563]\tLoss   0.29\tAcc  89.59\tTime/batch 0.057\n",
      "Epoch: [42][ 349/1563]\tLoss   0.29\tAcc  89.66\tTime/batch 0.057\n",
      "Epoch: [42][ 399/1563]\tLoss   0.29\tAcc  89.65\tTime/batch 0.057\n",
      "Epoch: [42][ 449/1563]\tLoss   0.30\tAcc  89.56\tTime/batch 0.057\n",
      "Epoch: [42][ 499/1563]\tLoss   0.30\tAcc  89.39\tTime/batch 0.057\n",
      "Epoch: [42][ 549/1563]\tLoss   0.31\tAcc  89.31\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [42][ 599/1563]\tLoss   0.31\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [42][ 649/1563]\tLoss   0.31\tAcc  89.15\tTime/batch 0.057\n",
      "Epoch: [42][ 699/1563]\tLoss   0.31\tAcc  89.10\tTime/batch 0.057\n",
      "Epoch: [42][ 749/1563]\tLoss   0.31\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [42][ 799/1563]\tLoss   0.32\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [42][ 849/1563]\tLoss   0.32\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [42][ 899/1563]\tLoss   0.32\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [42][ 949/1563]\tLoss   0.32\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [42][ 999/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [42][1049/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "Epoch: [42][1099/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [42][1149/1563]\tLoss   0.32\tAcc  88.93\tTime/batch 0.057\n",
      "Epoch: [42][1199/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "Epoch: [42][1249/1563]\tLoss   0.32\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [42][1299/1563]\tLoss   0.32\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [42][1349/1563]\tLoss   0.32\tAcc  89.02\tTime/batch 0.057\n",
      "Epoch: [42][1399/1563]\tLoss   0.32\tAcc  89.02\tTime/batch 0.057\n",
      "Epoch: [42][1449/1563]\tLoss   0.32\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [42][1499/1563]\tLoss   0.32\tAcc  88.96\tTime/batch 0.057\n",
      "Epoch: [42][1549/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [43][  49/1563]\tLoss   0.31\tAcc  88.75\tTime/batch 0.057\n",
      "Epoch: [43][  99/1563]\tLoss   0.31\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [43][ 149/1563]\tLoss   0.32\tAcc  88.54\tTime/batch 0.057\n",
      "Epoch: [43][ 199/1563]\tLoss   0.32\tAcc  88.39\tTime/batch 0.057\n",
      "Epoch: [43][ 249/1563]\tLoss   0.32\tAcc  88.64\tTime/batch 0.057\n",
      "Epoch: [43][ 299/1563]\tLoss   0.32\tAcc  88.76\tTime/batch 0.057\n",
      "Epoch: [43][ 349/1563]\tLoss   0.32\tAcc  88.87\tTime/batch 0.057\n",
      "Epoch: [43][ 399/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [43][ 449/1563]\tLoss   0.32\tAcc  88.89\tTime/batch 0.057\n",
      "Epoch: [43][ 499/1563]\tLoss   0.32\tAcc  88.86\tTime/batch 0.056\n",
      "Epoch: [43][ 549/1563]\tLoss   0.32\tAcc  88.88\tTime/batch 0.057\n",
      "Epoch: [43][ 599/1563]\tLoss   0.32\tAcc  88.86\tTime/batch 0.057\n",
      "Epoch: [43][ 649/1563]\tLoss   0.32\tAcc  88.77\tTime/batch 0.057\n",
      "Epoch: [43][ 699/1563]\tLoss   0.32\tAcc  88.86\tTime/batch 0.057\n",
      "Epoch: [43][ 749/1563]\tLoss   0.32\tAcc  88.85\tTime/batch 0.057\n",
      "Epoch: [43][ 799/1563]\tLoss   0.32\tAcc  88.89\tTime/batch 0.057\n",
      "Epoch: [43][ 849/1563]\tLoss   0.32\tAcc  88.90\tTime/batch 0.057\n",
      "Epoch: [43][ 899/1563]\tLoss   0.32\tAcc  88.85\tTime/batch 0.057\n",
      "Epoch: [43][ 949/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [43][ 999/1563]\tLoss   0.32\tAcc  88.77\tTime/batch 0.057\n",
      "Epoch: [43][1049/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [43][1099/1563]\tLoss   0.32\tAcc  88.86\tTime/batch 0.057\n",
      "Epoch: [43][1149/1563]\tLoss   0.32\tAcc  88.89\tTime/batch 0.057\n",
      "Epoch: [43][1199/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "Epoch: [43][1249/1563]\tLoss   0.32\tAcc  88.93\tTime/batch 0.057\n",
      "Epoch: [43][1299/1563]\tLoss   0.32\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [43][1349/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [43][1399/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "Epoch: [43][1449/1563]\tLoss   0.32\tAcc  88.93\tTime/batch 0.057\n",
      "Epoch: [43][1499/1563]\tLoss   0.32\tAcc  88.93\tTime/batch 0.057\n",
      "Epoch: [43][1549/1563]\tLoss   0.32\tAcc  88.93\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [44][  49/1563]\tLoss   0.31\tAcc  90.06\tTime/batch 0.058\n",
      "Epoch: [44][  99/1563]\tLoss   0.30\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [44][ 149/1563]\tLoss   0.30\tAcc  89.62\tTime/batch 0.057\n",
      "Epoch: [44][ 199/1563]\tLoss   0.31\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [44][ 249/1563]\tLoss   0.31\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [44][ 299/1563]\tLoss   0.31\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [44][ 349/1563]\tLoss   0.30\tAcc  89.54\tTime/batch 0.057\n",
      "Epoch: [44][ 399/1563]\tLoss   0.30\tAcc  89.45\tTime/batch 0.057\n",
      "Epoch: [44][ 449/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [44][ 499/1563]\tLoss   0.30\tAcc  89.59\tTime/batch 0.057\n",
      "Epoch: [44][ 549/1563]\tLoss   0.31\tAcc  89.47\tTime/batch 0.057\n",
      "Epoch: [44][ 599/1563]\tLoss   0.31\tAcc  89.30\tTime/batch 0.057\n",
      "Epoch: [44][ 649/1563]\tLoss   0.31\tAcc  89.25\tTime/batch 0.057\n",
      "Epoch: [44][ 699/1563]\tLoss   0.31\tAcc  89.21\tTime/batch 0.057\n",
      "Epoch: [44][ 749/1563]\tLoss   0.31\tAcc  89.17\tTime/batch 0.057\n",
      "Epoch: [44][ 799/1563]\tLoss   0.31\tAcc  89.13\tTime/batch 0.057\n",
      "Epoch: [44][ 849/1563]\tLoss   0.31\tAcc  89.08\tTime/batch 0.057\n",
      "Epoch: [44][ 899/1563]\tLoss   0.32\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [44][ 949/1563]\tLoss   0.31\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [44][ 999/1563]\tLoss   0.32\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [44][1049/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [44][1099/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [44][1149/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [44][1199/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [44][1249/1563]\tLoss   0.32\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [44][1299/1563]\tLoss   0.32\tAcc  89.04\tTime/batch 0.057\n",
      "Epoch: [44][1349/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [44][1399/1563]\tLoss   0.32\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [44][1449/1563]\tLoss   0.32\tAcc  88.98\tTime/batch 0.057\n",
      "Epoch: [44][1499/1563]\tLoss   0.32\tAcc  88.97\tTime/batch 0.057\n",
      "Epoch: [44][1549/1563]\tLoss   0.32\tAcc  88.92\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [45][  49/1563]\tLoss   0.31\tAcc  88.56\tTime/batch 0.057\n",
      "Epoch: [45][  99/1563]\tLoss   0.33\tAcc  88.28\tTime/batch 0.057\n",
      "Epoch: [45][ 149/1563]\tLoss   0.32\tAcc  88.69\tTime/batch 0.057\n",
      "Epoch: [45][ 199/1563]\tLoss   0.32\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [45][ 249/1563]\tLoss   0.32\tAcc  88.61\tTime/batch 0.057\n",
      "Epoch: [45][ 299/1563]\tLoss   0.31\tAcc  88.84\tTime/batch 0.057\n",
      "Epoch: [45][ 349/1563]\tLoss   0.31\tAcc  88.90\tTime/batch 0.057\n",
      "Epoch: [45][ 399/1563]\tLoss   0.31\tAcc  89.01\tTime/batch 0.057\n",
      "Epoch: [45][ 449/1563]\tLoss   0.31\tAcc  89.00\tTime/batch 0.057\n",
      "Epoch: [45][ 499/1563]\tLoss   0.31\tAcc  89.04\tTime/batch 0.057\n",
      "Epoch: [45][ 549/1563]\tLoss   0.31\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [45][ 599/1563]\tLoss   0.31\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [45][ 649/1563]\tLoss   0.31\tAcc  89.17\tTime/batch 0.057\n",
      "Epoch: [45][ 699/1563]\tLoss   0.31\tAcc  89.21\tTime/batch 0.057\n",
      "Epoch: [45][ 749/1563]\tLoss   0.30\tAcc  89.24\tTime/batch 0.057\n",
      "Epoch: [45][ 799/1563]\tLoss   0.31\tAcc  89.21\tTime/batch 0.057\n",
      "Epoch: [45][ 849/1563]\tLoss   0.31\tAcc  89.06\tTime/batch 0.057\n",
      "Epoch: [45][ 899/1563]\tLoss   0.31\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [45][ 949/1563]\tLoss   0.31\tAcc  88.95\tTime/batch 0.057\n",
      "Epoch: [45][ 999/1563]\tLoss   0.32\tAcc  88.91\tTime/batch 0.057\n",
      "Epoch: [45][1049/1563]\tLoss   0.31\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [45][1099/1563]\tLoss   0.32\tAcc  88.90\tTime/batch 0.057\n",
      "Epoch: [45][1149/1563]\tLoss   0.31\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [45][1199/1563]\tLoss   0.31\tAcc  88.94\tTime/batch 0.057\n",
      "Epoch: [45][1249/1563]\tLoss   0.31\tAcc  88.93\tTime/batch 0.057\n",
      "Epoch: [45][1299/1563]\tLoss   0.32\tAcc  88.86\tTime/batch 0.057\n",
      "Epoch: [45][1349/1563]\tLoss   0.32\tAcc  88.81\tTime/batch 0.057\n",
      "Epoch: [45][1399/1563]\tLoss   0.32\tAcc  88.86\tTime/batch 0.057\n",
      "Epoch: [45][1449/1563]\tLoss   0.32\tAcc  88.85\tTime/batch 0.057\n",
      "Epoch: [45][1499/1563]\tLoss   0.32\tAcc  88.90\tTime/batch 0.057\n",
      "Epoch: [45][1549/1563]\tLoss   0.32\tAcc  88.87\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [46][  49/1563]\tLoss   0.29\tAcc  89.81\tTime/batch 0.058\n",
      "Epoch: [46][  99/1563]\tLoss   0.29\tAcc  89.72\tTime/batch 0.057\n",
      "Epoch: [46][ 149/1563]\tLoss   0.29\tAcc  89.60\tTime/batch 0.057\n",
      "Epoch: [46][ 199/1563]\tLoss   0.30\tAcc  89.38\tTime/batch 0.057\n",
      "Epoch: [46][ 249/1563]\tLoss   0.30\tAcc  89.36\tTime/batch 0.057\n",
      "Epoch: [46][ 299/1563]\tLoss   0.30\tAcc  89.45\tTime/batch 0.057\n",
      "Epoch: [46][ 349/1563]\tLoss   0.30\tAcc  89.44\tTime/batch 0.057\n",
      "Epoch: [46][ 399/1563]\tLoss   0.30\tAcc  89.34\tTime/batch 0.057\n",
      "Epoch: [46][ 449/1563]\tLoss   0.31\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [46][ 499/1563]\tLoss   0.31\tAcc  89.20\tTime/batch 0.057\n",
      "Epoch: [46][ 549/1563]\tLoss   0.31\tAcc  89.05\tTime/batch 0.057\n",
      "Epoch: [46][ 599/1563]\tLoss   0.31\tAcc  89.14\tTime/batch 0.057\n",
      "Epoch: [46][ 649/1563]\tLoss   0.30\tAcc  89.25\tTime/batch 0.057\n",
      "Epoch: [46][ 699/1563]\tLoss   0.30\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [46][ 749/1563]\tLoss   0.30\tAcc  89.36\tTime/batch 0.057\n",
      "Epoch: [46][ 799/1563]\tLoss   0.30\tAcc  89.36\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [46][ 849/1563]\tLoss   0.31\tAcc  89.27\tTime/batch 0.057\n",
      "Epoch: [46][ 899/1563]\tLoss   0.31\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [46][ 949/1563]\tLoss   0.31\tAcc  89.19\tTime/batch 0.057\n",
      "Epoch: [46][ 999/1563]\tLoss   0.31\tAcc  89.20\tTime/batch 0.057\n",
      "Epoch: [46][1049/1563]\tLoss   0.31\tAcc  89.15\tTime/batch 0.057\n",
      "Epoch: [46][1099/1563]\tLoss   0.31\tAcc  89.07\tTime/batch 0.057\n",
      "Epoch: [46][1149/1563]\tLoss   0.31\tAcc  89.09\tTime/batch 0.057\n",
      "Epoch: [46][1199/1563]\tLoss   0.31\tAcc  89.07\tTime/batch 0.057\n",
      "Epoch: [46][1249/1563]\tLoss   0.31\tAcc  89.08\tTime/batch 0.057\n",
      "Epoch: [46][1299/1563]\tLoss   0.31\tAcc  89.06\tTime/batch 0.057\n",
      "Epoch: [46][1349/1563]\tLoss   0.31\tAcc  89.07\tTime/batch 0.057\n",
      "Epoch: [46][1399/1563]\tLoss   0.31\tAcc  89.10\tTime/batch 0.057\n",
      "Epoch: [46][1449/1563]\tLoss   0.31\tAcc  89.09\tTime/batch 0.057\n",
      "Epoch: [46][1499/1563]\tLoss   0.31\tAcc  89.06\tTime/batch 0.057\n",
      "Epoch: [46][1549/1563]\tLoss   0.31\tAcc  89.08\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [47][  49/1563]\tLoss   0.28\tAcc  89.94\tTime/batch 0.058\n",
      "Epoch: [47][  99/1563]\tLoss   0.29\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [47][ 149/1563]\tLoss   0.30\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [47][ 199/1563]\tLoss   0.30\tAcc  89.23\tTime/batch 0.057\n",
      "Epoch: [47][ 249/1563]\tLoss   0.30\tAcc  89.34\tTime/batch 0.057\n",
      "Epoch: [47][ 299/1563]\tLoss   0.31\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [47][ 349/1563]\tLoss   0.30\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [47][ 399/1563]\tLoss   0.30\tAcc  89.62\tTime/batch 0.057\n",
      "Epoch: [47][ 449/1563]\tLoss   0.30\tAcc  89.69\tTime/batch 0.057\n",
      "Epoch: [47][ 499/1563]\tLoss   0.30\tAcc  89.78\tTime/batch 0.057\n",
      "Epoch: [47][ 549/1563]\tLoss   0.30\tAcc  89.75\tTime/batch 0.057\n",
      "Epoch: [47][ 599/1563]\tLoss   0.30\tAcc  89.59\tTime/batch 0.057\n",
      "Epoch: [47][ 649/1563]\tLoss   0.30\tAcc  89.51\tTime/batch 0.057\n",
      "Epoch: [47][ 699/1563]\tLoss   0.30\tAcc  89.51\tTime/batch 0.057\n",
      "Epoch: [47][ 749/1563]\tLoss   0.30\tAcc  89.48\tTime/batch 0.057\n",
      "Epoch: [47][ 799/1563]\tLoss   0.30\tAcc  89.52\tTime/batch 0.057\n",
      "Epoch: [47][ 849/1563]\tLoss   0.30\tAcc  89.56\tTime/batch 0.057\n",
      "Epoch: [47][ 899/1563]\tLoss   0.31\tAcc  89.45\tTime/batch 0.057\n",
      "Epoch: [47][ 949/1563]\tLoss   0.31\tAcc  89.40\tTime/batch 0.057\n",
      "Epoch: [47][ 999/1563]\tLoss   0.31\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [47][1049/1563]\tLoss   0.31\tAcc  89.24\tTime/batch 0.057\n",
      "Epoch: [47][1099/1563]\tLoss   0.31\tAcc  89.20\tTime/batch 0.057\n",
      "Epoch: [47][1149/1563]\tLoss   0.31\tAcc  89.21\tTime/batch 0.057\n",
      "Epoch: [47][1199/1563]\tLoss   0.31\tAcc  89.20\tTime/batch 0.057\n",
      "Epoch: [47][1249/1563]\tLoss   0.31\tAcc  89.19\tTime/batch 0.057\n",
      "Epoch: [47][1299/1563]\tLoss   0.31\tAcc  89.17\tTime/batch 0.057\n",
      "Epoch: [47][1349/1563]\tLoss   0.31\tAcc  89.12\tTime/batch 0.057\n",
      "Epoch: [47][1399/1563]\tLoss   0.31\tAcc  89.10\tTime/batch 0.057\n",
      "Epoch: [47][1449/1563]\tLoss   0.31\tAcc  89.06\tTime/batch 0.057\n",
      "Epoch: [47][1499/1563]\tLoss   0.32\tAcc  89.02\tTime/batch 0.057\n",
      "Epoch: [47][1549/1563]\tLoss   0.32\tAcc  89.03\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [48][  49/1563]\tLoss   0.30\tAcc  89.81\tTime/batch 0.058\n",
      "Epoch: [48][  99/1563]\tLoss   0.31\tAcc  89.53\tTime/batch 0.057\n",
      "Epoch: [48][ 149/1563]\tLoss   0.30\tAcc  89.75\tTime/batch 0.057\n",
      "Epoch: [48][ 199/1563]\tLoss   0.30\tAcc  89.78\tTime/batch 0.057\n",
      "Epoch: [48][ 249/1563]\tLoss   0.30\tAcc  89.69\tTime/batch 0.057\n",
      "Epoch: [48][ 299/1563]\tLoss   0.30\tAcc  89.64\tTime/batch 0.057\n",
      "Epoch: [48][ 349/1563]\tLoss   0.30\tAcc  89.60\tTime/batch 0.057\n",
      "Epoch: [48][ 399/1563]\tLoss   0.30\tAcc  89.53\tTime/batch 0.057\n",
      "Epoch: [48][ 449/1563]\tLoss   0.31\tAcc  89.41\tTime/batch 0.057\n",
      "Epoch: [48][ 499/1563]\tLoss   0.31\tAcc  89.26\tTime/batch 0.057\n",
      "Epoch: [48][ 549/1563]\tLoss   0.31\tAcc  89.23\tTime/batch 0.057\n",
      "Epoch: [48][ 599/1563]\tLoss   0.31\tAcc  89.35\tTime/batch 0.057\n",
      "Epoch: [48][ 649/1563]\tLoss   0.31\tAcc  89.29\tTime/batch 0.057\n",
      "Epoch: [48][ 699/1563]\tLoss   0.31\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [48][ 749/1563]\tLoss   0.31\tAcc  89.40\tTime/batch 0.057\n",
      "Epoch: [48][ 799/1563]\tLoss   0.30\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [48][ 849/1563]\tLoss   0.30\tAcc  89.48\tTime/batch 0.057\n",
      "Epoch: [48][ 899/1563]\tLoss   0.30\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [48][ 949/1563]\tLoss   0.31\tAcc  89.40\tTime/batch 0.057\n",
      "Epoch: [48][ 999/1563]\tLoss   0.31\tAcc  89.37\tTime/batch 0.057\n",
      "Epoch: [48][1049/1563]\tLoss   0.31\tAcc  89.30\tTime/batch 0.057\n",
      "Epoch: [48][1099/1563]\tLoss   0.31\tAcc  89.30\tTime/batch 0.057\n",
      "Epoch: [48][1149/1563]\tLoss   0.31\tAcc  89.36\tTime/batch 0.057\n",
      "Epoch: [48][1199/1563]\tLoss   0.31\tAcc  89.36\tTime/batch 0.057\n",
      "Epoch: [48][1249/1563]\tLoss   0.31\tAcc  89.35\tTime/batch 0.057\n",
      "Epoch: [48][1299/1563]\tLoss   0.31\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [48][1349/1563]\tLoss   0.31\tAcc  89.30\tTime/batch 0.057\n",
      "Epoch: [48][1399/1563]\tLoss   0.31\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [48][1449/1563]\tLoss   0.31\tAcc  89.25\tTime/batch 0.057\n",
      "Epoch: [48][1499/1563]\tLoss   0.31\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [48][1549/1563]\tLoss   0.31\tAcc  89.31\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [49][  49/1563]\tLoss   0.29\tAcc  90.19\tTime/batch 0.058\n",
      "Epoch: [49][  99/1563]\tLoss   0.29\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [49][ 149/1563]\tLoss   0.29\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [49][ 199/1563]\tLoss   0.30\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [49][ 249/1563]\tLoss   0.30\tAcc  89.74\tTime/batch 0.057\n",
      "Epoch: [49][ 299/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [49][ 349/1563]\tLoss   0.29\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [49][ 399/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [49][ 449/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "Epoch: [49][ 499/1563]\tLoss   0.30\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [49][ 549/1563]\tLoss   0.30\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [49][ 599/1563]\tLoss   0.30\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [49][ 649/1563]\tLoss   0.30\tAcc  89.82\tTime/batch 0.057\n",
      "Epoch: [49][ 699/1563]\tLoss   0.30\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [49][ 749/1563]\tLoss   0.30\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [49][ 799/1563]\tLoss   0.30\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [49][ 849/1563]\tLoss   0.30\tAcc  89.68\tTime/batch 0.057\n",
      "Epoch: [49][ 899/1563]\tLoss   0.30\tAcc  89.65\tTime/batch 0.057\n",
      "Epoch: [49][ 949/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [49][ 999/1563]\tLoss   0.31\tAcc  89.49\tTime/batch 0.057\n",
      "Epoch: [49][1049/1563]\tLoss   0.31\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [49][1099/1563]\tLoss   0.30\tAcc  89.49\tTime/batch 0.057\n",
      "Epoch: [49][1149/1563]\tLoss   0.31\tAcc  89.40\tTime/batch 0.057\n",
      "Epoch: [49][1199/1563]\tLoss   0.31\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [49][1249/1563]\tLoss   0.31\tAcc  89.43\tTime/batch 0.057\n",
      "Epoch: [49][1299/1563]\tLoss   0.31\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [49][1349/1563]\tLoss   0.31\tAcc  89.44\tTime/batch 0.057\n",
      "Epoch: [49][1399/1563]\tLoss   0.31\tAcc  89.45\tTime/batch 0.057\n",
      "Epoch: [49][1449/1563]\tLoss   0.31\tAcc  89.48\tTime/batch 0.057\n",
      "Epoch: [49][1499/1563]\tLoss   0.31\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [49][1549/1563]\tLoss   0.31\tAcc  89.48\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [50][  49/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [50][  99/1563]\tLoss   0.31\tAcc  88.88\tTime/batch 0.057\n",
      "Epoch: [50][ 149/1563]\tLoss   0.31\tAcc  89.10\tTime/batch 0.057\n",
      "Epoch: [50][ 199/1563]\tLoss   0.30\tAcc  89.25\tTime/batch 0.057\n",
      "Epoch: [50][ 249/1563]\tLoss   0.30\tAcc  89.26\tTime/batch 0.057\n",
      "Epoch: [50][ 299/1563]\tLoss   0.30\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [50][ 349/1563]\tLoss   0.30\tAcc  89.31\tTime/batch 0.057\n",
      "Epoch: [50][ 399/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [50][ 449/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [50][ 499/1563]\tLoss   0.29\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [50][ 549/1563]\tLoss   0.30\tAcc  89.60\tTime/batch 0.057\n",
      "Epoch: [50][ 599/1563]\tLoss   0.30\tAcc  89.59\tTime/batch 0.057\n",
      "Epoch: [50][ 649/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [50][ 699/1563]\tLoss   0.30\tAcc  89.52\tTime/batch 0.057\n",
      "Epoch: [50][ 749/1563]\tLoss   0.30\tAcc  89.57\tTime/batch 0.057\n",
      "Epoch: [50][ 799/1563]\tLoss   0.30\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [50][ 849/1563]\tLoss   0.30\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [50][ 899/1563]\tLoss   0.30\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [50][ 949/1563]\tLoss   0.30\tAcc  89.45\tTime/batch 0.057\n",
      "Epoch: [50][ 999/1563]\tLoss   0.30\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [50][1049/1563]\tLoss   0.30\tAcc  89.47\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [50][1099/1563]\tLoss   0.30\tAcc  89.42\tTime/batch 0.057\n",
      "Epoch: [50][1149/1563]\tLoss   0.30\tAcc  89.40\tTime/batch 0.057\n",
      "Epoch: [50][1199/1563]\tLoss   0.30\tAcc  89.38\tTime/batch 0.057\n",
      "Epoch: [50][1249/1563]\tLoss   0.30\tAcc  89.34\tTime/batch 0.057\n",
      "Epoch: [50][1299/1563]\tLoss   0.30\tAcc  89.34\tTime/batch 0.057\n",
      "Epoch: [50][1349/1563]\tLoss   0.31\tAcc  89.34\tTime/batch 0.057\n",
      "Epoch: [50][1399/1563]\tLoss   0.31\tAcc  89.33\tTime/batch 0.057\n",
      "Epoch: [50][1449/1563]\tLoss   0.31\tAcc  89.28\tTime/batch 0.057\n",
      "Epoch: [50][1499/1563]\tLoss   0.31\tAcc  89.29\tTime/batch 0.057\n",
      "Epoch: [50][1549/1563]\tLoss   0.31\tAcc  89.29\tTime/batch 0.057\n",
      "epoch 50\n",
      "Accuracy of the network on the 10000 test images: 86.1 %\n",
      "Sparsity of the update phase: 65.5 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [51][  49/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [51][  99/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "Epoch: [51][ 149/1563]\tLoss   0.28\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [51][ 199/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.057\n",
      "Epoch: [51][ 249/1563]\tLoss   0.28\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [51][ 299/1563]\tLoss   0.28\tAcc  89.99\tTime/batch 0.056\n",
      "Epoch: [51][ 349/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.056\n",
      "Epoch: [51][ 399/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.056\n",
      "Epoch: [51][ 449/1563]\tLoss   0.28\tAcc  90.01\tTime/batch 0.056\n",
      "Epoch: [51][ 499/1563]\tLoss   0.29\tAcc  89.96\tTime/batch 0.056\n",
      "Epoch: [51][ 549/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.056\n",
      "Epoch: [51][ 599/1563]\tLoss   0.28\tAcc  90.03\tTime/batch 0.056\n",
      "Epoch: [51][ 649/1563]\tLoss   0.29\tAcc  89.94\tTime/batch 0.056\n",
      "Epoch: [51][ 699/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [51][ 749/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [51][ 799/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [51][ 849/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [51][ 899/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [51][ 949/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [51][ 999/1563]\tLoss   0.29\tAcc  89.77\tTime/batch 0.057\n",
      "Epoch: [51][1049/1563]\tLoss   0.30\tAcc  89.74\tTime/batch 0.057\n",
      "Epoch: [51][1099/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [51][1149/1563]\tLoss   0.30\tAcc  89.65\tTime/batch 0.057\n",
      "Epoch: [51][1199/1563]\tLoss   0.30\tAcc  89.60\tTime/batch 0.057\n",
      "Epoch: [51][1249/1563]\tLoss   0.30\tAcc  89.59\tTime/batch 0.057\n",
      "Epoch: [51][1299/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [51][1349/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [51][1399/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [51][1449/1563]\tLoss   0.30\tAcc  89.45\tTime/batch 0.057\n",
      "Epoch: [51][1499/1563]\tLoss   0.30\tAcc  89.47\tTime/batch 0.057\n",
      "Epoch: [51][1549/1563]\tLoss   0.30\tAcc  89.43\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [52][  49/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.058\n",
      "Epoch: [52][  99/1563]\tLoss   0.25\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [52][ 149/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [52][ 199/1563]\tLoss   0.26\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [52][ 249/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.057\n",
      "Epoch: [52][ 299/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [52][ 349/1563]\tLoss   0.29\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [52][ 399/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [52][ 449/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [52][ 499/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [52][ 549/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [52][ 599/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [52][ 649/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [52][ 699/1563]\tLoss   0.30\tAcc  89.76\tTime/batch 0.057\n",
      "Epoch: [52][ 749/1563]\tLoss   0.30\tAcc  89.71\tTime/batch 0.057\n",
      "Epoch: [52][ 799/1563]\tLoss   0.30\tAcc  89.64\tTime/batch 0.057\n",
      "Epoch: [52][ 849/1563]\tLoss   0.30\tAcc  89.71\tTime/batch 0.057\n",
      "Epoch: [52][ 899/1563]\tLoss   0.30\tAcc  89.74\tTime/batch 0.057\n",
      "Epoch: [52][ 949/1563]\tLoss   0.30\tAcc  89.70\tTime/batch 0.057\n",
      "Epoch: [52][ 999/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [52][1049/1563]\tLoss   0.30\tAcc  89.63\tTime/batch 0.057\n",
      "Epoch: [52][1099/1563]\tLoss   0.30\tAcc  89.68\tTime/batch 0.057\n",
      "Epoch: [52][1149/1563]\tLoss   0.30\tAcc  89.62\tTime/batch 0.057\n",
      "Epoch: [52][1199/1563]\tLoss   0.30\tAcc  89.60\tTime/batch 0.057\n",
      "Epoch: [52][1249/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [52][1299/1563]\tLoss   0.30\tAcc  89.56\tTime/batch 0.057\n",
      "Epoch: [52][1349/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [52][1399/1563]\tLoss   0.30\tAcc  89.57\tTime/batch 0.057\n",
      "Epoch: [52][1449/1563]\tLoss   0.30\tAcc  89.55\tTime/batch 0.057\n",
      "Epoch: [52][1499/1563]\tLoss   0.30\tAcc  89.54\tTime/batch 0.057\n",
      "Epoch: [52][1549/1563]\tLoss   0.30\tAcc  89.51\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [53][  49/1563]\tLoss   0.27\tAcc  90.75\tTime/batch 0.058\n",
      "Epoch: [53][  99/1563]\tLoss   0.26\tAcc  91.28\tTime/batch 0.057\n",
      "Epoch: [53][ 149/1563]\tLoss   0.27\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [53][ 199/1563]\tLoss   0.28\tAcc  90.47\tTime/batch 0.057\n",
      "Epoch: [53][ 249/1563]\tLoss   0.29\tAcc  90.21\tTime/batch 0.057\n",
      "Epoch: [53][ 299/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [53][ 349/1563]\tLoss   0.30\tAcc  89.94\tTime/batch 0.057\n",
      "Epoch: [53][ 399/1563]\tLoss   0.30\tAcc  89.93\tTime/batch 0.057\n",
      "Epoch: [53][ 449/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [53][ 499/1563]\tLoss   0.30\tAcc  89.86\tTime/batch 0.057\n",
      "Epoch: [53][ 549/1563]\tLoss   0.29\tAcc  89.86\tTime/batch 0.057\n",
      "Epoch: [53][ 599/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [53][ 649/1563]\tLoss   0.29\tAcc  89.79\tTime/batch 0.057\n",
      "Epoch: [53][ 699/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [53][ 749/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [53][ 799/1563]\tLoss   0.30\tAcc  89.66\tTime/batch 0.057\n",
      "Epoch: [53][ 849/1563]\tLoss   0.30\tAcc  89.58\tTime/batch 0.057\n",
      "Epoch: [53][ 899/1563]\tLoss   0.30\tAcc  89.56\tTime/batch 0.057\n",
      "Epoch: [53][ 949/1563]\tLoss   0.30\tAcc  89.57\tTime/batch 0.057\n",
      "Epoch: [53][ 999/1563]\tLoss   0.30\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [53][1049/1563]\tLoss   0.30\tAcc  89.49\tTime/batch 0.057\n",
      "Epoch: [53][1099/1563]\tLoss   0.30\tAcc  89.48\tTime/batch 0.057\n",
      "Epoch: [53][1149/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "Epoch: [53][1199/1563]\tLoss   0.30\tAcc  89.46\tTime/batch 0.057\n",
      "Epoch: [53][1249/1563]\tLoss   0.30\tAcc  89.48\tTime/batch 0.057\n",
      "Epoch: [53][1299/1563]\tLoss   0.30\tAcc  89.51\tTime/batch 0.057\n",
      "Epoch: [53][1349/1563]\tLoss   0.30\tAcc  89.53\tTime/batch 0.057\n",
      "Epoch: [53][1399/1563]\tLoss   0.30\tAcc  89.49\tTime/batch 0.057\n",
      "Epoch: [53][1449/1563]\tLoss   0.30\tAcc  89.52\tTime/batch 0.057\n",
      "Epoch: [53][1499/1563]\tLoss   0.30\tAcc  89.52\tTime/batch 0.057\n",
      "Epoch: [53][1549/1563]\tLoss   0.30\tAcc  89.51\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [54][  49/1563]\tLoss   0.29\tAcc  90.25\tTime/batch 0.058\n",
      "Epoch: [54][  99/1563]\tLoss   0.28\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [54][ 149/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [54][ 199/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [54][ 249/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [54][ 299/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [54][ 349/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [54][ 399/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.056\n",
      "Epoch: [54][ 449/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.056\n",
      "Epoch: [54][ 499/1563]\tLoss   0.29\tAcc  89.98\tTime/batch 0.056\n",
      "Epoch: [54][ 549/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.056\n",
      "Epoch: [54][ 599/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.056\n",
      "Epoch: [54][ 649/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.056\n",
      "Epoch: [54][ 699/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.056\n",
      "Epoch: [54][ 749/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.056\n",
      "Epoch: [54][ 799/1563]\tLoss   0.29\tAcc  89.76\tTime/batch 0.056\n",
      "Epoch: [54][ 849/1563]\tLoss   0.29\tAcc  89.71\tTime/batch 0.056\n",
      "Epoch: [54][ 899/1563]\tLoss   0.29\tAcc  89.72\tTime/batch 0.057\n",
      "Epoch: [54][ 949/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [54][ 999/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [54][1049/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [54][1099/1563]\tLoss   0.30\tAcc  89.68\tTime/batch 0.057\n",
      "Epoch: [54][1149/1563]\tLoss   0.30\tAcc  89.69\tTime/batch 0.057\n",
      "Epoch: [54][1199/1563]\tLoss   0.30\tAcc  89.69\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [54][1249/1563]\tLoss   0.30\tAcc  89.68\tTime/batch 0.057\n",
      "Epoch: [54][1299/1563]\tLoss   0.30\tAcc  89.66\tTime/batch 0.057\n",
      "Epoch: [54][1349/1563]\tLoss   0.30\tAcc  89.63\tTime/batch 0.057\n",
      "Epoch: [54][1399/1563]\tLoss   0.30\tAcc  89.62\tTime/batch 0.057\n",
      "Epoch: [54][1449/1563]\tLoss   0.30\tAcc  89.59\tTime/batch 0.057\n",
      "Epoch: [54][1499/1563]\tLoss   0.30\tAcc  89.57\tTime/batch 0.057\n",
      "Epoch: [54][1549/1563]\tLoss   0.30\tAcc  89.59\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [55][  49/1563]\tLoss   0.27\tAcc  91.25\tTime/batch 0.057\n",
      "Epoch: [55][  99/1563]\tLoss   0.28\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [55][ 149/1563]\tLoss   0.29\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [55][ 199/1563]\tLoss   0.28\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [55][ 249/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [55][ 299/1563]\tLoss   0.29\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [55][ 349/1563]\tLoss   0.28\tAcc  90.24\tTime/batch 0.057\n",
      "Epoch: [55][ 399/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [55][ 449/1563]\tLoss   0.29\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [55][ 499/1563]\tLoss   0.29\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [55][ 549/1563]\tLoss   0.29\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [55][ 599/1563]\tLoss   0.29\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [55][ 649/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [55][ 699/1563]\tLoss   0.29\tAcc  89.93\tTime/batch 0.057\n",
      "Epoch: [55][ 749/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [55][ 799/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [55][ 849/1563]\tLoss   0.29\tAcc  89.82\tTime/batch 0.057\n",
      "Epoch: [55][ 899/1563]\tLoss   0.30\tAcc  89.76\tTime/batch 0.057\n",
      "Epoch: [55][ 949/1563]\tLoss   0.30\tAcc  89.69\tTime/batch 0.057\n",
      "Epoch: [55][ 999/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [55][1049/1563]\tLoss   0.30\tAcc  89.67\tTime/batch 0.057\n",
      "Epoch: [55][1099/1563]\tLoss   0.30\tAcc  89.65\tTime/batch 0.057\n",
      "Epoch: [55][1149/1563]\tLoss   0.30\tAcc  89.63\tTime/batch 0.057\n",
      "Epoch: [55][1199/1563]\tLoss   0.30\tAcc  89.63\tTime/batch 0.057\n",
      "Epoch: [55][1249/1563]\tLoss   0.30\tAcc  89.60\tTime/batch 0.057\n",
      "Epoch: [55][1299/1563]\tLoss   0.30\tAcc  89.56\tTime/batch 0.057\n",
      "Epoch: [55][1349/1563]\tLoss   0.30\tAcc  89.55\tTime/batch 0.057\n",
      "Epoch: [55][1399/1563]\tLoss   0.30\tAcc  89.54\tTime/batch 0.057\n",
      "Epoch: [55][1449/1563]\tLoss   0.30\tAcc  89.53\tTime/batch 0.057\n",
      "Epoch: [55][1499/1563]\tLoss   0.30\tAcc  89.53\tTime/batch 0.057\n",
      "Epoch: [55][1549/1563]\tLoss   0.30\tAcc  89.50\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [56][  49/1563]\tLoss   0.30\tAcc  89.19\tTime/batch 0.058\n",
      "Epoch: [56][  99/1563]\tLoss   0.28\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [56][ 149/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [56][ 199/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [56][ 249/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [56][ 299/1563]\tLoss   0.28\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [56][ 349/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [56][ 399/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [56][ 449/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [56][ 499/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [56][ 549/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [56][ 599/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [56][ 649/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.057\n",
      "Epoch: [56][ 699/1563]\tLoss   0.29\tAcc  89.96\tTime/batch 0.057\n",
      "Epoch: [56][ 749/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.057\n",
      "Epoch: [56][ 799/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "Epoch: [56][ 849/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [56][ 899/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.057\n",
      "Epoch: [56][ 949/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [56][ 999/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [56][1049/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "Epoch: [56][1099/1563]\tLoss   0.29\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [56][1149/1563]\tLoss   0.29\tAcc  89.76\tTime/batch 0.057\n",
      "Epoch: [56][1199/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [56][1249/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [56][1299/1563]\tLoss   0.29\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [56][1349/1563]\tLoss   0.29\tAcc  89.75\tTime/batch 0.057\n",
      "Epoch: [56][1399/1563]\tLoss   0.29\tAcc  89.72\tTime/batch 0.057\n",
      "Epoch: [56][1449/1563]\tLoss   0.29\tAcc  89.74\tTime/batch 0.057\n",
      "Epoch: [56][1499/1563]\tLoss   0.29\tAcc  89.70\tTime/batch 0.057\n",
      "Epoch: [56][1549/1563]\tLoss   0.29\tAcc  89.71\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [57][  49/1563]\tLoss   0.31\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [57][  99/1563]\tLoss   0.31\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [57][ 149/1563]\tLoss   0.30\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [57][ 199/1563]\tLoss   0.30\tAcc  90.02\tTime/batch 0.056\n",
      "Epoch: [57][ 249/1563]\tLoss   0.30\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [57][ 299/1563]\tLoss   0.30\tAcc  89.96\tTime/batch 0.057\n",
      "Epoch: [57][ 349/1563]\tLoss   0.30\tAcc  89.98\tTime/batch 0.057\n",
      "Epoch: [57][ 399/1563]\tLoss   0.30\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [57][ 449/1563]\tLoss   0.30\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [57][ 499/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [57][ 549/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [57][ 599/1563]\tLoss   0.29\tAcc  90.00\tTime/batch 0.057\n",
      "Epoch: [57][ 649/1563]\tLoss   0.29\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [57][ 699/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [57][ 749/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [57][ 799/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.057\n",
      "Epoch: [57][ 849/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.057\n",
      "Epoch: [57][ 899/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [57][ 949/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [57][ 999/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "Epoch: [57][1049/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [57][1099/1563]\tLoss   0.30\tAcc  89.78\tTime/batch 0.057\n",
      "Epoch: [57][1149/1563]\tLoss   0.30\tAcc  89.80\tTime/batch 0.056\n",
      "Epoch: [57][1199/1563]\tLoss   0.30\tAcc  89.80\tTime/batch 0.056\n",
      "Epoch: [57][1249/1563]\tLoss   0.30\tAcc  89.77\tTime/batch 0.056\n",
      "Epoch: [57][1299/1563]\tLoss   0.30\tAcc  89.73\tTime/batch 0.056\n",
      "Epoch: [57][1349/1563]\tLoss   0.30\tAcc  89.72\tTime/batch 0.056\n",
      "Epoch: [57][1399/1563]\tLoss   0.30\tAcc  89.71\tTime/batch 0.056\n",
      "Epoch: [57][1449/1563]\tLoss   0.30\tAcc  89.68\tTime/batch 0.056\n",
      "Epoch: [57][1499/1563]\tLoss   0.30\tAcc  89.64\tTime/batch 0.056\n",
      "Epoch: [57][1549/1563]\tLoss   0.30\tAcc  89.62\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [58][  49/1563]\tLoss   0.25\tAcc  92.00\tTime/batch 0.058\n",
      "Epoch: [58][  99/1563]\tLoss   0.26\tAcc  91.56\tTime/batch 0.057\n",
      "Epoch: [58][ 149/1563]\tLoss   0.26\tAcc  91.42\tTime/batch 0.057\n",
      "Epoch: [58][ 199/1563]\tLoss   0.26\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [58][ 249/1563]\tLoss   0.27\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [58][ 299/1563]\tLoss   0.27\tAcc  91.00\tTime/batch 0.056\n",
      "Epoch: [58][ 349/1563]\tLoss   0.27\tAcc  90.88\tTime/batch 0.056\n",
      "Epoch: [58][ 399/1563]\tLoss   0.28\tAcc  90.58\tTime/batch 0.056\n",
      "Epoch: [58][ 449/1563]\tLoss   0.28\tAcc  90.51\tTime/batch 0.056\n",
      "Epoch: [58][ 499/1563]\tLoss   0.28\tAcc  90.32\tTime/batch 0.056\n",
      "Epoch: [58][ 549/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.056\n",
      "Epoch: [58][ 599/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.056\n",
      "Epoch: [58][ 649/1563]\tLoss   0.29\tAcc  90.24\tTime/batch 0.056\n",
      "Epoch: [58][ 699/1563]\tLoss   0.29\tAcc  90.19\tTime/batch 0.056\n",
      "Epoch: [58][ 749/1563]\tLoss   0.29\tAcc  90.21\tTime/batch 0.056\n",
      "Epoch: [58][ 799/1563]\tLoss   0.29\tAcc  90.18\tTime/batch 0.056\n",
      "Epoch: [58][ 849/1563]\tLoss   0.29\tAcc  90.23\tTime/batch 0.056\n",
      "Epoch: [58][ 899/1563]\tLoss   0.29\tAcc  90.21\tTime/batch 0.056\n",
      "Epoch: [58][ 949/1563]\tLoss   0.29\tAcc  90.14\tTime/batch 0.056\n",
      "Epoch: [58][ 999/1563]\tLoss   0.29\tAcc  90.14\tTime/batch 0.056\n",
      "Epoch: [58][1049/1563]\tLoss   0.29\tAcc  90.10\tTime/batch 0.056\n",
      "Epoch: [58][1099/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.056\n",
      "Epoch: [58][1149/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.056\n",
      "Epoch: [58][1199/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.056\n",
      "Epoch: [58][1249/1563]\tLoss   0.29\tAcc  89.98\tTime/batch 0.056\n",
      "Epoch: [58][1299/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.056\n",
      "Epoch: [58][1349/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.056\n",
      "Epoch: [58][1399/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.056\n",
      "Epoch: [58][1449/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [58][1499/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [58][1549/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [59][  49/1563]\tLoss   0.27\tAcc  90.06\tTime/batch 0.058\n",
      "Epoch: [59][  99/1563]\tLoss   0.27\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [59][ 149/1563]\tLoss   0.27\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [59][ 199/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [59][ 249/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [59][ 299/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [59][ 349/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [59][ 399/1563]\tLoss   0.29\tAcc  89.77\tTime/batch 0.057\n",
      "Epoch: [59][ 449/1563]\tLoss   0.29\tAcc  89.81\tTime/batch 0.057\n",
      "Epoch: [59][ 499/1563]\tLoss   0.29\tAcc  89.96\tTime/batch 0.057\n",
      "Epoch: [59][ 549/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.057\n",
      "Epoch: [59][ 599/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.057\n",
      "Epoch: [59][ 649/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [59][ 699/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [59][ 749/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [59][ 799/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [59][ 849/1563]\tLoss   0.29\tAcc  89.79\tTime/batch 0.057\n",
      "Epoch: [59][ 899/1563]\tLoss   0.29\tAcc  89.82\tTime/batch 0.057\n",
      "Epoch: [59][ 949/1563]\tLoss   0.29\tAcc  89.78\tTime/batch 0.057\n",
      "Epoch: [59][ 999/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [59][1049/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [59][1099/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.057\n",
      "Epoch: [59][1149/1563]\tLoss   0.29\tAcc  89.79\tTime/batch 0.057\n",
      "Epoch: [59][1199/1563]\tLoss   0.29\tAcc  89.75\tTime/batch 0.057\n",
      "Epoch: [59][1249/1563]\tLoss   0.29\tAcc  89.77\tTime/batch 0.057\n",
      "Epoch: [59][1299/1563]\tLoss   0.29\tAcc  89.79\tTime/batch 0.057\n",
      "Epoch: [59][1349/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [59][1399/1563]\tLoss   0.29\tAcc  89.77\tTime/batch 0.057\n",
      "Epoch: [59][1449/1563]\tLoss   0.29\tAcc  89.72\tTime/batch 0.057\n",
      "Epoch: [59][1499/1563]\tLoss   0.29\tAcc  89.73\tTime/batch 0.057\n",
      "Epoch: [59][1549/1563]\tLoss   0.29\tAcc  89.73\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [60][  49/1563]\tLoss   0.27\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [60][  99/1563]\tLoss   0.27\tAcc  90.84\tTime/batch 0.057\n",
      "Epoch: [60][ 149/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "Epoch: [60][ 199/1563]\tLoss   0.28\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [60][ 249/1563]\tLoss   0.28\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [60][ 299/1563]\tLoss   0.28\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [60][ 349/1563]\tLoss   0.28\tAcc  90.63\tTime/batch 0.057\n",
      "Epoch: [60][ 399/1563]\tLoss   0.28\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [60][ 449/1563]\tLoss   0.28\tAcc  90.55\tTime/batch 0.057\n",
      "Epoch: [60][ 499/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [60][ 549/1563]\tLoss   0.28\tAcc  90.43\tTime/batch 0.057\n",
      "Epoch: [60][ 599/1563]\tLoss   0.28\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [60][ 649/1563]\tLoss   0.28\tAcc  90.41\tTime/batch 0.057\n",
      "Epoch: [60][ 699/1563]\tLoss   0.29\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [60][ 749/1563]\tLoss   0.29\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [60][ 799/1563]\tLoss   0.29\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [60][ 849/1563]\tLoss   0.29\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [60][ 899/1563]\tLoss   0.29\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [60][ 949/1563]\tLoss   0.29\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [60][ 999/1563]\tLoss   0.29\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [60][1049/1563]\tLoss   0.29\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [60][1099/1563]\tLoss   0.29\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [60][1149/1563]\tLoss   0.29\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [60][1199/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [60][1249/1563]\tLoss   0.29\tAcc  90.00\tTime/batch 0.057\n",
      "Epoch: [60][1299/1563]\tLoss   0.29\tAcc  90.00\tTime/batch 0.057\n",
      "Epoch: [60][1349/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.057\n",
      "Epoch: [60][1399/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.057\n",
      "Epoch: [60][1449/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "Epoch: [60][1499/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "Epoch: [60][1549/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "epoch 60\n",
      "Accuracy of the network on the 10000 test images: 85.0 %\n",
      "Sparsity of the update phase: 67.0 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [61][  49/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.058\n",
      "Epoch: [61][  99/1563]\tLoss   0.27\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [61][ 149/1563]\tLoss   0.27\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [61][ 199/1563]\tLoss   0.27\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [61][ 249/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [61][ 299/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [61][ 349/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [61][ 399/1563]\tLoss   0.27\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [61][ 449/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [61][ 499/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [61][ 549/1563]\tLoss   0.27\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [61][ 599/1563]\tLoss   0.27\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [61][ 649/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [61][ 699/1563]\tLoss   0.27\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [61][ 749/1563]\tLoss   0.28\tAcc  90.35\tTime/batch 0.057\n",
      "Epoch: [61][ 799/1563]\tLoss   0.28\tAcc  90.30\tTime/batch 0.057\n",
      "Epoch: [61][ 849/1563]\tLoss   0.28\tAcc  90.21\tTime/batch 0.056\n",
      "Epoch: [61][ 899/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.056\n",
      "Epoch: [61][ 949/1563]\tLoss   0.28\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [61][ 999/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [61][1049/1563]\tLoss   0.28\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [61][1099/1563]\tLoss   0.28\tAcc  90.00\tTime/batch 0.057\n",
      "Epoch: [61][1149/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [61][1199/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [61][1249/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [61][1299/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [61][1349/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [61][1399/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "Epoch: [61][1449/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [61][1499/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "Epoch: [61][1549/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [62][  49/1563]\tLoss   0.28\tAcc  90.00\tTime/batch 0.059\n",
      "Epoch: [62][  99/1563]\tLoss   0.29\tAcc  89.94\tTime/batch 0.058\n",
      "Epoch: [62][ 149/1563]\tLoss   0.28\tAcc  89.96\tTime/batch 0.058\n",
      "Epoch: [62][ 199/1563]\tLoss   0.28\tAcc  89.94\tTime/batch 0.058\n",
      "Epoch: [62][ 249/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.058\n",
      "Epoch: [62][ 299/1563]\tLoss   0.29\tAcc  89.70\tTime/batch 0.058\n",
      "Epoch: [62][ 349/1563]\tLoss   0.29\tAcc  89.73\tTime/batch 0.058\n",
      "Epoch: [62][ 399/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.058\n",
      "Epoch: [62][ 449/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.058\n",
      "Epoch: [62][ 499/1563]\tLoss   0.29\tAcc  90.06\tTime/batch 0.058\n",
      "Epoch: [62][ 549/1563]\tLoss   0.29\tAcc  89.98\tTime/batch 0.058\n",
      "Epoch: [62][ 599/1563]\tLoss   0.29\tAcc  89.98\tTime/batch 0.058\n",
      "Epoch: [62][ 649/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.058\n",
      "Epoch: [62][ 699/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.058\n",
      "Epoch: [62][ 749/1563]\tLoss   0.29\tAcc  90.07\tTime/batch 0.058\n",
      "Epoch: [62][ 799/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.058\n",
      "Epoch: [62][ 849/1563]\tLoss   0.29\tAcc  90.06\tTime/batch 0.058\n",
      "Epoch: [62][ 899/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.058\n",
      "Epoch: [62][ 949/1563]\tLoss   0.29\tAcc  90.06\tTime/batch 0.058\n",
      "Epoch: [62][ 999/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.058\n",
      "Epoch: [62][1049/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.058\n",
      "Epoch: [62][1099/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.058\n",
      "Epoch: [62][1149/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.057\n",
      "Epoch: [62][1199/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [62][1249/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [62][1299/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.057\n",
      "Epoch: [62][1349/1563]\tLoss   0.29\tAcc  89.86\tTime/batch 0.057\n",
      "Epoch: [62][1399/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "Epoch: [62][1449/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [62][1499/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [62][1549/1563]\tLoss   0.29\tAcc  89.74\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [63][  49/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [63][  99/1563]\tLoss   0.29\tAcc  90.22\tTime/batch 0.057\n",
      "Epoch: [63][ 149/1563]\tLoss   0.28\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [63][ 199/1563]\tLoss   0.28\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [63][ 249/1563]\tLoss   0.28\tAcc  90.45\tTime/batch 0.057\n",
      "Epoch: [63][ 299/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [63][ 349/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [63][ 399/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [63][ 449/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [63][ 499/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [63][ 549/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [63][ 599/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [63][ 649/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [63][ 699/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [63][ 749/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [63][ 799/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [63][ 849/1563]\tLoss   0.28\tAcc  90.24\tTime/batch 0.056\n",
      "Epoch: [63][ 899/1563]\tLoss   0.29\tAcc  90.18\tTime/batch 0.056\n",
      "Epoch: [63][ 949/1563]\tLoss   0.29\tAcc  90.13\tTime/batch 0.056\n",
      "Epoch: [63][ 999/1563]\tLoss   0.29\tAcc  90.12\tTime/batch 0.056\n",
      "Epoch: [63][1049/1563]\tLoss   0.29\tAcc  90.11\tTime/batch 0.056\n",
      "Epoch: [63][1099/1563]\tLoss   0.29\tAcc  90.11\tTime/batch 0.056\n",
      "Epoch: [63][1149/1563]\tLoss   0.29\tAcc  90.08\tTime/batch 0.056\n",
      "Epoch: [63][1199/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.056\n",
      "Epoch: [63][1249/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.056\n",
      "Epoch: [63][1299/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.056\n",
      "Epoch: [63][1349/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.056\n",
      "Epoch: [63][1399/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.056\n",
      "Epoch: [63][1449/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.056\n",
      "Epoch: [63][1499/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.056\n",
      "Epoch: [63][1549/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [64][  49/1563]\tLoss   0.26\tAcc  91.25\tTime/batch 0.057\n",
      "Epoch: [64][  99/1563]\tLoss   0.26\tAcc  91.06\tTime/batch 0.056\n",
      "Epoch: [64][ 149/1563]\tLoss   0.28\tAcc  90.54\tTime/batch 0.056\n",
      "Epoch: [64][ 199/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.056\n",
      "Epoch: [64][ 249/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.056\n",
      "Epoch: [64][ 299/1563]\tLoss   0.28\tAcc  90.49\tTime/batch 0.056\n",
      "Epoch: [64][ 349/1563]\tLoss   0.28\tAcc  90.50\tTime/batch 0.056\n",
      "Epoch: [64][ 399/1563]\tLoss   0.28\tAcc  90.41\tTime/batch 0.056\n",
      "Epoch: [64][ 449/1563]\tLoss   0.28\tAcc  90.40\tTime/batch 0.056\n",
      "Epoch: [64][ 499/1563]\tLoss   0.28\tAcc  90.45\tTime/batch 0.056\n",
      "Epoch: [64][ 549/1563]\tLoss   0.28\tAcc  90.38\tTime/batch 0.056\n",
      "Epoch: [64][ 599/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.056\n",
      "Epoch: [64][ 649/1563]\tLoss   0.29\tAcc  90.16\tTime/batch 0.056\n",
      "Epoch: [64][ 699/1563]\tLoss   0.29\tAcc  89.98\tTime/batch 0.056\n",
      "Epoch: [64][ 749/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.056\n",
      "Epoch: [64][ 799/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.056\n",
      "Epoch: [64][ 849/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.056\n",
      "Epoch: [64][ 899/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.056\n",
      "Epoch: [64][ 949/1563]\tLoss   0.29\tAcc  89.83\tTime/batch 0.056\n",
      "Epoch: [64][ 999/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.056\n",
      "Epoch: [64][1049/1563]\tLoss   0.29\tAcc  89.81\tTime/batch 0.056\n",
      "Epoch: [64][1099/1563]\tLoss   0.29\tAcc  89.78\tTime/batch 0.056\n",
      "Epoch: [64][1149/1563]\tLoss   0.29\tAcc  89.69\tTime/batch 0.056\n",
      "Epoch: [64][1199/1563]\tLoss   0.29\tAcc  89.73\tTime/batch 0.056\n",
      "Epoch: [64][1249/1563]\tLoss   0.29\tAcc  89.66\tTime/batch 0.056\n",
      "Epoch: [64][1299/1563]\tLoss   0.29\tAcc  89.66\tTime/batch 0.056\n",
      "Epoch: [64][1349/1563]\tLoss   0.29\tAcc  89.62\tTime/batch 0.056\n",
      "Epoch: [64][1399/1563]\tLoss   0.29\tAcc  89.64\tTime/batch 0.056\n",
      "Epoch: [64][1449/1563]\tLoss   0.29\tAcc  89.67\tTime/batch 0.056\n",
      "Epoch: [64][1499/1563]\tLoss   0.29\tAcc  89.71\tTime/batch 0.056\n",
      "Epoch: [64][1549/1563]\tLoss   0.29\tAcc  89.74\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [65][  49/1563]\tLoss   0.26\tAcc  91.44\tTime/batch 0.058\n",
      "Epoch: [65][  99/1563]\tLoss   0.27\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [65][ 149/1563]\tLoss   0.28\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [65][ 199/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [65][ 249/1563]\tLoss   0.29\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [65][ 299/1563]\tLoss   0.29\tAcc  89.96\tTime/batch 0.057\n",
      "Epoch: [65][ 349/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [65][ 399/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [65][ 449/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [65][ 499/1563]\tLoss   0.29\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [65][ 549/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [65][ 599/1563]\tLoss   0.29\tAcc  90.00\tTime/batch 0.057\n",
      "Epoch: [65][ 649/1563]\tLoss   0.29\tAcc  89.93\tTime/batch 0.057\n",
      "Epoch: [65][ 699/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.057\n",
      "Epoch: [65][ 749/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [65][ 799/1563]\tLoss   0.29\tAcc  89.86\tTime/batch 0.057\n",
      "Epoch: [65][ 849/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [65][ 899/1563]\tLoss   0.29\tAcc  89.80\tTime/batch 0.057\n",
      "Epoch: [65][ 949/1563]\tLoss   0.29\tAcc  89.87\tTime/batch 0.057\n",
      "Epoch: [65][ 999/1563]\tLoss   0.29\tAcc  89.85\tTime/batch 0.057\n",
      "Epoch: [65][1049/1563]\tLoss   0.29\tAcc  89.91\tTime/batch 0.057\n",
      "Epoch: [65][1099/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [65][1149/1563]\tLoss   0.29\tAcc  89.90\tTime/batch 0.057\n",
      "Epoch: [65][1199/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [65][1249/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "Epoch: [65][1299/1563]\tLoss   0.29\tAcc  89.88\tTime/batch 0.057\n",
      "Epoch: [65][1349/1563]\tLoss   0.29\tAcc  89.86\tTime/batch 0.057\n",
      "Epoch: [65][1399/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [65][1449/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [65][1499/1563]\tLoss   0.29\tAcc  89.84\tTime/batch 0.057\n",
      "Epoch: [65][1549/1563]\tLoss   0.29\tAcc  89.81\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [66][  49/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.058\n",
      "Epoch: [66][  99/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.058\n",
      "Epoch: [66][ 149/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [66][ 199/1563]\tLoss   0.28\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [66][ 249/1563]\tLoss   0.29\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [66][ 299/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [66][ 349/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.057\n",
      "Epoch: [66][ 399/1563]\tLoss   0.29\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [66][ 449/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.057\n",
      "Epoch: [66][ 499/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [66][ 549/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [66][ 599/1563]\tLoss   0.28\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [66][ 649/1563]\tLoss   0.28\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [66][ 699/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [66][ 749/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [66][ 799/1563]\tLoss   0.28\tAcc  90.30\tTime/batch 0.057\n",
      "Epoch: [66][ 849/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [66][ 899/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [66][ 949/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [66][ 999/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [66][1049/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [66][1099/1563]\tLoss   0.28\tAcc  90.15\tTime/batch 0.057\n",
      "Epoch: [66][1149/1563]\tLoss   0.28\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [66][1199/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [66][1249/1563]\tLoss   0.29\tAcc  90.06\tTime/batch 0.057\n",
      "Epoch: [66][1299/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [66][1349/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [66][1399/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [66][1449/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [66][1499/1563]\tLoss   0.29\tAcc  89.98\tTime/batch 0.057\n",
      "Epoch: [66][1549/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [67][  49/1563]\tLoss   0.29\tAcc  90.00\tTime/batch 0.058\n",
      "Epoch: [67][  99/1563]\tLoss   0.28\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [67][ 149/1563]\tLoss   0.27\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [67][ 199/1563]\tLoss   0.27\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [67][ 249/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.057\n",
      "Epoch: [67][ 299/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [67][ 349/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.056\n",
      "Epoch: [67][ 399/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.056\n",
      "Epoch: [67][ 449/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.056\n",
      "Epoch: [67][ 499/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.056\n",
      "Epoch: [67][ 549/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.056\n",
      "Epoch: [67][ 599/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.056\n",
      "Epoch: [67][ 649/1563]\tLoss   0.28\tAcc  90.13\tTime/batch 0.056\n",
      "Epoch: [67][ 699/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.056\n",
      "Epoch: [67][ 749/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.056\n",
      "Epoch: [67][ 799/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.056\n",
      "Epoch: [67][ 849/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.056\n",
      "Epoch: [67][ 899/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.056\n",
      "Epoch: [67][ 949/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.056\n",
      "Epoch: [67][ 999/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.056\n",
      "Epoch: [67][1049/1563]\tLoss   0.28\tAcc  89.99\tTime/batch 0.056\n",
      "Epoch: [67][1099/1563]\tLoss   0.29\tAcc  89.93\tTime/batch 0.056\n",
      "Epoch: [67][1149/1563]\tLoss   0.29\tAcc  89.93\tTime/batch 0.056\n",
      "Epoch: [67][1199/1563]\tLoss   0.28\tAcc  89.96\tTime/batch 0.056\n",
      "Epoch: [67][1249/1563]\tLoss   0.28\tAcc  89.97\tTime/batch 0.056\n",
      "Epoch: [67][1299/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.056\n",
      "Epoch: [67][1349/1563]\tLoss   0.28\tAcc  90.01\tTime/batch 0.056\n",
      "Epoch: [67][1399/1563]\tLoss   0.28\tAcc  90.00\tTime/batch 0.056\n",
      "Epoch: [67][1449/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.056\n",
      "Epoch: [67][1499/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.056\n",
      "Epoch: [67][1549/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [68][  49/1563]\tLoss   0.28\tAcc  90.00\tTime/batch 0.058\n",
      "Epoch: [68][  99/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [68][ 149/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [68][ 199/1563]\tLoss   0.28\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [68][ 249/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [68][ 299/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [68][ 349/1563]\tLoss   0.28\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [68][ 399/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [68][ 449/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [68][ 499/1563]\tLoss   0.28\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [68][ 549/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [68][ 599/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [68][ 649/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [68][ 699/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.056\n",
      "Epoch: [68][ 749/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.056\n",
      "Epoch: [68][ 799/1563]\tLoss   0.28\tAcc  90.36\tTime/batch 0.056\n",
      "Epoch: [68][ 849/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.056\n",
      "Epoch: [68][ 899/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.056\n",
      "Epoch: [68][ 949/1563]\tLoss   0.28\tAcc  90.36\tTime/batch 0.056\n",
      "Epoch: [68][ 999/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.056\n",
      "Epoch: [68][1049/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.056\n",
      "Epoch: [68][1099/1563]\tLoss   0.28\tAcc  90.24\tTime/batch 0.056\n",
      "Epoch: [68][1149/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.056\n",
      "Epoch: [68][1199/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.056\n",
      "Epoch: [68][1249/1563]\tLoss   0.28\tAcc  90.32\tTime/batch 0.056\n",
      "Epoch: [68][1299/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.056\n",
      "Epoch: [68][1349/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.056\n",
      "Epoch: [68][1399/1563]\tLoss   0.28\tAcc  90.20\tTime/batch 0.056\n",
      "Epoch: [68][1449/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.056\n",
      "Epoch: [68][1499/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.056\n",
      "Epoch: [68][1549/1563]\tLoss   0.28\tAcc  90.15\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [69][  49/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.058\n",
      "Epoch: [69][  99/1563]\tLoss   0.27\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [69][ 149/1563]\tLoss   0.27\tAcc  91.38\tTime/batch 0.057\n",
      "Epoch: [69][ 199/1563]\tLoss   0.27\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [69][ 249/1563]\tLoss   0.27\tAcc  90.71\tTime/batch 0.057\n",
      "Epoch: [69][ 299/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [69][ 349/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [69][ 399/1563]\tLoss   0.28\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [69][ 449/1563]\tLoss   0.28\tAcc  90.51\tTime/batch 0.057\n",
      "Epoch: [69][ 499/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.057\n",
      "Epoch: [69][ 549/1563]\tLoss   0.28\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [69][ 599/1563]\tLoss   0.28\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [69][ 649/1563]\tLoss   0.28\tAcc  90.35\tTime/batch 0.057\n",
      "Epoch: [69][ 699/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [69][ 749/1563]\tLoss   0.29\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [69][ 799/1563]\tLoss   0.29\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [69][ 849/1563]\tLoss   0.29\tAcc  90.00\tTime/batch 0.057\n",
      "Epoch: [69][ 899/1563]\tLoss   0.29\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [69][ 949/1563]\tLoss   0.29\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [69][ 999/1563]\tLoss   0.29\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [69][1049/1563]\tLoss   0.29\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [69][1099/1563]\tLoss   0.29\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [69][1149/1563]\tLoss   0.29\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [69][1199/1563]\tLoss   0.29\tAcc  90.15\tTime/batch 0.057\n",
      "Epoch: [69][1249/1563]\tLoss   0.29\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [69][1299/1563]\tLoss   0.29\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [69][1349/1563]\tLoss   0.29\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [69][1399/1563]\tLoss   0.29\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [69][1449/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [69][1499/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [69][1549/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [70][  49/1563]\tLoss   0.28\tAcc  89.19\tTime/batch 0.058\n",
      "Epoch: [70][  99/1563]\tLoss   0.26\tAcc  90.03\tTime/batch 0.058\n",
      "Epoch: [70][ 149/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.058\n",
      "Epoch: [70][ 199/1563]\tLoss   0.26\tAcc  90.50\tTime/batch 0.058\n",
      "Epoch: [70][ 249/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.058\n",
      "Epoch: [70][ 299/1563]\tLoss   0.27\tAcc  90.51\tTime/batch 0.058\n",
      "Epoch: [70][ 349/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.058\n",
      "Epoch: [70][ 399/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [70][ 449/1563]\tLoss   0.28\tAcc  90.30\tTime/batch 0.057\n",
      "Epoch: [70][ 499/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [70][ 549/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [70][ 599/1563]\tLoss   0.28\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [70][ 649/1563]\tLoss   0.28\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [70][ 699/1563]\tLoss   0.28\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [70][ 749/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [70][ 799/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [70][ 849/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [70][ 899/1563]\tLoss   0.28\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [70][ 949/1563]\tLoss   0.28\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [70][ 999/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [70][1049/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [70][1099/1563]\tLoss   0.28\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [70][1149/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [70][1199/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [70][1249/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [70][1299/1563]\tLoss   0.28\tAcc  90.06\tTime/batch 0.057\n",
      "Epoch: [70][1349/1563]\tLoss   0.28\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [70][1399/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [70][1449/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [70][1499/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [70][1549/1563]\tLoss   0.29\tAcc  89.97\tTime/batch 0.057\n",
      "epoch 70\n",
      "Accuracy of the network on the 10000 test images: 87.0 %\n",
      "Sparsity of the update phase: 67.1 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [71][  49/1563]\tLoss   0.28\tAcc  90.00\tTime/batch 0.059\n",
      "Epoch: [71][  99/1563]\tLoss   0.25\tAcc  91.12\tTime/batch 0.058\n",
      "Epoch: [71][ 149/1563]\tLoss   0.27\tAcc  90.35\tTime/batch 0.058\n",
      "Epoch: [71][ 199/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [71][ 249/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "Epoch: [71][ 299/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [71][ 349/1563]\tLoss   0.28\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [71][ 399/1563]\tLoss   0.28\tAcc  90.36\tTime/batch 0.057\n",
      "Epoch: [71][ 449/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [71][ 499/1563]\tLoss   0.28\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [71][ 549/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [71][ 599/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [71][ 649/1563]\tLoss   0.28\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [71][ 699/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [71][ 749/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [71][ 799/1563]\tLoss   0.29\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [71][ 849/1563]\tLoss   0.29\tAcc  90.07\tTime/batch 0.057\n",
      "Epoch: [71][ 899/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [71][ 949/1563]\tLoss   0.29\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [71][ 999/1563]\tLoss   0.28\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [71][1049/1563]\tLoss   0.29\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [71][1099/1563]\tLoss   0.29\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [71][1149/1563]\tLoss   0.29\tAcc  89.95\tTime/batch 0.057\n",
      "Epoch: [71][1199/1563]\tLoss   0.29\tAcc  89.92\tTime/batch 0.057\n",
      "Epoch: [71][1249/1563]\tLoss   0.29\tAcc  89.96\tTime/batch 0.057\n",
      "Epoch: [71][1299/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [71][1349/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [71][1399/1563]\tLoss   0.29\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [71][1449/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [71][1499/1563]\tLoss   0.29\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [71][1549/1563]\tLoss   0.29\tAcc  89.99\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [72][  49/1563]\tLoss   0.30\tAcc  90.06\tTime/batch 0.058\n",
      "Epoch: [72][  99/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [72][ 149/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [72][ 199/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [72][ 249/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [72][ 299/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [72][ 349/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [72][ 399/1563]\tLoss   0.27\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [72][ 449/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [72][ 499/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [72][ 549/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [72][ 599/1563]\tLoss   0.28\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [72][ 649/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [72][ 699/1563]\tLoss   0.28\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [72][ 749/1563]\tLoss   0.28\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [72][ 799/1563]\tLoss   0.28\tAcc  90.36\tTime/batch 0.057\n",
      "Epoch: [72][ 849/1563]\tLoss   0.28\tAcc  90.32\tTime/batch 0.057\n",
      "Epoch: [72][ 899/1563]\tLoss   0.28\tAcc  90.35\tTime/batch 0.057\n",
      "Epoch: [72][ 949/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [72][ 999/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [72][1049/1563]\tLoss   0.28\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [72][1099/1563]\tLoss   0.28\tAcc  90.41\tTime/batch 0.057\n",
      "Epoch: [72][1149/1563]\tLoss   0.28\tAcc  90.35\tTime/batch 0.057\n",
      "Epoch: [72][1199/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [72][1249/1563]\tLoss   0.28\tAcc  90.21\tTime/batch 0.057\n",
      "Epoch: [72][1299/1563]\tLoss   0.28\tAcc  90.20\tTime/batch 0.057\n",
      "Epoch: [72][1349/1563]\tLoss   0.28\tAcc  90.21\tTime/batch 0.057\n",
      "Epoch: [72][1399/1563]\tLoss   0.28\tAcc  90.23\tTime/batch 0.057\n",
      "Epoch: [72][1449/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [72][1499/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [72][1549/1563]\tLoss   0.28\tAcc  90.24\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [73][  49/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.058\n",
      "Epoch: [73][  99/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [73][ 149/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [73][ 199/1563]\tLoss   0.26\tAcc  90.95\tTime/batch 0.057\n",
      "Epoch: [73][ 249/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [73][ 299/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [73][ 349/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [73][ 399/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [73][ 449/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [73][ 499/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [73][ 549/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [73][ 599/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.057\n",
      "Epoch: [73][ 649/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.057\n",
      "Epoch: [73][ 699/1563]\tLoss   0.27\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [73][ 749/1563]\tLoss   0.28\tAcc  90.32\tTime/batch 0.057\n",
      "Epoch: [73][ 799/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [73][ 849/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [73][ 899/1563]\tLoss   0.27\tAcc  90.36\tTime/batch 0.057\n",
      "Epoch: [73][ 949/1563]\tLoss   0.27\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [73][ 999/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [73][1049/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [73][1099/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [73][1149/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [73][1199/1563]\tLoss   0.28\tAcc  90.24\tTime/batch 0.057\n",
      "Epoch: [73][1249/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [73][1299/1563]\tLoss   0.28\tAcc  90.24\tTime/batch 0.057\n",
      "Epoch: [73][1349/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [73][1399/1563]\tLoss   0.28\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [73][1449/1563]\tLoss   0.28\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [73][1499/1563]\tLoss   0.28\tAcc  90.10\tTime/batch 0.057\n",
      "Epoch: [73][1549/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [74][  49/1563]\tLoss   0.31\tAcc  88.50\tTime/batch 0.058\n",
      "Epoch: [74][  99/1563]\tLoss   0.29\tAcc  89.38\tTime/batch 0.057\n",
      "Epoch: [74][ 149/1563]\tLoss   0.28\tAcc  90.21\tTime/batch 0.057\n",
      "Epoch: [74][ 199/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [74][ 249/1563]\tLoss   0.26\tAcc  90.99\tTime/batch 0.057\n",
      "Epoch: [74][ 299/1563]\tLoss   0.27\tAcc  90.82\tTime/batch 0.057\n",
      "Epoch: [74][ 349/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [74][ 399/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [74][ 449/1563]\tLoss   0.28\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [74][ 499/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [74][ 549/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [74][ 599/1563]\tLoss   0.28\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [74][ 649/1563]\tLoss   0.27\tAcc  90.43\tTime/batch 0.057\n",
      "Epoch: [74][ 699/1563]\tLoss   0.28\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [74][ 749/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.057\n",
      "Epoch: [74][ 799/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [74][ 849/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [74][ 899/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [74][ 949/1563]\tLoss   0.28\tAcc  90.45\tTime/batch 0.057\n",
      "Epoch: [74][ 999/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [74][1049/1563]\tLoss   0.28\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [74][1099/1563]\tLoss   0.28\tAcc  90.41\tTime/batch 0.057\n",
      "Epoch: [74][1149/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [74][1199/1563]\tLoss   0.28\tAcc  90.36\tTime/batch 0.057\n",
      "Epoch: [74][1249/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [74][1299/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [74][1349/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [74][1399/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [74][1449/1563]\tLoss   0.28\tAcc  90.26\tTime/batch 0.057\n",
      "Epoch: [74][1499/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [74][1549/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [75][  49/1563]\tLoss   0.29\tAcc  88.75\tTime/batch 0.058\n",
      "Epoch: [75][  99/1563]\tLoss   0.27\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [75][ 149/1563]\tLoss   0.27\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [75][ 199/1563]\tLoss   0.26\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [75][ 249/1563]\tLoss   0.26\tAcc  90.51\tTime/batch 0.057\n",
      "Epoch: [75][ 299/1563]\tLoss   0.26\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [75][ 349/1563]\tLoss   0.27\tAcc  90.15\tTime/batch 0.057\n",
      "Epoch: [75][ 399/1563]\tLoss   0.27\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [75][ 449/1563]\tLoss   0.27\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [75][ 499/1563]\tLoss   0.27\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [75][ 549/1563]\tLoss   0.27\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [75][ 599/1563]\tLoss   0.27\tAcc  90.35\tTime/batch 0.057\n",
      "Epoch: [75][ 649/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.057\n",
      "Epoch: [75][ 699/1563]\tLoss   0.27\tAcc  90.39\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [75][ 749/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [75][ 799/1563]\tLoss   0.27\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [75][ 849/1563]\tLoss   0.27\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [75][ 899/1563]\tLoss   0.27\tAcc  90.24\tTime/batch 0.057\n",
      "Epoch: [75][ 949/1563]\tLoss   0.27\tAcc  90.32\tTime/batch 0.057\n",
      "Epoch: [75][ 999/1563]\tLoss   0.27\tAcc  90.30\tTime/batch 0.057\n",
      "Epoch: [75][1049/1563]\tLoss   0.27\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [75][1099/1563]\tLoss   0.27\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [75][1149/1563]\tLoss   0.27\tAcc  90.23\tTime/batch 0.057\n",
      "Epoch: [75][1199/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [75][1249/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [75][1299/1563]\tLoss   0.28\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [75][1349/1563]\tLoss   0.28\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [75][1399/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [75][1449/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [75][1499/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [75][1549/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [76][  49/1563]\tLoss   0.26\tAcc  90.44\tTime/batch 0.058\n",
      "Epoch: [76][  99/1563]\tLoss   0.27\tAcc  89.94\tTime/batch 0.057\n",
      "Epoch: [76][ 149/1563]\tLoss   0.27\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [76][ 199/1563]\tLoss   0.27\tAcc  90.23\tTime/batch 0.057\n",
      "Epoch: [76][ 249/1563]\tLoss   0.27\tAcc  90.20\tTime/batch 0.056\n",
      "Epoch: [76][ 299/1563]\tLoss   0.26\tAcc  90.52\tTime/batch 0.056\n",
      "Epoch: [76][ 349/1563]\tLoss   0.26\tAcc  90.49\tTime/batch 0.056\n",
      "Epoch: [76][ 399/1563]\tLoss   0.26\tAcc  90.53\tTime/batch 0.056\n",
      "Epoch: [76][ 449/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.056\n",
      "Epoch: [76][ 499/1563]\tLoss   0.27\tAcc  90.33\tTime/batch 0.056\n",
      "Epoch: [76][ 549/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.056\n",
      "Epoch: [76][ 599/1563]\tLoss   0.27\tAcc  90.40\tTime/batch 0.056\n",
      "Epoch: [76][ 649/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.056\n",
      "Epoch: [76][ 699/1563]\tLoss   0.26\tAcc  90.55\tTime/batch 0.056\n",
      "Epoch: [76][ 749/1563]\tLoss   0.26\tAcc  90.53\tTime/batch 0.056\n",
      "Epoch: [76][ 799/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.056\n",
      "Epoch: [76][ 849/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.056\n",
      "Epoch: [76][ 899/1563]\tLoss   0.27\tAcc  90.43\tTime/batch 0.056\n",
      "Epoch: [76][ 949/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.056\n",
      "Epoch: [76][ 999/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.056\n",
      "Epoch: [76][1049/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.056\n",
      "Epoch: [76][1099/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.056\n",
      "Epoch: [76][1149/1563]\tLoss   0.27\tAcc  90.39\tTime/batch 0.056\n",
      "Epoch: [76][1199/1563]\tLoss   0.27\tAcc  90.37\tTime/batch 0.056\n",
      "Epoch: [76][1249/1563]\tLoss   0.27\tAcc  90.32\tTime/batch 0.056\n",
      "Epoch: [76][1299/1563]\tLoss   0.27\tAcc  90.30\tTime/batch 0.056\n",
      "Epoch: [76][1349/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.056\n",
      "Epoch: [76][1399/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.056\n",
      "Epoch: [76][1449/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.056\n",
      "Epoch: [76][1499/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [76][1549/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [77][  49/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [77][  99/1563]\tLoss   0.26\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [77][ 149/1563]\tLoss   0.25\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [77][ 199/1563]\tLoss   0.25\tAcc  91.27\tTime/batch 0.057\n",
      "Epoch: [77][ 249/1563]\tLoss   0.26\tAcc  91.01\tTime/batch 0.057\n",
      "Epoch: [77][ 299/1563]\tLoss   0.26\tAcc  91.01\tTime/batch 0.057\n",
      "Epoch: [77][ 349/1563]\tLoss   0.26\tAcc  91.11\tTime/batch 0.057\n",
      "Epoch: [77][ 399/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [77][ 449/1563]\tLoss   0.26\tAcc  91.03\tTime/batch 0.057\n",
      "Epoch: [77][ 499/1563]\tLoss   0.27\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [77][ 549/1563]\tLoss   0.27\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [77][ 599/1563]\tLoss   0.27\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [77][ 649/1563]\tLoss   0.27\tAcc  90.86\tTime/batch 0.057\n",
      "Epoch: [77][ 699/1563]\tLoss   0.27\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [77][ 749/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [77][ 799/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [77][ 849/1563]\tLoss   0.27\tAcc  90.71\tTime/batch 0.057\n",
      "Epoch: [77][ 899/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [77][ 949/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [77][ 999/1563]\tLoss   0.27\tAcc  90.77\tTime/batch 0.057\n",
      "Epoch: [77][1049/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [77][1099/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [77][1149/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [77][1199/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [77][1249/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [77][1299/1563]\tLoss   0.28\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [77][1349/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [77][1399/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [77][1449/1563]\tLoss   0.28\tAcc  90.47\tTime/batch 0.057\n",
      "Epoch: [77][1499/1563]\tLoss   0.28\tAcc  90.45\tTime/batch 0.057\n",
      "Epoch: [77][1549/1563]\tLoss   0.28\tAcc  90.41\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [78][  49/1563]\tLoss   0.26\tAcc  91.31\tTime/batch 0.058\n",
      "Epoch: [78][  99/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.058\n",
      "Epoch: [78][ 149/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.058\n",
      "Epoch: [78][ 199/1563]\tLoss   0.27\tAcc  90.78\tTime/batch 0.058\n",
      "Epoch: [78][ 249/1563]\tLoss   0.26\tAcc  91.06\tTime/batch 0.058\n",
      "Epoch: [78][ 299/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.058\n",
      "Epoch: [78][ 349/1563]\tLoss   0.27\tAcc  90.88\tTime/batch 0.058\n",
      "Epoch: [78][ 399/1563]\tLoss   0.27\tAcc  90.88\tTime/batch 0.058\n",
      "Epoch: [78][ 449/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.058\n",
      "Epoch: [78][ 499/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.058\n",
      "Epoch: [78][ 549/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.058\n",
      "Epoch: [78][ 599/1563]\tLoss   0.26\tAcc  90.89\tTime/batch 0.058\n",
      "Epoch: [78][ 649/1563]\tLoss   0.26\tAcc  90.85\tTime/batch 0.058\n",
      "Epoch: [78][ 699/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.058\n",
      "Epoch: [78][ 749/1563]\tLoss   0.27\tAcc  90.75\tTime/batch 0.058\n",
      "Epoch: [78][ 799/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [78][ 849/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [78][ 899/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [78][ 949/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [78][ 999/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [78][1049/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [78][1099/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [78][1149/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "Epoch: [78][1199/1563]\tLoss   0.27\tAcc  90.71\tTime/batch 0.057\n",
      "Epoch: [78][1249/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [78][1299/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [78][1349/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [78][1399/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [78][1449/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [78][1499/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [78][1549/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [79][  49/1563]\tLoss   0.30\tAcc  89.44\tTime/batch 0.057\n",
      "Epoch: [79][  99/1563]\tLoss   0.29\tAcc  89.41\tTime/batch 0.057\n",
      "Epoch: [79][ 149/1563]\tLoss   0.29\tAcc  89.52\tTime/batch 0.057\n",
      "Epoch: [79][ 199/1563]\tLoss   0.29\tAcc  89.89\tTime/batch 0.057\n",
      "Epoch: [79][ 249/1563]\tLoss   0.28\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [79][ 299/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [79][ 349/1563]\tLoss   0.28\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [79][ 399/1563]\tLoss   0.28\tAcc  89.99\tTime/batch 0.057\n",
      "Epoch: [79][ 449/1563]\tLoss   0.28\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [79][ 499/1563]\tLoss   0.28\tAcc  90.19\tTime/batch 0.057\n",
      "Epoch: [79][ 549/1563]\tLoss   0.28\tAcc  90.05\tTime/batch 0.057\n",
      "Epoch: [79][ 599/1563]\tLoss   0.28\tAcc  90.13\tTime/batch 0.057\n",
      "Epoch: [79][ 649/1563]\tLoss   0.28\tAcc  90.01\tTime/batch 0.057\n",
      "Epoch: [79][ 699/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [79][ 749/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.057\n",
      "Epoch: [79][ 799/1563]\tLoss   0.28\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [79][ 849/1563]\tLoss   0.28\tAcc  89.97\tTime/batch 0.057\n",
      "Epoch: [79][ 899/1563]\tLoss   0.28\tAcc  89.99\tTime/batch 0.057\n",
      "Epoch: [79][ 949/1563]\tLoss   0.28\tAcc  90.04\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [79][ 999/1563]\tLoss   0.28\tAcc  90.21\tTime/batch 0.057\n",
      "Epoch: [79][1049/1563]\tLoss   0.28\tAcc  90.22\tTime/batch 0.057\n",
      "Epoch: [79][1099/1563]\tLoss   0.28\tAcc  90.20\tTime/batch 0.057\n",
      "Epoch: [79][1149/1563]\tLoss   0.28\tAcc  90.17\tTime/batch 0.057\n",
      "Epoch: [79][1199/1563]\tLoss   0.28\tAcc  90.15\tTime/batch 0.057\n",
      "Epoch: [79][1249/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [79][1299/1563]\tLoss   0.28\tAcc  90.11\tTime/batch 0.057\n",
      "Epoch: [79][1349/1563]\tLoss   0.28\tAcc  90.09\tTime/batch 0.057\n",
      "Epoch: [79][1399/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [79][1449/1563]\tLoss   0.28\tAcc  90.08\tTime/batch 0.057\n",
      "Epoch: [79][1499/1563]\tLoss   0.28\tAcc  90.02\tTime/batch 0.057\n",
      "Epoch: [79][1549/1563]\tLoss   0.28\tAcc  90.06\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [80][  49/1563]\tLoss   0.25\tAcc  91.31\tTime/batch 0.058\n",
      "Epoch: [80][  99/1563]\tLoss   0.25\tAcc  91.25\tTime/batch 0.058\n",
      "Epoch: [80][ 149/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.058\n",
      "Epoch: [80][ 199/1563]\tLoss   0.26\tAcc  90.53\tTime/batch 0.058\n",
      "Epoch: [80][ 249/1563]\tLoss   0.26\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [80][ 299/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.057\n",
      "Epoch: [80][ 349/1563]\tLoss   0.26\tAcc  90.95\tTime/batch 0.057\n",
      "Epoch: [80][ 399/1563]\tLoss   0.26\tAcc  91.06\tTime/batch 0.057\n",
      "Epoch: [80][ 449/1563]\tLoss   0.25\tAcc  91.15\tTime/batch 0.056\n",
      "Epoch: [80][ 499/1563]\tLoss   0.26\tAcc  91.01\tTime/batch 0.056\n",
      "Epoch: [80][ 549/1563]\tLoss   0.26\tAcc  91.01\tTime/batch 0.056\n",
      "Epoch: [80][ 599/1563]\tLoss   0.26\tAcc  91.00\tTime/batch 0.056\n",
      "Epoch: [80][ 649/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.056\n",
      "Epoch: [80][ 699/1563]\tLoss   0.26\tAcc  90.95\tTime/batch 0.056\n",
      "Epoch: [80][ 749/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.056\n",
      "Epoch: [80][ 799/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.056\n",
      "Epoch: [80][ 849/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.056\n",
      "Epoch: [80][ 899/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.056\n",
      "Epoch: [80][ 949/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.056\n",
      "Epoch: [80][ 999/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.056\n",
      "Epoch: [80][1049/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.056\n",
      "Epoch: [80][1099/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.056\n",
      "Epoch: [80][1149/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.056\n",
      "Epoch: [80][1199/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.056\n",
      "Epoch: [80][1249/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.056\n",
      "Epoch: [80][1299/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.056\n",
      "Epoch: [80][1349/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.056\n",
      "Epoch: [80][1399/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.056\n",
      "Epoch: [80][1449/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.056\n",
      "Epoch: [80][1499/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.056\n",
      "Epoch: [80][1549/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.056\n",
      "epoch 80\n",
      "Accuracy of the network on the 10000 test images: 85.9 %\n",
      "Sparsity of the update phase: 68.0 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [81][  49/1563]\tLoss   0.27\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [81][  99/1563]\tLoss   0.28\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [81][ 149/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [81][ 199/1563]\tLoss   0.29\tAcc  90.03\tTime/batch 0.057\n",
      "Epoch: [81][ 249/1563]\tLoss   0.28\tAcc  90.33\tTime/batch 0.057\n",
      "Epoch: [81][ 299/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [81][ 349/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [81][ 399/1563]\tLoss   0.27\tAcc  90.43\tTime/batch 0.057\n",
      "Epoch: [81][ 449/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [81][ 499/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [81][ 549/1563]\tLoss   0.27\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [81][ 599/1563]\tLoss   0.28\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [81][ 649/1563]\tLoss   0.28\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [81][ 699/1563]\tLoss   0.28\tAcc  90.23\tTime/batch 0.057\n",
      "Epoch: [81][ 749/1563]\tLoss   0.28\tAcc  90.15\tTime/batch 0.057\n",
      "Epoch: [81][ 799/1563]\tLoss   0.28\tAcc  90.12\tTime/batch 0.057\n",
      "Epoch: [81][ 849/1563]\tLoss   0.28\tAcc  90.14\tTime/batch 0.057\n",
      "Epoch: [81][ 899/1563]\tLoss   0.28\tAcc  90.20\tTime/batch 0.057\n",
      "Epoch: [81][ 949/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [81][ 999/1563]\tLoss   0.28\tAcc  90.15\tTime/batch 0.057\n",
      "Epoch: [81][1049/1563]\tLoss   0.28\tAcc  90.16\tTime/batch 0.057\n",
      "Epoch: [81][1099/1563]\tLoss   0.28\tAcc  90.18\tTime/batch 0.057\n",
      "Epoch: [81][1149/1563]\tLoss   0.28\tAcc  90.20\tTime/batch 0.057\n",
      "Epoch: [81][1199/1563]\tLoss   0.28\tAcc  90.23\tTime/batch 0.057\n",
      "Epoch: [81][1249/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [81][1299/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [81][1349/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [81][1399/1563]\tLoss   0.28\tAcc  90.25\tTime/batch 0.057\n",
      "Epoch: [81][1449/1563]\tLoss   0.28\tAcc  90.30\tTime/batch 0.057\n",
      "Epoch: [81][1499/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "Epoch: [81][1549/1563]\tLoss   0.28\tAcc  90.29\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [82][  49/1563]\tLoss   0.26\tAcc  90.38\tTime/batch 0.058\n",
      "Epoch: [82][  99/1563]\tLoss   0.26\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [82][ 149/1563]\tLoss   0.25\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [82][ 199/1563]\tLoss   0.25\tAcc  91.06\tTime/batch 0.057\n",
      "Epoch: [82][ 249/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [82][ 299/1563]\tLoss   0.26\tAcc  90.84\tTime/batch 0.057\n",
      "Epoch: [82][ 349/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [82][ 399/1563]\tLoss   0.26\tAcc  90.93\tTime/batch 0.057\n",
      "Epoch: [82][ 449/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [82][ 499/1563]\tLoss   0.26\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [82][ 549/1563]\tLoss   0.26\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [82][ 599/1563]\tLoss   0.26\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [82][ 649/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [82][ 699/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [82][ 749/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [82][ 799/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [82][ 849/1563]\tLoss   0.27\tAcc  90.71\tTime/batch 0.057\n",
      "Epoch: [82][ 899/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [82][ 949/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [82][ 999/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [82][1049/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [82][1099/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [82][1149/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [82][1199/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [82][1249/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [82][1299/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [82][1349/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [82][1399/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [82][1449/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.057\n",
      "Epoch: [82][1499/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [82][1549/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [83][  49/1563]\tLoss   0.29\tAcc  90.25\tTime/batch 0.058\n",
      "Epoch: [83][  99/1563]\tLoss   0.25\tAcc  91.59\tTime/batch 0.057\n",
      "Epoch: [83][ 149/1563]\tLoss   0.26\tAcc  91.17\tTime/batch 0.057\n",
      "Epoch: [83][ 199/1563]\tLoss   0.26\tAcc  90.84\tTime/batch 0.057\n",
      "Epoch: [83][ 249/1563]\tLoss   0.26\tAcc  91.01\tTime/batch 0.057\n",
      "Epoch: [83][ 299/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [83][ 349/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.057\n",
      "Epoch: [83][ 399/1563]\tLoss   0.26\tAcc  91.02\tTime/batch 0.057\n",
      "Epoch: [83][ 449/1563]\tLoss   0.26\tAcc  90.99\tTime/batch 0.057\n",
      "Epoch: [83][ 499/1563]\tLoss   0.26\tAcc  91.05\tTime/batch 0.057\n",
      "Epoch: [83][ 549/1563]\tLoss   0.26\tAcc  91.05\tTime/batch 0.057\n",
      "Epoch: [83][ 599/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.057\n",
      "Epoch: [83][ 649/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [83][ 699/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [83][ 749/1563]\tLoss   0.26\tAcc  90.90\tTime/batch 0.057\n",
      "Epoch: [83][ 799/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [83][ 849/1563]\tLoss   0.26\tAcc  90.87\tTime/batch 0.057\n",
      "Epoch: [83][ 899/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [83][ 949/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [83][ 999/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [83][1049/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [83][1099/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [83][1149/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [83][1199/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [83][1249/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [83][1299/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [83][1349/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [83][1399/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "Epoch: [83][1449/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.057\n",
      "Epoch: [83][1499/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.057\n",
      "Epoch: [83][1549/1563]\tLoss   0.27\tAcc  90.39\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [84][  49/1563]\tLoss   0.29\tAcc  89.44\tTime/batch 0.058\n",
      "Epoch: [84][  99/1563]\tLoss   0.30\tAcc  89.41\tTime/batch 0.057\n",
      "Epoch: [84][ 149/1563]\tLoss   0.28\tAcc  89.96\tTime/batch 0.057\n",
      "Epoch: [84][ 199/1563]\tLoss   0.28\tAcc  90.27\tTime/batch 0.057\n",
      "Epoch: [84][ 249/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [84][ 299/1563]\tLoss   0.27\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [84][ 349/1563]\tLoss   0.28\tAcc  90.28\tTime/batch 0.057\n",
      "Epoch: [84][ 399/1563]\tLoss   0.28\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [84][ 449/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [84][ 499/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [84][ 549/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [84][ 599/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [84][ 649/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [84][ 699/1563]\tLoss   0.28\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [84][ 749/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [84][ 799/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [84][ 849/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [84][ 899/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.057\n",
      "Epoch: [84][ 949/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [84][ 999/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.057\n",
      "Epoch: [84][1049/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [84][1099/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [84][1149/1563]\tLoss   0.28\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [84][1199/1563]\tLoss   0.28\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [84][1249/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [84][1299/1563]\tLoss   0.28\tAcc  90.35\tTime/batch 0.057\n",
      "Epoch: [84][1349/1563]\tLoss   0.28\tAcc  90.37\tTime/batch 0.057\n",
      "Epoch: [84][1399/1563]\tLoss   0.28\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [84][1449/1563]\tLoss   0.27\tAcc  90.39\tTime/batch 0.057\n",
      "Epoch: [84][1499/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.057\n",
      "Epoch: [84][1549/1563]\tLoss   0.28\tAcc  90.40\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [85][  49/1563]\tLoss   0.25\tAcc  90.62\tTime/batch 0.059\n",
      "Epoch: [85][  99/1563]\tLoss   0.25\tAcc  90.97\tTime/batch 0.058\n",
      "Epoch: [85][ 149/1563]\tLoss   0.24\tAcc  90.90\tTime/batch 0.058\n",
      "Epoch: [85][ 199/1563]\tLoss   0.25\tAcc  91.08\tTime/batch 0.058\n",
      "Epoch: [85][ 249/1563]\tLoss   0.25\tAcc  91.04\tTime/batch 0.057\n",
      "Epoch: [85][ 299/1563]\tLoss   0.25\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [85][ 349/1563]\tLoss   0.25\tAcc  90.93\tTime/batch 0.057\n",
      "Epoch: [85][ 399/1563]\tLoss   0.26\tAcc  90.93\tTime/batch 0.057\n",
      "Epoch: [85][ 449/1563]\tLoss   0.25\tAcc  90.96\tTime/batch 0.058\n",
      "Epoch: [85][ 499/1563]\tLoss   0.26\tAcc  90.74\tTime/batch 0.058\n",
      "Epoch: [85][ 549/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [85][ 599/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [85][ 649/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [85][ 699/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [85][ 749/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [85][ 799/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [85][ 849/1563]\tLoss   0.26\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [85][ 899/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [85][ 949/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [85][ 999/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [85][1049/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [85][1099/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [85][1149/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.057\n",
      "Epoch: [85][1199/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [85][1249/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [85][1299/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.057\n",
      "Epoch: [85][1349/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [85][1399/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [85][1449/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [85][1499/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [85][1549/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [86][  49/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.057\n",
      "Epoch: [86][  99/1563]\tLoss   0.25\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [86][ 149/1563]\tLoss   0.26\tAcc  90.69\tTime/batch 0.056\n",
      "Epoch: [86][ 199/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.056\n",
      "Epoch: [86][ 249/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.056\n",
      "Epoch: [86][ 299/1563]\tLoss   0.26\tAcc  90.85\tTime/batch 0.056\n",
      "Epoch: [86][ 349/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.056\n",
      "Epoch: [86][ 399/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.056\n",
      "Epoch: [86][ 449/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.056\n",
      "Epoch: [86][ 499/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.056\n",
      "Epoch: [86][ 549/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.056\n",
      "Epoch: [86][ 599/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.056\n",
      "Epoch: [86][ 649/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.056\n",
      "Epoch: [86][ 699/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.056\n",
      "Epoch: [86][ 749/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.056\n",
      "Epoch: [86][ 799/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.056\n",
      "Epoch: [86][ 849/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.056\n",
      "Epoch: [86][ 899/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.056\n",
      "Epoch: [86][ 949/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.056\n",
      "Epoch: [86][ 999/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.056\n",
      "Epoch: [86][1049/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.056\n",
      "Epoch: [86][1099/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.056\n",
      "Epoch: [86][1149/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.056\n",
      "Epoch: [86][1199/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.056\n",
      "Epoch: [86][1249/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.056\n",
      "Epoch: [86][1299/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.056\n",
      "Epoch: [86][1349/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.056\n",
      "Epoch: [86][1399/1563]\tLoss   0.27\tAcc  90.49\tTime/batch 0.056\n",
      "Epoch: [86][1449/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.056\n",
      "Epoch: [86][1499/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.056\n",
      "Epoch: [86][1549/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [87][  49/1563]\tLoss   0.25\tAcc  91.50\tTime/batch 0.057\n",
      "Epoch: [87][  99/1563]\tLoss   0.26\tAcc  91.09\tTime/batch 0.057\n",
      "Epoch: [87][ 149/1563]\tLoss   0.26\tAcc  91.17\tTime/batch 0.056\n",
      "Epoch: [87][ 199/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.056\n",
      "Epoch: [87][ 249/1563]\tLoss   0.26\tAcc  91.04\tTime/batch 0.056\n",
      "Epoch: [87][ 299/1563]\tLoss   0.27\tAcc  90.81\tTime/batch 0.056\n",
      "Epoch: [87][ 349/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.056\n",
      "Epoch: [87][ 399/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.056\n",
      "Epoch: [87][ 449/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.056\n",
      "Epoch: [87][ 499/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.056\n",
      "Epoch: [87][ 549/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.056\n",
      "Epoch: [87][ 599/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.056\n",
      "Epoch: [87][ 649/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.056\n",
      "Epoch: [87][ 699/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.056\n",
      "Epoch: [87][ 749/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [87][ 799/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [87][ 849/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [87][ 899/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [87][ 949/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.057\n",
      "Epoch: [87][ 999/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.057\n",
      "Epoch: [87][1049/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [87][1099/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [87][1149/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "Epoch: [87][1199/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [87][1249/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "Epoch: [87][1299/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.057\n",
      "Epoch: [87][1349/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [87][1399/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.057\n",
      "Epoch: [87][1449/1563]\tLoss   0.27\tAcc  90.40\tTime/batch 0.057\n",
      "Epoch: [87][1499/1563]\tLoss   0.27\tAcc  90.36\tTime/batch 0.057\n",
      "Epoch: [87][1549/1563]\tLoss   0.28\tAcc  90.34\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [88][  49/1563]\tLoss   0.27\tAcc  91.31\tTime/batch 0.058\n",
      "Epoch: [88][  99/1563]\tLoss   0.26\tAcc  91.41\tTime/batch 0.057\n",
      "Epoch: [88][ 149/1563]\tLoss   0.27\tAcc  90.96\tTime/batch 0.057\n",
      "Epoch: [88][ 199/1563]\tLoss   0.27\tAcc  90.92\tTime/batch 0.057\n",
      "Epoch: [88][ 249/1563]\tLoss   0.26\tAcc  90.95\tTime/batch 0.057\n",
      "Epoch: [88][ 299/1563]\tLoss   0.27\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [88][ 349/1563]\tLoss   0.27\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [88][ 399/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "Epoch: [88][ 449/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [88][ 499/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [88][ 549/1563]\tLoss   0.27\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [88][ 599/1563]\tLoss   0.27\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [88][ 649/1563]\tLoss   0.27\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [88][ 699/1563]\tLoss   0.27\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [88][ 749/1563]\tLoss   0.27\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [88][ 799/1563]\tLoss   0.27\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [88][ 849/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [88][ 899/1563]\tLoss   0.27\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [88][ 949/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [88][ 999/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [88][1049/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [88][1099/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [88][1149/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [88][1199/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [88][1249/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [88][1299/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [88][1349/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [88][1399/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [88][1449/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [88][1499/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.057\n",
      "Epoch: [88][1549/1563]\tLoss   0.27\tAcc  90.51\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [89][  49/1563]\tLoss   0.27\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [89][  99/1563]\tLoss   0.27\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [89][ 149/1563]\tLoss   0.26\tAcc  90.98\tTime/batch 0.057\n",
      "Epoch: [89][ 199/1563]\tLoss   0.25\tAcc  91.31\tTime/batch 0.057\n",
      "Epoch: [89][ 249/1563]\tLoss   0.25\tAcc  91.33\tTime/batch 0.057\n",
      "Epoch: [89][ 299/1563]\tLoss   0.25\tAcc  91.55\tTime/batch 0.057\n",
      "Epoch: [89][ 349/1563]\tLoss   0.25\tAcc  91.45\tTime/batch 0.057\n",
      "Epoch: [89][ 399/1563]\tLoss   0.25\tAcc  91.40\tTime/batch 0.057\n",
      "Epoch: [89][ 449/1563]\tLoss   0.26\tAcc  91.25\tTime/batch 0.057\n",
      "Epoch: [89][ 499/1563]\tLoss   0.26\tAcc  91.16\tTime/batch 0.057\n",
      "Epoch: [89][ 549/1563]\tLoss   0.26\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [89][ 599/1563]\tLoss   0.26\tAcc  91.06\tTime/batch 0.057\n",
      "Epoch: [89][ 649/1563]\tLoss   0.26\tAcc  91.08\tTime/batch 0.057\n",
      "Epoch: [89][ 699/1563]\tLoss   0.26\tAcc  91.06\tTime/batch 0.057\n",
      "Epoch: [89][ 749/1563]\tLoss   0.26\tAcc  91.02\tTime/batch 0.057\n",
      "Epoch: [89][ 799/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.057\n",
      "Epoch: [89][ 849/1563]\tLoss   0.26\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [89][ 899/1563]\tLoss   0.26\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [89][ 949/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [89][ 999/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [89][1049/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [89][1099/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [89][1149/1563]\tLoss   0.26\tAcc  90.82\tTime/batch 0.057\n",
      "Epoch: [89][1199/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.057\n",
      "Epoch: [89][1249/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "Epoch: [89][1299/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [89][1349/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [89][1399/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [89][1449/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [89][1499/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [89][1549/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [90][  49/1563]\tLoss   0.26\tAcc  90.50\tTime/batch 0.059\n",
      "Epoch: [90][  99/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.059\n",
      "Epoch: [90][ 149/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.058\n",
      "Epoch: [90][ 199/1563]\tLoss   0.25\tAcc  91.03\tTime/batch 0.058\n",
      "Epoch: [90][ 249/1563]\tLoss   0.25\tAcc  91.16\tTime/batch 0.058\n",
      "Epoch: [90][ 299/1563]\tLoss   0.26\tAcc  91.07\tTime/batch 0.058\n",
      "Epoch: [90][ 349/1563]\tLoss   0.26\tAcc  91.25\tTime/batch 0.058\n",
      "Epoch: [90][ 399/1563]\tLoss   0.25\tAcc  91.38\tTime/batch 0.058\n",
      "Epoch: [90][ 449/1563]\tLoss   0.26\tAcc  91.12\tTime/batch 0.058\n",
      "Epoch: [90][ 499/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.058\n",
      "Epoch: [90][ 549/1563]\tLoss   0.26\tAcc  90.90\tTime/batch 0.058\n",
      "Epoch: [90][ 599/1563]\tLoss   0.27\tAcc  90.76\tTime/batch 0.058\n",
      "Epoch: [90][ 649/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.058\n",
      "Epoch: [90][ 699/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.058\n",
      "Epoch: [90][ 749/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.058\n",
      "Epoch: [90][ 799/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.058\n",
      "Epoch: [90][ 849/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.058\n",
      "Epoch: [90][ 899/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.058\n",
      "Epoch: [90][ 949/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.058\n",
      "Epoch: [90][ 999/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.058\n",
      "Epoch: [90][1049/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.058\n",
      "Epoch: [90][1099/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.058\n",
      "Epoch: [90][1149/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.058\n",
      "Epoch: [90][1199/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.058\n",
      "Epoch: [90][1249/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.058\n",
      "Epoch: [90][1299/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.058\n",
      "Epoch: [90][1349/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.058\n",
      "Epoch: [90][1399/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.058\n",
      "Epoch: [90][1449/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.058\n",
      "Epoch: [90][1499/1563]\tLoss   0.27\tAcc  90.42\tTime/batch 0.058\n",
      "Epoch: [90][1549/1563]\tLoss   0.27\tAcc  90.37\tTime/batch 0.058\n",
      "epoch 90\n",
      "Accuracy of the network on the 10000 test images: 86.8 %\n",
      "Sparsity of the update phase: 67.2 %\n",
      "current learning rate = 0.025\n",
      "Epoch: [91][  49/1563]\tLoss   0.24\tAcc  91.94\tTime/batch 0.057\n",
      "Epoch: [91][  99/1563]\tLoss   0.25\tAcc  91.03\tTime/batch 0.057\n",
      "Epoch: [91][ 149/1563]\tLoss   0.26\tAcc  91.23\tTime/batch 0.057\n",
      "Epoch: [91][ 199/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.056\n",
      "Epoch: [91][ 249/1563]\tLoss   0.26\tAcc  90.86\tTime/batch 0.057\n",
      "Epoch: [91][ 299/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.056\n",
      "Epoch: [91][ 349/1563]\tLoss   0.27\tAcc  90.50\tTime/batch 0.056\n",
      "Epoch: [91][ 399/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.056\n",
      "Epoch: [91][ 449/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.056\n",
      "Epoch: [91][ 499/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.056\n",
      "Epoch: [91][ 549/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.056\n",
      "Epoch: [91][ 599/1563]\tLoss   0.27\tAcc  90.51\tTime/batch 0.056\n",
      "Epoch: [91][ 649/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.056\n",
      "Epoch: [91][ 699/1563]\tLoss   0.26\tAcc  90.58\tTime/batch 0.056\n",
      "Epoch: [91][ 749/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [91][ 799/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [91][ 849/1563]\tLoss   0.27\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [91][ 899/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [91][ 949/1563]\tLoss   0.27\tAcc  90.31\tTime/batch 0.057\n",
      "Epoch: [91][ 999/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [91][1049/1563]\tLoss   0.27\tAcc  90.34\tTime/batch 0.057\n",
      "Epoch: [91][1099/1563]\tLoss   0.27\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [91][1149/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [91][1199/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.057\n",
      "Epoch: [91][1249/1563]\tLoss   0.27\tAcc  90.43\tTime/batch 0.057\n",
      "Epoch: [91][1299/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [91][1349/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.057\n",
      "Epoch: [91][1399/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [91][1449/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "Epoch: [91][1499/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [91][1549/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [92][  49/1563]\tLoss   0.23\tAcc  92.75\tTime/batch 0.058\n",
      "Epoch: [92][  99/1563]\tLoss   0.25\tAcc  91.84\tTime/batch 0.057\n",
      "Epoch: [92][ 149/1563]\tLoss   0.26\tAcc  91.38\tTime/batch 0.057\n",
      "Epoch: [92][ 199/1563]\tLoss   0.26\tAcc  91.22\tTime/batch 0.057\n",
      "Epoch: [92][ 249/1563]\tLoss   0.25\tAcc  91.21\tTime/batch 0.057\n",
      "Epoch: [92][ 299/1563]\tLoss   0.26\tAcc  91.07\tTime/batch 0.057\n",
      "Epoch: [92][ 349/1563]\tLoss   0.25\tAcc  91.17\tTime/batch 0.057\n",
      "Epoch: [92][ 399/1563]\tLoss   0.25\tAcc  91.16\tTime/batch 0.057\n",
      "Epoch: [92][ 449/1563]\tLoss   0.26\tAcc  91.06\tTime/batch 0.057\n",
      "Epoch: [92][ 499/1563]\tLoss   0.26\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [92][ 549/1563]\tLoss   0.26\tAcc  90.90\tTime/batch 0.057\n",
      "Epoch: [92][ 599/1563]\tLoss   0.26\tAcc  90.92\tTime/batch 0.057\n",
      "Epoch: [92][ 649/1563]\tLoss   0.26\tAcc  91.03\tTime/batch 0.057\n",
      "Epoch: [92][ 699/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.057\n",
      "Epoch: [92][ 749/1563]\tLoss   0.26\tAcc  91.00\tTime/batch 0.057\n",
      "Epoch: [92][ 799/1563]\tLoss   0.26\tAcc  90.93\tTime/batch 0.057\n",
      "Epoch: [92][ 849/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [92][ 899/1563]\tLoss   0.26\tAcc  90.86\tTime/batch 0.057\n",
      "Epoch: [92][ 949/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [92][ 999/1563]\tLoss   0.26\tAcc  90.90\tTime/batch 0.057\n",
      "Epoch: [92][1049/1563]\tLoss   0.26\tAcc  90.90\tTime/batch 0.057\n",
      "Epoch: [92][1099/1563]\tLoss   0.27\tAcc  90.84\tTime/batch 0.057\n",
      "Epoch: [92][1149/1563]\tLoss   0.27\tAcc  90.82\tTime/batch 0.057\n",
      "Epoch: [92][1199/1563]\tLoss   0.27\tAcc  90.87\tTime/batch 0.057\n",
      "Epoch: [92][1249/1563]\tLoss   0.27\tAcc  90.86\tTime/batch 0.057\n",
      "Epoch: [92][1299/1563]\tLoss   0.27\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [92][1349/1563]\tLoss   0.27\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [92][1399/1563]\tLoss   0.27\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [92][1449/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [92][1499/1563]\tLoss   0.27\tAcc  90.71\tTime/batch 0.057\n",
      "Epoch: [92][1549/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [93][  49/1563]\tLoss   0.24\tAcc  91.62\tTime/batch 0.058\n",
      "Epoch: [93][  99/1563]\tLoss   0.25\tAcc  91.41\tTime/batch 0.057\n",
      "Epoch: [93][ 149/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.057\n",
      "Epoch: [93][ 199/1563]\tLoss   0.27\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [93][ 249/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [93][ 299/1563]\tLoss   0.28\tAcc  90.56\tTime/batch 0.057\n",
      "Epoch: [93][ 349/1563]\tLoss   0.28\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [93][ 399/1563]\tLoss   0.28\tAcc  90.43\tTime/batch 0.057\n",
      "Epoch: [93][ 449/1563]\tLoss   0.28\tAcc  90.42\tTime/batch 0.057\n",
      "Epoch: [93][ 499/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.057\n",
      "Epoch: [93][ 549/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [93][ 599/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [93][ 649/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [93][ 699/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [93][ 749/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [93][ 799/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [93][ 849/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [93][ 899/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [93][ 949/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [93][ 999/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [93][1049/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.056\n",
      "Epoch: [93][1099/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.056\n",
      "Epoch: [93][1149/1563]\tLoss   0.27\tAcc  90.51\tTime/batch 0.056\n",
      "Epoch: [93][1199/1563]\tLoss   0.27\tAcc  90.45\tTime/batch 0.056\n",
      "Epoch: [93][1249/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.056\n",
      "Epoch: [93][1299/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.056\n",
      "Epoch: [93][1349/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.056\n",
      "Epoch: [93][1399/1563]\tLoss   0.28\tAcc  90.40\tTime/batch 0.056\n",
      "Epoch: [93][1449/1563]\tLoss   0.27\tAcc  90.42\tTime/batch 0.056\n",
      "Epoch: [93][1499/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.056\n",
      "Epoch: [93][1549/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.056\n",
      "current learning rate = 0.025\n",
      "Epoch: [94][  49/1563]\tLoss   0.27\tAcc  92.06\tTime/batch 0.057\n",
      "Epoch: [94][  99/1563]\tLoss   0.27\tAcc  91.41\tTime/batch 0.057\n",
      "Epoch: [94][ 149/1563]\tLoss   0.26\tAcc  91.44\tTime/batch 0.057\n",
      "Epoch: [94][ 199/1563]\tLoss   0.26\tAcc  91.16\tTime/batch 0.057\n",
      "Epoch: [94][ 249/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [94][ 299/1563]\tLoss   0.27\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [94][ 349/1563]\tLoss   0.26\tAcc  91.00\tTime/batch 0.057\n",
      "Epoch: [94][ 399/1563]\tLoss   0.26\tAcc  91.04\tTime/batch 0.057\n",
      "Epoch: [94][ 449/1563]\tLoss   0.26\tAcc  91.10\tTime/batch 0.057\n",
      "Epoch: [94][ 499/1563]\tLoss   0.26\tAcc  91.19\tTime/batch 0.057\n",
      "Epoch: [94][ 549/1563]\tLoss   0.26\tAcc  91.25\tTime/batch 0.057\n",
      "Epoch: [94][ 599/1563]\tLoss   0.26\tAcc  91.15\tTime/batch 0.057\n",
      "Epoch: [94][ 649/1563]\tLoss   0.26\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [94][ 699/1563]\tLoss   0.26\tAcc  91.14\tTime/batch 0.057\n",
      "Epoch: [94][ 749/1563]\tLoss   0.26\tAcc  91.13\tTime/batch 0.057\n",
      "Epoch: [94][ 799/1563]\tLoss   0.26\tAcc  91.04\tTime/batch 0.057\n",
      "Epoch: [94][ 849/1563]\tLoss   0.27\tAcc  90.92\tTime/batch 0.057\n",
      "Epoch: [94][ 899/1563]\tLoss   0.27\tAcc  90.95\tTime/batch 0.057\n",
      "Epoch: [94][ 949/1563]\tLoss   0.26\tAcc  91.00\tTime/batch 0.057\n",
      "Epoch: [94][ 999/1563]\tLoss   0.26\tAcc  90.98\tTime/batch 0.057\n",
      "Epoch: [94][1049/1563]\tLoss   0.26\tAcc  90.95\tTime/batch 0.057\n",
      "Epoch: [94][1099/1563]\tLoss   0.26\tAcc  90.93\tTime/batch 0.057\n",
      "Epoch: [94][1149/1563]\tLoss   0.27\tAcc  90.92\tTime/batch 0.057\n",
      "Epoch: [94][1199/1563]\tLoss   0.27\tAcc  90.88\tTime/batch 0.057\n",
      "Epoch: [94][1249/1563]\tLoss   0.27\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [94][1299/1563]\tLoss   0.27\tAcc  90.77\tTime/batch 0.057\n",
      "Epoch: [94][1349/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [94][1399/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [94][1449/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [94][1499/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [94][1549/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [95][  49/1563]\tLoss   0.25\tAcc  90.44\tTime/batch 0.058\n",
      "Epoch: [95][  99/1563]\tLoss   0.25\tAcc  91.03\tTime/batch 0.057\n",
      "Epoch: [95][ 149/1563]\tLoss   0.25\tAcc  91.21\tTime/batch 0.057\n",
      "Epoch: [95][ 199/1563]\tLoss   0.25\tAcc  91.28\tTime/batch 0.057\n",
      "Epoch: [95][ 249/1563]\tLoss   0.25\tAcc  91.21\tTime/batch 0.057\n",
      "Epoch: [95][ 299/1563]\tLoss   0.26\tAcc  91.04\tTime/batch 0.057\n",
      "Epoch: [95][ 349/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [95][ 399/1563]\tLoss   0.26\tAcc  90.95\tTime/batch 0.057\n",
      "Epoch: [95][ 449/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.058\n",
      "Epoch: [95][ 499/1563]\tLoss   0.26\tAcc  91.04\tTime/batch 0.058\n",
      "Epoch: [95][ 549/1563]\tLoss   0.26\tAcc  90.99\tTime/batch 0.058\n",
      "Epoch: [95][ 599/1563]\tLoss   0.26\tAcc  91.01\tTime/batch 0.058\n",
      "Epoch: [95][ 649/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.058\n",
      "Epoch: [95][ 699/1563]\tLoss   0.26\tAcc  90.94\tTime/batch 0.058\n",
      "Epoch: [95][ 749/1563]\tLoss   0.26\tAcc  90.85\tTime/batch 0.058\n",
      "Epoch: [95][ 799/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.058\n",
      "Epoch: [95][ 849/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.058\n",
      "Epoch: [95][ 899/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.058\n",
      "Epoch: [95][ 949/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.058\n",
      "Epoch: [95][ 999/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.058\n",
      "Epoch: [95][1049/1563]\tLoss   0.26\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [95][1099/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [95][1149/1563]\tLoss   0.26\tAcc  90.82\tTime/batch 0.057\n",
      "Epoch: [95][1199/1563]\tLoss   0.26\tAcc  90.84\tTime/batch 0.057\n",
      "Epoch: [95][1249/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [95][1299/1563]\tLoss   0.26\tAcc  90.82\tTime/batch 0.057\n",
      "Epoch: [95][1349/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.057\n",
      "Epoch: [95][1399/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [95][1449/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [95][1499/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [95][1549/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [96][  49/1563]\tLoss   0.26\tAcc  91.44\tTime/batch 0.057\n",
      "Epoch: [96][  99/1563]\tLoss   0.25\tAcc  91.16\tTime/batch 0.057\n",
      "Epoch: [96][ 149/1563]\tLoss   0.25\tAcc  91.10\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [96][ 199/1563]\tLoss   0.25\tAcc  91.27\tTime/batch 0.057\n",
      "Epoch: [96][ 249/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [96][ 299/1563]\tLoss   0.26\tAcc  90.89\tTime/batch 0.057\n",
      "Epoch: [96][ 349/1563]\tLoss   0.26\tAcc  90.96\tTime/batch 0.057\n",
      "Epoch: [96][ 399/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [96][ 449/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [96][ 499/1563]\tLoss   0.26\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [96][ 549/1563]\tLoss   0.26\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [96][ 599/1563]\tLoss   0.26\tAcc  90.85\tTime/batch 0.057\n",
      "Epoch: [96][ 649/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [96][ 699/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [96][ 749/1563]\tLoss   0.26\tAcc  90.77\tTime/batch 0.057\n",
      "Epoch: [96][ 799/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [96][ 849/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [96][ 899/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [96][ 949/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [96][ 999/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [96][1049/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [96][1099/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [96][1149/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [96][1199/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.057\n",
      "Epoch: [96][1249/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [96][1299/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [96][1349/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "Epoch: [96][1399/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [96][1449/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [96][1499/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [96][1549/1563]\tLoss   0.27\tAcc  90.53\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [97][  49/1563]\tLoss   0.22\tAcc  91.69\tTime/batch 0.058\n",
      "Epoch: [97][  99/1563]\tLoss   0.24\tAcc  91.31\tTime/batch 0.057\n",
      "Epoch: [97][ 149/1563]\tLoss   0.26\tAcc  90.90\tTime/batch 0.057\n",
      "Epoch: [97][ 199/1563]\tLoss   0.25\tAcc  91.03\tTime/batch 0.057\n",
      "Epoch: [97][ 249/1563]\tLoss   0.25\tAcc  91.11\tTime/batch 0.057\n",
      "Epoch: [97][ 299/1563]\tLoss   0.26\tAcc  91.03\tTime/batch 0.057\n",
      "Epoch: [97][ 349/1563]\tLoss   0.26\tAcc  90.91\tTime/batch 0.057\n",
      "Epoch: [97][ 399/1563]\tLoss   0.26\tAcc  91.05\tTime/batch 0.057\n",
      "Epoch: [97][ 449/1563]\tLoss   0.26\tAcc  90.97\tTime/batch 0.057\n",
      "Epoch: [97][ 499/1563]\tLoss   0.26\tAcc  90.92\tTime/batch 0.057\n",
      "Epoch: [97][ 549/1563]\tLoss   0.26\tAcc  90.86\tTime/batch 0.057\n",
      "Epoch: [97][ 599/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [97][ 649/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [97][ 699/1563]\tLoss   0.26\tAcc  90.86\tTime/batch 0.057\n",
      "Epoch: [97][ 749/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [97][ 799/1563]\tLoss   0.26\tAcc  90.84\tTime/batch 0.057\n",
      "Epoch: [97][ 849/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [97][ 899/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [97][ 949/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [97][ 999/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [97][1049/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [97][1099/1563]\tLoss   0.26\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [97][1149/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [97][1199/1563]\tLoss   0.26\tAcc  90.82\tTime/batch 0.057\n",
      "Epoch: [97][1249/1563]\tLoss   0.26\tAcc  90.78\tTime/batch 0.057\n",
      "Epoch: [97][1299/1563]\tLoss   0.26\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [97][1349/1563]\tLoss   0.26\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [97][1399/1563]\tLoss   0.26\tAcc  90.62\tTime/batch 0.057\n",
      "Epoch: [97][1449/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [97][1499/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.057\n",
      "Epoch: [97][1549/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [98][  49/1563]\tLoss   0.24\tAcc  92.00\tTime/batch 0.058\n",
      "Epoch: [98][  99/1563]\tLoss   0.24\tAcc  91.78\tTime/batch 0.057\n",
      "Epoch: [98][ 149/1563]\tLoss   0.26\tAcc  91.10\tTime/batch 0.057\n",
      "Epoch: [98][ 199/1563]\tLoss   0.26\tAcc  91.08\tTime/batch 0.057\n",
      "Epoch: [98][ 249/1563]\tLoss   0.26\tAcc  91.00\tTime/batch 0.057\n",
      "Epoch: [98][ 299/1563]\tLoss   0.26\tAcc  91.12\tTime/batch 0.057\n",
      "Epoch: [98][ 349/1563]\tLoss   0.26\tAcc  91.09\tTime/batch 0.057\n",
      "Epoch: [98][ 399/1563]\tLoss   0.26\tAcc  90.99\tTime/batch 0.057\n",
      "Epoch: [98][ 449/1563]\tLoss   0.26\tAcc  90.99\tTime/batch 0.057\n",
      "Epoch: [98][ 499/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [98][ 549/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [98][ 599/1563]\tLoss   0.26\tAcc  90.87\tTime/batch 0.057\n",
      "Epoch: [98][ 649/1563]\tLoss   0.26\tAcc  90.83\tTime/batch 0.057\n",
      "Epoch: [98][ 699/1563]\tLoss   0.26\tAcc  90.75\tTime/batch 0.057\n",
      "Epoch: [98][ 749/1563]\tLoss   0.26\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [98][ 799/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.057\n",
      "Epoch: [98][ 849/1563]\tLoss   0.27\tAcc  90.56\tTime/batch 0.057\n",
      "Epoch: [98][ 899/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [98][ 949/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [98][ 999/1563]\tLoss   0.27\tAcc  90.63\tTime/batch 0.057\n",
      "Epoch: [98][1049/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [98][1099/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [98][1149/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [98][1199/1563]\tLoss   0.27\tAcc  90.51\tTime/batch 0.057\n",
      "Epoch: [98][1249/1563]\tLoss   0.27\tAcc  90.51\tTime/batch 0.057\n",
      "Epoch: [98][1299/1563]\tLoss   0.27\tAcc  90.54\tTime/batch 0.057\n",
      "Epoch: [98][1349/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [98][1399/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.057\n",
      "Epoch: [98][1449/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.057\n",
      "Epoch: [98][1499/1563]\tLoss   0.27\tAcc  90.48\tTime/batch 0.057\n",
      "Epoch: [98][1549/1563]\tLoss   0.27\tAcc  90.44\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [99][  49/1563]\tLoss   0.26\tAcc  90.88\tTime/batch 0.058\n",
      "Epoch: [99][  99/1563]\tLoss   0.26\tAcc  90.81\tTime/batch 0.057\n",
      "Epoch: [99][ 149/1563]\tLoss   0.26\tAcc  90.38\tTime/batch 0.057\n",
      "Epoch: [99][ 199/1563]\tLoss   0.26\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [99][ 249/1563]\tLoss   0.27\tAcc  90.46\tTime/batch 0.057\n",
      "Epoch: [99][ 299/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "Epoch: [99][ 349/1563]\tLoss   0.26\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [99][ 399/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [99][ 449/1563]\tLoss   0.26\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [99][ 499/1563]\tLoss   0.26\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [99][ 549/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [99][ 599/1563]\tLoss   0.26\tAcc  90.79\tTime/batch 0.057\n",
      "Epoch: [99][ 649/1563]\tLoss   0.26\tAcc  90.80\tTime/batch 0.057\n",
      "Epoch: [99][ 699/1563]\tLoss   0.27\tAcc  90.76\tTime/batch 0.057\n",
      "Epoch: [99][ 749/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "Epoch: [99][ 799/1563]\tLoss   0.27\tAcc  90.74\tTime/batch 0.057\n",
      "Epoch: [99][ 849/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.057\n",
      "Epoch: [99][ 899/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [99][ 949/1563]\tLoss   0.27\tAcc  90.68\tTime/batch 0.057\n",
      "Epoch: [99][ 999/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [99][1049/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [99][1099/1563]\tLoss   0.27\tAcc  90.70\tTime/batch 0.057\n",
      "Epoch: [99][1149/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "Epoch: [99][1199/1563]\tLoss   0.27\tAcc  90.71\tTime/batch 0.057\n",
      "Epoch: [99][1249/1563]\tLoss   0.27\tAcc  90.67\tTime/batch 0.057\n",
      "Epoch: [99][1299/1563]\tLoss   0.27\tAcc  90.66\tTime/batch 0.057\n",
      "Epoch: [99][1349/1563]\tLoss   0.27\tAcc  90.65\tTime/batch 0.057\n",
      "Epoch: [99][1399/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [99][1449/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [99][1499/1563]\tLoss   0.27\tAcc  90.69\tTime/batch 0.057\n",
      "Epoch: [99][1549/1563]\tLoss   0.27\tAcc  90.73\tTime/batch 0.057\n",
      "current learning rate = 0.025\n",
      "Epoch: [100][  49/1563]\tLoss   0.27\tAcc  90.94\tTime/batch 0.057\n",
      "Epoch: [100][  99/1563]\tLoss   0.27\tAcc  90.62\tTime/batch 0.056\n",
      "Epoch: [100][ 149/1563]\tLoss   0.28\tAcc  90.46\tTime/batch 0.056\n",
      "Epoch: [100][ 199/1563]\tLoss   0.28\tAcc  90.36\tTime/batch 0.056\n",
      "Epoch: [100][ 249/1563]\tLoss   0.27\tAcc  90.41\tTime/batch 0.056\n",
      "Epoch: [100][ 299/1563]\tLoss   0.27\tAcc  90.47\tTime/batch 0.056\n",
      "Epoch: [100][ 349/1563]\tLoss   0.27\tAcc  90.43\tTime/batch 0.056\n",
      "Epoch: [100][ 399/1563]\tLoss   0.27\tAcc  90.59\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [100][ 449/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.056\n",
      "Epoch: [100][ 499/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.056\n",
      "Epoch: [100][ 549/1563]\tLoss   0.27\tAcc  90.72\tTime/batch 0.056\n",
      "Epoch: [100][ 599/1563]\tLoss   0.26\tAcc  90.74\tTime/batch 0.056\n",
      "Epoch: [100][ 649/1563]\tLoss   0.26\tAcc  90.70\tTime/batch 0.056\n",
      "Epoch: [100][ 699/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.056\n",
      "Epoch: [100][ 749/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.056\n",
      "Epoch: [100][ 799/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.056\n",
      "Epoch: [100][ 849/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.056\n",
      "Epoch: [100][ 899/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.056\n",
      "Epoch: [100][ 949/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.056\n",
      "Epoch: [100][ 999/1563]\tLoss   0.27\tAcc  90.58\tTime/batch 0.057\n",
      "Epoch: [100][1049/1563]\tLoss   0.27\tAcc  90.60\tTime/batch 0.057\n",
      "Epoch: [100][1099/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [100][1149/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [100][1199/1563]\tLoss   0.27\tAcc  90.64\tTime/batch 0.057\n",
      "Epoch: [100][1249/1563]\tLoss   0.27\tAcc  90.61\tTime/batch 0.057\n",
      "Epoch: [100][1299/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [100][1349/1563]\tLoss   0.27\tAcc  90.55\tTime/batch 0.057\n",
      "Epoch: [100][1399/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [100][1449/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [100][1499/1563]\tLoss   0.27\tAcc  90.57\tTime/batch 0.057\n",
      "Epoch: [100][1549/1563]\tLoss   0.27\tAcc  90.52\tTime/batch 0.057\n",
      "epoch 100\n",
      "Accuracy of the network on the 10000 test images: 87.4 %\n",
      "Sparsity of the update phase: 68.3 %\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [101][  49/1563]\tLoss   0.25\tAcc  91.56\tTime/batch 0.058\n",
      "Epoch: [101][  99/1563]\tLoss   0.23\tAcc  92.00\tTime/batch 0.057\n",
      "Epoch: [101][ 149/1563]\tLoss   0.22\tAcc  92.42\tTime/batch 0.057\n",
      "Epoch: [101][ 199/1563]\tLoss   0.21\tAcc  92.81\tTime/batch 0.057\n",
      "Epoch: [101][ 249/1563]\tLoss   0.22\tAcc  92.72\tTime/batch 0.057\n",
      "Epoch: [101][ 299/1563]\tLoss   0.21\tAcc  92.75\tTime/batch 0.057\n",
      "Epoch: [101][ 349/1563]\tLoss   0.21\tAcc  92.79\tTime/batch 0.057\n",
      "Epoch: [101][ 399/1563]\tLoss   0.21\tAcc  92.91\tTime/batch 0.057\n",
      "Epoch: [101][ 449/1563]\tLoss   0.21\tAcc  93.01\tTime/batch 0.057\n",
      "Epoch: [101][ 499/1563]\tLoss   0.20\tAcc  93.03\tTime/batch 0.057\n",
      "Epoch: [101][ 549/1563]\tLoss   0.20\tAcc  93.07\tTime/batch 0.057\n",
      "Epoch: [101][ 599/1563]\tLoss   0.20\tAcc  93.04\tTime/batch 0.057\n",
      "Epoch: [101][ 649/1563]\tLoss   0.20\tAcc  93.08\tTime/batch 0.057\n",
      "Epoch: [101][ 699/1563]\tLoss   0.20\tAcc  93.09\tTime/batch 0.057\n",
      "Epoch: [101][ 749/1563]\tLoss   0.20\tAcc  93.12\tTime/batch 0.057\n",
      "Epoch: [101][ 799/1563]\tLoss   0.20\tAcc  93.14\tTime/batch 0.057\n",
      "Epoch: [101][ 849/1563]\tLoss   0.20\tAcc  93.20\tTime/batch 0.057\n",
      "Epoch: [101][ 899/1563]\tLoss   0.20\tAcc  93.24\tTime/batch 0.057\n",
      "Epoch: [101][ 949/1563]\tLoss   0.20\tAcc  93.29\tTime/batch 0.057\n",
      "Epoch: [101][ 999/1563]\tLoss   0.19\tAcc  93.31\tTime/batch 0.057\n",
      "Epoch: [101][1049/1563]\tLoss   0.20\tAcc  93.30\tTime/batch 0.057\n",
      "Epoch: [101][1099/1563]\tLoss   0.19\tAcc  93.35\tTime/batch 0.057\n",
      "Epoch: [101][1149/1563]\tLoss   0.19\tAcc  93.35\tTime/batch 0.057\n",
      "Epoch: [101][1199/1563]\tLoss   0.19\tAcc  93.39\tTime/batch 0.057\n",
      "Epoch: [101][1249/1563]\tLoss   0.19\tAcc  93.42\tTime/batch 0.057\n",
      "Epoch: [101][1299/1563]\tLoss   0.19\tAcc  93.40\tTime/batch 0.057\n",
      "Epoch: [101][1349/1563]\tLoss   0.19\tAcc  93.38\tTime/batch 0.057\n",
      "Epoch: [101][1399/1563]\tLoss   0.19\tAcc  93.42\tTime/batch 0.057\n",
      "Epoch: [101][1449/1563]\tLoss   0.19\tAcc  93.46\tTime/batch 0.057\n",
      "Epoch: [101][1499/1563]\tLoss   0.19\tAcc  93.48\tTime/batch 0.057\n",
      "Epoch: [101][1549/1563]\tLoss   0.19\tAcc  93.49\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [102][  49/1563]\tLoss   0.17\tAcc  94.56\tTime/batch 0.057\n",
      "Epoch: [102][  99/1563]\tLoss   0.17\tAcc  94.19\tTime/batch 0.057\n",
      "Epoch: [102][ 149/1563]\tLoss   0.17\tAcc  94.00\tTime/batch 0.057\n",
      "Epoch: [102][ 199/1563]\tLoss   0.17\tAcc  93.95\tTime/batch 0.057\n",
      "Epoch: [102][ 249/1563]\tLoss   0.17\tAcc  93.99\tTime/batch 0.057\n",
      "Epoch: [102][ 299/1563]\tLoss   0.17\tAcc  93.96\tTime/batch 0.057\n",
      "Epoch: [102][ 349/1563]\tLoss   0.17\tAcc  94.04\tTime/batch 0.057\n",
      "Epoch: [102][ 399/1563]\tLoss   0.17\tAcc  93.93\tTime/batch 0.057\n",
      "Epoch: [102][ 449/1563]\tLoss   0.17\tAcc  93.97\tTime/batch 0.057\n",
      "Epoch: [102][ 499/1563]\tLoss   0.17\tAcc  94.09\tTime/batch 0.057\n",
      "Epoch: [102][ 549/1563]\tLoss   0.17\tAcc  94.19\tTime/batch 0.057\n",
      "Epoch: [102][ 599/1563]\tLoss   0.17\tAcc  94.22\tTime/batch 0.057\n",
      "Epoch: [102][ 649/1563]\tLoss   0.17\tAcc  94.19\tTime/batch 0.057\n",
      "Epoch: [102][ 699/1563]\tLoss   0.17\tAcc  94.18\tTime/batch 0.057\n",
      "Epoch: [102][ 749/1563]\tLoss   0.17\tAcc  94.18\tTime/batch 0.057\n",
      "Epoch: [102][ 799/1563]\tLoss   0.17\tAcc  94.18\tTime/batch 0.057\n",
      "Epoch: [102][ 849/1563]\tLoss   0.17\tAcc  94.25\tTime/batch 0.057\n",
      "Epoch: [102][ 899/1563]\tLoss   0.17\tAcc  94.24\tTime/batch 0.057\n",
      "Epoch: [102][ 949/1563]\tLoss   0.17\tAcc  94.21\tTime/batch 0.057\n",
      "Epoch: [102][ 999/1563]\tLoss   0.17\tAcc  94.23\tTime/batch 0.057\n",
      "Epoch: [102][1049/1563]\tLoss   0.17\tAcc  94.24\tTime/batch 0.057\n",
      "Epoch: [102][1099/1563]\tLoss   0.17\tAcc  94.23\tTime/batch 0.057\n",
      "Epoch: [102][1149/1563]\tLoss   0.17\tAcc  94.24\tTime/batch 0.057\n",
      "Epoch: [102][1199/1563]\tLoss   0.17\tAcc  94.23\tTime/batch 0.057\n",
      "Epoch: [102][1249/1563]\tLoss   0.17\tAcc  94.26\tTime/batch 0.057\n",
      "Epoch: [102][1299/1563]\tLoss   0.17\tAcc  94.27\tTime/batch 0.057\n",
      "Epoch: [102][1349/1563]\tLoss   0.17\tAcc  94.31\tTime/batch 0.057\n",
      "Epoch: [102][1399/1563]\tLoss   0.16\tAcc  94.34\tTime/batch 0.057\n",
      "Epoch: [102][1449/1563]\tLoss   0.17\tAcc  94.30\tTime/batch 0.057\n",
      "Epoch: [102][1499/1563]\tLoss   0.16\tAcc  94.34\tTime/batch 0.057\n",
      "Epoch: [102][1549/1563]\tLoss   0.16\tAcc  94.32\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [103][  49/1563]\tLoss   0.16\tAcc  94.25\tTime/batch 0.058\n",
      "Epoch: [103][  99/1563]\tLoss   0.15\tAcc  94.75\tTime/batch 0.057\n",
      "Epoch: [103][ 149/1563]\tLoss   0.15\tAcc  94.83\tTime/batch 0.057\n",
      "Epoch: [103][ 199/1563]\tLoss   0.15\tAcc  94.81\tTime/batch 0.057\n",
      "Epoch: [103][ 249/1563]\tLoss   0.16\tAcc  94.58\tTime/batch 0.057\n",
      "Epoch: [103][ 299/1563]\tLoss   0.16\tAcc  94.51\tTime/batch 0.057\n",
      "Epoch: [103][ 349/1563]\tLoss   0.16\tAcc  94.46\tTime/batch 0.057\n",
      "Epoch: [103][ 399/1563]\tLoss   0.16\tAcc  94.56\tTime/batch 0.057\n",
      "Epoch: [103][ 449/1563]\tLoss   0.16\tAcc  94.54\tTime/batch 0.057\n",
      "Epoch: [103][ 499/1563]\tLoss   0.16\tAcc  94.51\tTime/batch 0.057\n",
      "Epoch: [103][ 549/1563]\tLoss   0.15\tAcc  94.55\tTime/batch 0.057\n",
      "Epoch: [103][ 599/1563]\tLoss   0.15\tAcc  94.57\tTime/batch 0.057\n",
      "Epoch: [103][ 649/1563]\tLoss   0.15\tAcc  94.58\tTime/batch 0.057\n",
      "Epoch: [103][ 699/1563]\tLoss   0.15\tAcc  94.59\tTime/batch 0.057\n",
      "Epoch: [103][ 749/1563]\tLoss   0.16\tAcc  94.54\tTime/batch 0.057\n",
      "Epoch: [103][ 799/1563]\tLoss   0.16\tAcc  94.48\tTime/batch 0.057\n",
      "Epoch: [103][ 849/1563]\tLoss   0.16\tAcc  94.46\tTime/batch 0.057\n",
      "Epoch: [103][ 899/1563]\tLoss   0.16\tAcc  94.50\tTime/batch 0.057\n",
      "Epoch: [103][ 949/1563]\tLoss   0.16\tAcc  94.50\tTime/batch 0.057\n",
      "Epoch: [103][ 999/1563]\tLoss   0.16\tAcc  94.51\tTime/batch 0.057\n",
      "Epoch: [103][1049/1563]\tLoss   0.16\tAcc  94.50\tTime/batch 0.057\n",
      "Epoch: [103][1099/1563]\tLoss   0.16\tAcc  94.52\tTime/batch 0.057\n",
      "Epoch: [103][1149/1563]\tLoss   0.16\tAcc  94.52\tTime/batch 0.057\n",
      "Epoch: [103][1199/1563]\tLoss   0.16\tAcc  94.54\tTime/batch 0.057\n",
      "Epoch: [103][1249/1563]\tLoss   0.16\tAcc  94.56\tTime/batch 0.057\n",
      "Epoch: [103][1299/1563]\tLoss   0.16\tAcc  94.55\tTime/batch 0.057\n",
      "Epoch: [103][1349/1563]\tLoss   0.16\tAcc  94.52\tTime/batch 0.057\n",
      "Epoch: [103][1399/1563]\tLoss   0.16\tAcc  94.53\tTime/batch 0.057\n",
      "Epoch: [103][1449/1563]\tLoss   0.16\tAcc  94.57\tTime/batch 0.057\n",
      "Epoch: [103][1499/1563]\tLoss   0.16\tAcc  94.56\tTime/batch 0.057\n",
      "Epoch: [103][1549/1563]\tLoss   0.16\tAcc  94.54\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [104][  49/1563]\tLoss   0.16\tAcc  94.50\tTime/batch 0.057\n",
      "Epoch: [104][  99/1563]\tLoss   0.16\tAcc  94.31\tTime/batch 0.056\n",
      "Epoch: [104][ 149/1563]\tLoss   0.16\tAcc  94.48\tTime/batch 0.056\n",
      "Epoch: [104][ 199/1563]\tLoss   0.16\tAcc  94.55\tTime/batch 0.057\n",
      "Epoch: [104][ 249/1563]\tLoss   0.16\tAcc  94.41\tTime/batch 0.057\n",
      "Epoch: [104][ 299/1563]\tLoss   0.16\tAcc  94.46\tTime/batch 0.057\n",
      "Epoch: [104][ 349/1563]\tLoss   0.16\tAcc  94.43\tTime/batch 0.057\n",
      "Epoch: [104][ 399/1563]\tLoss   0.16\tAcc  94.45\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [104][ 449/1563]\tLoss   0.16\tAcc  94.52\tTime/batch 0.057\n",
      "Epoch: [104][ 499/1563]\tLoss   0.16\tAcc  94.49\tTime/batch 0.057\n",
      "Epoch: [104][ 549/1563]\tLoss   0.16\tAcc  94.47\tTime/batch 0.057\n",
      "Epoch: [104][ 599/1563]\tLoss   0.15\tAcc  94.56\tTime/batch 0.057\n",
      "Epoch: [104][ 649/1563]\tLoss   0.15\tAcc  94.62\tTime/batch 0.057\n",
      "Epoch: [104][ 699/1563]\tLoss   0.15\tAcc  94.57\tTime/batch 0.057\n",
      "Epoch: [104][ 749/1563]\tLoss   0.15\tAcc  94.60\tTime/batch 0.057\n",
      "Epoch: [104][ 799/1563]\tLoss   0.15\tAcc  94.63\tTime/batch 0.057\n",
      "Epoch: [104][ 849/1563]\tLoss   0.15\tAcc  94.65\tTime/batch 0.057\n",
      "Epoch: [104][ 899/1563]\tLoss   0.15\tAcc  94.67\tTime/batch 0.057\n",
      "Epoch: [104][ 949/1563]\tLoss   0.15\tAcc  94.69\tTime/batch 0.057\n",
      "Epoch: [104][ 999/1563]\tLoss   0.15\tAcc  94.69\tTime/batch 0.057\n",
      "Epoch: [104][1049/1563]\tLoss   0.15\tAcc  94.72\tTime/batch 0.057\n",
      "Epoch: [104][1099/1563]\tLoss   0.15\tAcc  94.71\tTime/batch 0.057\n",
      "Epoch: [104][1149/1563]\tLoss   0.15\tAcc  94.68\tTime/batch 0.057\n",
      "Epoch: [104][1199/1563]\tLoss   0.15\tAcc  94.67\tTime/batch 0.057\n",
      "Epoch: [104][1249/1563]\tLoss   0.15\tAcc  94.70\tTime/batch 0.057\n",
      "Epoch: [104][1299/1563]\tLoss   0.15\tAcc  94.74\tTime/batch 0.057\n",
      "Epoch: [104][1349/1563]\tLoss   0.15\tAcc  94.75\tTime/batch 0.057\n",
      "Epoch: [104][1399/1563]\tLoss   0.15\tAcc  94.74\tTime/batch 0.057\n",
      "Epoch: [104][1449/1563]\tLoss   0.15\tAcc  94.76\tTime/batch 0.057\n",
      "Epoch: [104][1499/1563]\tLoss   0.15\tAcc  94.80\tTime/batch 0.057\n",
      "Epoch: [104][1549/1563]\tLoss   0.15\tAcc  94.78\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [105][  49/1563]\tLoss   0.16\tAcc  94.69\tTime/batch 0.058\n",
      "Epoch: [105][  99/1563]\tLoss   0.14\tAcc  95.16\tTime/batch 0.057\n",
      "Epoch: [105][ 149/1563]\tLoss   0.14\tAcc  95.08\tTime/batch 0.057\n",
      "Epoch: [105][ 199/1563]\tLoss   0.14\tAcc  95.11\tTime/batch 0.057\n",
      "Epoch: [105][ 249/1563]\tLoss   0.14\tAcc  95.04\tTime/batch 0.057\n",
      "Epoch: [105][ 299/1563]\tLoss   0.15\tAcc  94.82\tTime/batch 0.057\n",
      "Epoch: [105][ 349/1563]\tLoss   0.14\tAcc  95.02\tTime/batch 0.057\n",
      "Epoch: [105][ 399/1563]\tLoss   0.15\tAcc  94.96\tTime/batch 0.057\n",
      "Epoch: [105][ 449/1563]\tLoss   0.14\tAcc  94.97\tTime/batch 0.057\n",
      "Epoch: [105][ 499/1563]\tLoss   0.15\tAcc  94.94\tTime/batch 0.057\n",
      "Epoch: [105][ 549/1563]\tLoss   0.14\tAcc  94.99\tTime/batch 0.057\n",
      "Epoch: [105][ 599/1563]\tLoss   0.15\tAcc  94.91\tTime/batch 0.057\n",
      "Epoch: [105][ 649/1563]\tLoss   0.15\tAcc  94.95\tTime/batch 0.057\n",
      "Epoch: [105][ 699/1563]\tLoss   0.15\tAcc  94.93\tTime/batch 0.057\n",
      "Epoch: [105][ 749/1563]\tLoss   0.15\tAcc  94.93\tTime/batch 0.057\n",
      "Epoch: [105][ 799/1563]\tLoss   0.15\tAcc  94.94\tTime/batch 0.057\n",
      "Epoch: [105][ 849/1563]\tLoss   0.15\tAcc  95.00\tTime/batch 0.057\n",
      "Epoch: [105][ 899/1563]\tLoss   0.15\tAcc  95.00\tTime/batch 0.057\n",
      "Epoch: [105][ 949/1563]\tLoss   0.15\tAcc  94.99\tTime/batch 0.057\n",
      "Epoch: [105][ 999/1563]\tLoss   0.15\tAcc  94.97\tTime/batch 0.057\n",
      "Epoch: [105][1049/1563]\tLoss   0.15\tAcc  95.01\tTime/batch 0.057\n",
      "Epoch: [105][1099/1563]\tLoss   0.15\tAcc  95.00\tTime/batch 0.057\n",
      "Epoch: [105][1149/1563]\tLoss   0.15\tAcc  94.97\tTime/batch 0.057\n",
      "Epoch: [105][1199/1563]\tLoss   0.15\tAcc  94.98\tTime/batch 0.057\n",
      "Epoch: [105][1249/1563]\tLoss   0.15\tAcc  94.98\tTime/batch 0.057\n",
      "Epoch: [105][1299/1563]\tLoss   0.15\tAcc  94.98\tTime/batch 0.057\n",
      "Epoch: [105][1349/1563]\tLoss   0.15\tAcc  94.97\tTime/batch 0.057\n",
      "Epoch: [105][1399/1563]\tLoss   0.15\tAcc  94.99\tTime/batch 0.057\n",
      "Epoch: [105][1449/1563]\tLoss   0.15\tAcc  94.98\tTime/batch 0.057\n",
      "Epoch: [105][1499/1563]\tLoss   0.15\tAcc  94.98\tTime/batch 0.057\n",
      "Epoch: [105][1549/1563]\tLoss   0.15\tAcc  94.98\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [106][  49/1563]\tLoss   0.13\tAcc  96.12\tTime/batch 0.058\n",
      "Epoch: [106][  99/1563]\tLoss   0.14\tAcc  95.38\tTime/batch 0.057\n",
      "Epoch: [106][ 149/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [106][ 199/1563]\tLoss   0.14\tAcc  95.05\tTime/batch 0.057\n",
      "Epoch: [106][ 249/1563]\tLoss   0.13\tAcc  95.29\tTime/batch 0.057\n",
      "Epoch: [106][ 299/1563]\tLoss   0.13\tAcc  95.32\tTime/batch 0.057\n",
      "Epoch: [106][ 349/1563]\tLoss   0.14\tAcc  95.20\tTime/batch 0.057\n",
      "Epoch: [106][ 399/1563]\tLoss   0.14\tAcc  95.20\tTime/batch 0.057\n",
      "Epoch: [106][ 449/1563]\tLoss   0.14\tAcc  95.19\tTime/batch 0.057\n",
      "Epoch: [106][ 499/1563]\tLoss   0.14\tAcc  95.14\tTime/batch 0.057\n",
      "Epoch: [106][ 549/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [106][ 599/1563]\tLoss   0.14\tAcc  95.23\tTime/batch 0.057\n",
      "Epoch: [106][ 649/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [106][ 699/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [106][ 749/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [106][ 799/1563]\tLoss   0.14\tAcc  95.15\tTime/batch 0.057\n",
      "Epoch: [106][ 849/1563]\tLoss   0.14\tAcc  95.17\tTime/batch 0.057\n",
      "Epoch: [106][ 899/1563]\tLoss   0.14\tAcc  95.15\tTime/batch 0.057\n",
      "Epoch: [106][ 949/1563]\tLoss   0.14\tAcc  95.12\tTime/batch 0.057\n",
      "Epoch: [106][ 999/1563]\tLoss   0.14\tAcc  95.14\tTime/batch 0.057\n",
      "Epoch: [106][1049/1563]\tLoss   0.14\tAcc  95.12\tTime/batch 0.057\n",
      "Epoch: [106][1099/1563]\tLoss   0.14\tAcc  95.13\tTime/batch 0.057\n",
      "Epoch: [106][1149/1563]\tLoss   0.14\tAcc  95.15\tTime/batch 0.057\n",
      "Epoch: [106][1199/1563]\tLoss   0.14\tAcc  95.15\tTime/batch 0.057\n",
      "Epoch: [106][1249/1563]\tLoss   0.14\tAcc  95.14\tTime/batch 0.057\n",
      "Epoch: [106][1299/1563]\tLoss   0.14\tAcc  95.17\tTime/batch 0.057\n",
      "Epoch: [106][1349/1563]\tLoss   0.14\tAcc  95.16\tTime/batch 0.057\n",
      "Epoch: [106][1399/1563]\tLoss   0.14\tAcc  95.18\tTime/batch 0.057\n",
      "Epoch: [106][1449/1563]\tLoss   0.14\tAcc  95.17\tTime/batch 0.057\n",
      "Epoch: [106][1499/1563]\tLoss   0.14\tAcc  95.18\tTime/batch 0.057\n",
      "Epoch: [106][1549/1563]\tLoss   0.14\tAcc  95.17\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [107][  49/1563]\tLoss   0.13\tAcc  95.44\tTime/batch 0.058\n",
      "Epoch: [107][  99/1563]\tLoss   0.14\tAcc  95.19\tTime/batch 0.057\n",
      "Epoch: [107][ 149/1563]\tLoss   0.13\tAcc  95.33\tTime/batch 0.057\n",
      "Epoch: [107][ 199/1563]\tLoss   0.14\tAcc  95.08\tTime/batch 0.057\n",
      "Epoch: [107][ 249/1563]\tLoss   0.14\tAcc  95.01\tTime/batch 0.057\n",
      "Epoch: [107][ 299/1563]\tLoss   0.14\tAcc  94.98\tTime/batch 0.057\n",
      "Epoch: [107][ 349/1563]\tLoss   0.14\tAcc  95.09\tTime/batch 0.057\n",
      "Epoch: [107][ 399/1563]\tLoss   0.14\tAcc  95.16\tTime/batch 0.057\n",
      "Epoch: [107][ 449/1563]\tLoss   0.14\tAcc  95.26\tTime/batch 0.057\n",
      "Epoch: [107][ 499/1563]\tLoss   0.14\tAcc  95.28\tTime/batch 0.057\n",
      "Epoch: [107][ 549/1563]\tLoss   0.14\tAcc  95.31\tTime/batch 0.057\n",
      "Epoch: [107][ 599/1563]\tLoss   0.13\tAcc  95.35\tTime/batch 0.057\n",
      "Epoch: [107][ 649/1563]\tLoss   0.14\tAcc  95.28\tTime/batch 0.057\n",
      "Epoch: [107][ 699/1563]\tLoss   0.14\tAcc  95.30\tTime/batch 0.057\n",
      "Epoch: [107][ 749/1563]\tLoss   0.14\tAcc  95.25\tTime/batch 0.057\n",
      "Epoch: [107][ 799/1563]\tLoss   0.14\tAcc  95.26\tTime/batch 0.057\n",
      "Epoch: [107][ 849/1563]\tLoss   0.13\tAcc  95.27\tTime/batch 0.057\n",
      "Epoch: [107][ 899/1563]\tLoss   0.13\tAcc  95.30\tTime/batch 0.057\n",
      "Epoch: [107][ 949/1563]\tLoss   0.13\tAcc  95.33\tTime/batch 0.057\n",
      "Epoch: [107][ 999/1563]\tLoss   0.13\tAcc  95.34\tTime/batch 0.057\n",
      "Epoch: [107][1049/1563]\tLoss   0.13\tAcc  95.35\tTime/batch 0.057\n",
      "Epoch: [107][1099/1563]\tLoss   0.13\tAcc  95.35\tTime/batch 0.057\n",
      "Epoch: [107][1149/1563]\tLoss   0.13\tAcc  95.35\tTime/batch 0.057\n",
      "Epoch: [107][1199/1563]\tLoss   0.13\tAcc  95.33\tTime/batch 0.057\n",
      "Epoch: [107][1249/1563]\tLoss   0.14\tAcc  95.31\tTime/batch 0.057\n",
      "Epoch: [107][1299/1563]\tLoss   0.14\tAcc  95.32\tTime/batch 0.057\n",
      "Epoch: [107][1349/1563]\tLoss   0.13\tAcc  95.34\tTime/batch 0.057\n",
      "Epoch: [107][1399/1563]\tLoss   0.14\tAcc  95.32\tTime/batch 0.057\n",
      "Epoch: [107][1449/1563]\tLoss   0.14\tAcc  95.34\tTime/batch 0.057\n",
      "Epoch: [107][1499/1563]\tLoss   0.14\tAcc  95.34\tTime/batch 0.057\n",
      "Epoch: [107][1549/1563]\tLoss   0.13\tAcc  95.34\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [108][  49/1563]\tLoss   0.15\tAcc  94.62\tTime/batch 0.058\n",
      "Epoch: [108][  99/1563]\tLoss   0.14\tAcc  95.09\tTime/batch 0.058\n",
      "Epoch: [108][ 149/1563]\tLoss   0.13\tAcc  95.27\tTime/batch 0.057\n",
      "Epoch: [108][ 199/1563]\tLoss   0.13\tAcc  95.44\tTime/batch 0.057\n",
      "Epoch: [108][ 249/1563]\tLoss   0.13\tAcc  95.34\tTime/batch 0.057\n",
      "Epoch: [108][ 299/1563]\tLoss   0.14\tAcc  95.19\tTime/batch 0.057\n",
      "Epoch: [108][ 349/1563]\tLoss   0.14\tAcc  95.22\tTime/batch 0.057\n",
      "Epoch: [108][ 399/1563]\tLoss   0.14\tAcc  95.20\tTime/batch 0.057\n",
      "Epoch: [108][ 449/1563]\tLoss   0.14\tAcc  95.30\tTime/batch 0.057\n",
      "Epoch: [108][ 499/1563]\tLoss   0.14\tAcc  95.23\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [108][ 549/1563]\tLoss   0.14\tAcc  95.17\tTime/batch 0.057\n",
      "Epoch: [108][ 599/1563]\tLoss   0.14\tAcc  95.19\tTime/batch 0.057\n",
      "Epoch: [108][ 649/1563]\tLoss   0.14\tAcc  95.24\tTime/batch 0.057\n",
      "Epoch: [108][ 699/1563]\tLoss   0.14\tAcc  95.24\tTime/batch 0.057\n",
      "Epoch: [108][ 749/1563]\tLoss   0.14\tAcc  95.17\tTime/batch 0.057\n",
      "Epoch: [108][ 799/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [108][ 849/1563]\tLoss   0.14\tAcc  95.21\tTime/batch 0.057\n",
      "Epoch: [108][ 899/1563]\tLoss   0.14\tAcc  95.26\tTime/batch 0.057\n",
      "Epoch: [108][ 949/1563]\tLoss   0.14\tAcc  95.26\tTime/batch 0.057\n",
      "Epoch: [108][ 999/1563]\tLoss   0.14\tAcc  95.24\tTime/batch 0.057\n",
      "Epoch: [108][1049/1563]\tLoss   0.14\tAcc  95.24\tTime/batch 0.057\n",
      "Epoch: [108][1099/1563]\tLoss   0.14\tAcc  95.25\tTime/batch 0.057\n",
      "Epoch: [108][1149/1563]\tLoss   0.14\tAcc  95.27\tTime/batch 0.057\n",
      "Epoch: [108][1199/1563]\tLoss   0.14\tAcc  95.26\tTime/batch 0.057\n",
      "Epoch: [108][1249/1563]\tLoss   0.14\tAcc  95.25\tTime/batch 0.057\n",
      "Epoch: [108][1299/1563]\tLoss   0.14\tAcc  95.27\tTime/batch 0.057\n",
      "Epoch: [108][1349/1563]\tLoss   0.14\tAcc  95.27\tTime/batch 0.057\n",
      "Epoch: [108][1399/1563]\tLoss   0.14\tAcc  95.25\tTime/batch 0.057\n",
      "Epoch: [108][1449/1563]\tLoss   0.14\tAcc  95.25\tTime/batch 0.057\n",
      "Epoch: [108][1499/1563]\tLoss   0.14\tAcc  95.25\tTime/batch 0.057\n",
      "Epoch: [108][1549/1563]\tLoss   0.14\tAcc  95.26\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [109][  49/1563]\tLoss   0.14\tAcc  94.69\tTime/batch 0.059\n",
      "Epoch: [109][  99/1563]\tLoss   0.14\tAcc  95.16\tTime/batch 0.058\n",
      "Epoch: [109][ 149/1563]\tLoss   0.14\tAcc  95.10\tTime/batch 0.058\n",
      "Epoch: [109][ 199/1563]\tLoss   0.14\tAcc  95.09\tTime/batch 0.058\n",
      "Epoch: [109][ 249/1563]\tLoss   0.14\tAcc  95.19\tTime/batch 0.058\n",
      "Epoch: [109][ 299/1563]\tLoss   0.14\tAcc  95.19\tTime/batch 0.058\n",
      "Epoch: [109][ 349/1563]\tLoss   0.14\tAcc  95.24\tTime/batch 0.058\n",
      "Epoch: [109][ 399/1563]\tLoss   0.14\tAcc  95.15\tTime/batch 0.057\n",
      "Epoch: [109][ 449/1563]\tLoss   0.14\tAcc  95.23\tTime/batch 0.057\n",
      "Epoch: [109][ 499/1563]\tLoss   0.14\tAcc  95.24\tTime/batch 0.057\n",
      "Epoch: [109][ 549/1563]\tLoss   0.14\tAcc  95.28\tTime/batch 0.057\n",
      "Epoch: [109][ 599/1563]\tLoss   0.14\tAcc  95.34\tTime/batch 0.057\n",
      "Epoch: [109][ 649/1563]\tLoss   0.14\tAcc  95.32\tTime/batch 0.057\n",
      "Epoch: [109][ 699/1563]\tLoss   0.13\tAcc  95.37\tTime/batch 0.057\n",
      "Epoch: [109][ 749/1563]\tLoss   0.13\tAcc  95.35\tTime/batch 0.057\n",
      "Epoch: [109][ 799/1563]\tLoss   0.13\tAcc  95.38\tTime/batch 0.057\n",
      "Epoch: [109][ 849/1563]\tLoss   0.14\tAcc  95.36\tTime/batch 0.057\n",
      "Epoch: [109][ 899/1563]\tLoss   0.13\tAcc  95.40\tTime/batch 0.057\n",
      "Epoch: [109][ 949/1563]\tLoss   0.13\tAcc  95.39\tTime/batch 0.057\n",
      "Epoch: [109][ 999/1563]\tLoss   0.13\tAcc  95.37\tTime/batch 0.057\n",
      "Epoch: [109][1049/1563]\tLoss   0.13\tAcc  95.38\tTime/batch 0.057\n",
      "Epoch: [109][1099/1563]\tLoss   0.13\tAcc  95.39\tTime/batch 0.057\n",
      "Epoch: [109][1149/1563]\tLoss   0.13\tAcc  95.36\tTime/batch 0.057\n",
      "Epoch: [109][1199/1563]\tLoss   0.13\tAcc  95.36\tTime/batch 0.057\n",
      "Epoch: [109][1249/1563]\tLoss   0.13\tAcc  95.36\tTime/batch 0.057\n",
      "Epoch: [109][1299/1563]\tLoss   0.13\tAcc  95.41\tTime/batch 0.057\n",
      "Epoch: [109][1349/1563]\tLoss   0.13\tAcc  95.41\tTime/batch 0.057\n",
      "Epoch: [109][1399/1563]\tLoss   0.13\tAcc  95.41\tTime/batch 0.057\n",
      "Epoch: [109][1449/1563]\tLoss   0.13\tAcc  95.45\tTime/batch 0.057\n",
      "Epoch: [109][1499/1563]\tLoss   0.13\tAcc  95.41\tTime/batch 0.057\n",
      "Epoch: [109][1549/1563]\tLoss   0.13\tAcc  95.45\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [110][  49/1563]\tLoss   0.13\tAcc  94.88\tTime/batch 0.058\n",
      "Epoch: [110][  99/1563]\tLoss   0.13\tAcc  95.31\tTime/batch 0.058\n",
      "Epoch: [110][ 149/1563]\tLoss   0.13\tAcc  95.27\tTime/batch 0.058\n",
      "Epoch: [110][ 199/1563]\tLoss   0.13\tAcc  95.31\tTime/batch 0.058\n",
      "Epoch: [110][ 249/1563]\tLoss   0.13\tAcc  95.46\tTime/batch 0.058\n",
      "Epoch: [110][ 299/1563]\tLoss   0.13\tAcc  95.40\tTime/batch 0.057\n",
      "Epoch: [110][ 349/1563]\tLoss   0.13\tAcc  95.52\tTime/batch 0.057\n",
      "Epoch: [110][ 399/1563]\tLoss   0.13\tAcc  95.52\tTime/batch 0.057\n",
      "Epoch: [110][ 449/1563]\tLoss   0.13\tAcc  95.56\tTime/batch 0.057\n",
      "Epoch: [110][ 499/1563]\tLoss   0.13\tAcc  95.50\tTime/batch 0.057\n",
      "Epoch: [110][ 549/1563]\tLoss   0.13\tAcc  95.40\tTime/batch 0.057\n",
      "Epoch: [110][ 599/1563]\tLoss   0.13\tAcc  95.45\tTime/batch 0.057\n",
      "Epoch: [110][ 649/1563]\tLoss   0.13\tAcc  95.42\tTime/batch 0.057\n",
      "Epoch: [110][ 699/1563]\tLoss   0.13\tAcc  95.47\tTime/batch 0.057\n",
      "Epoch: [110][ 749/1563]\tLoss   0.13\tAcc  95.47\tTime/batch 0.057\n",
      "Epoch: [110][ 799/1563]\tLoss   0.13\tAcc  95.46\tTime/batch 0.057\n",
      "Epoch: [110][ 849/1563]\tLoss   0.13\tAcc  95.43\tTime/batch 0.057\n",
      "Epoch: [110][ 899/1563]\tLoss   0.13\tAcc  95.45\tTime/batch 0.057\n",
      "Epoch: [110][ 949/1563]\tLoss   0.13\tAcc  95.44\tTime/batch 0.057\n",
      "Epoch: [110][ 999/1563]\tLoss   0.13\tAcc  95.45\tTime/batch 0.057\n",
      "Epoch: [110][1049/1563]\tLoss   0.13\tAcc  95.44\tTime/batch 0.057\n",
      "Epoch: [110][1099/1563]\tLoss   0.13\tAcc  95.43\tTime/batch 0.057\n",
      "Epoch: [110][1149/1563]\tLoss   0.13\tAcc  95.39\tTime/batch 0.057\n",
      "Epoch: [110][1199/1563]\tLoss   0.13\tAcc  95.40\tTime/batch 0.057\n",
      "Epoch: [110][1249/1563]\tLoss   0.13\tAcc  95.43\tTime/batch 0.057\n",
      "Epoch: [110][1299/1563]\tLoss   0.13\tAcc  95.41\tTime/batch 0.057\n",
      "Epoch: [110][1349/1563]\tLoss   0.13\tAcc  95.43\tTime/batch 0.057\n",
      "Epoch: [110][1399/1563]\tLoss   0.13\tAcc  95.42\tTime/batch 0.057\n",
      "Epoch: [110][1449/1563]\tLoss   0.13\tAcc  95.40\tTime/batch 0.057\n",
      "Epoch: [110][1499/1563]\tLoss   0.13\tAcc  95.36\tTime/batch 0.057\n",
      "Epoch: [110][1549/1563]\tLoss   0.13\tAcc  95.37\tTime/batch 0.057\n",
      "epoch 110\n",
      "Accuracy of the network on the 10000 test images: 91.1 %\n",
      "Sparsity of the update phase: 68.3 %\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [111][  49/1563]\tLoss   0.14\tAcc  95.00\tTime/batch 0.057\n",
      "Epoch: [111][  99/1563]\tLoss   0.12\tAcc  95.88\tTime/batch 0.057\n",
      "Epoch: [111][ 149/1563]\tLoss   0.12\tAcc  95.79\tTime/batch 0.057\n",
      "Epoch: [111][ 199/1563]\tLoss   0.13\tAcc  95.59\tTime/batch 0.057\n",
      "Epoch: [111][ 249/1563]\tLoss   0.13\tAcc  95.69\tTime/batch 0.057\n",
      "Epoch: [111][ 299/1563]\tLoss   0.13\tAcc  95.71\tTime/batch 0.057\n",
      "Epoch: [111][ 349/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [111][ 399/1563]\tLoss   0.13\tAcc  95.64\tTime/batch 0.057\n",
      "Epoch: [111][ 449/1563]\tLoss   0.13\tAcc  95.65\tTime/batch 0.057\n",
      "Epoch: [111][ 499/1563]\tLoss   0.13\tAcc  95.64\tTime/batch 0.057\n",
      "Epoch: [111][ 549/1563]\tLoss   0.13\tAcc  95.59\tTime/batch 0.057\n",
      "Epoch: [111][ 599/1563]\tLoss   0.13\tAcc  95.60\tTime/batch 0.057\n",
      "Epoch: [111][ 649/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [111][ 699/1563]\tLoss   0.13\tAcc  95.67\tTime/batch 0.057\n",
      "Epoch: [111][ 749/1563]\tLoss   0.13\tAcc  95.65\tTime/batch 0.057\n",
      "Epoch: [111][ 799/1563]\tLoss   0.13\tAcc  95.63\tTime/batch 0.057\n",
      "Epoch: [111][ 849/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [111][ 899/1563]\tLoss   0.13\tAcc  95.62\tTime/batch 0.057\n",
      "Epoch: [111][ 949/1563]\tLoss   0.13\tAcc  95.61\tTime/batch 0.057\n",
      "Epoch: [111][ 999/1563]\tLoss   0.13\tAcc  95.59\tTime/batch 0.057\n",
      "Epoch: [111][1049/1563]\tLoss   0.13\tAcc  95.61\tTime/batch 0.057\n",
      "Epoch: [111][1099/1563]\tLoss   0.13\tAcc  95.59\tTime/batch 0.057\n",
      "Epoch: [111][1149/1563]\tLoss   0.13\tAcc  95.60\tTime/batch 0.057\n",
      "Epoch: [111][1199/1563]\tLoss   0.13\tAcc  95.62\tTime/batch 0.057\n",
      "Epoch: [111][1249/1563]\tLoss   0.13\tAcc  95.61\tTime/batch 0.057\n",
      "Epoch: [111][1299/1563]\tLoss   0.13\tAcc  95.60\tTime/batch 0.057\n",
      "Epoch: [111][1349/1563]\tLoss   0.13\tAcc  95.59\tTime/batch 0.057\n",
      "Epoch: [111][1399/1563]\tLoss   0.13\tAcc  95.57\tTime/batch 0.057\n",
      "Epoch: [111][1449/1563]\tLoss   0.13\tAcc  95.57\tTime/batch 0.057\n",
      "Epoch: [111][1499/1563]\tLoss   0.13\tAcc  95.56\tTime/batch 0.057\n",
      "Epoch: [111][1549/1563]\tLoss   0.13\tAcc  95.56\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [112][  49/1563]\tLoss   0.14\tAcc  95.44\tTime/batch 0.058\n",
      "Epoch: [112][  99/1563]\tLoss   0.14\tAcc  95.22\tTime/batch 0.057\n",
      "Epoch: [112][ 149/1563]\tLoss   0.13\tAcc  95.44\tTime/batch 0.057\n",
      "Epoch: [112][ 199/1563]\tLoss   0.14\tAcc  95.36\tTime/batch 0.057\n",
      "Epoch: [112][ 249/1563]\tLoss   0.13\tAcc  95.54\tTime/batch 0.057\n",
      "Epoch: [112][ 299/1563]\tLoss   0.13\tAcc  95.64\tTime/batch 0.057\n",
      "Epoch: [112][ 349/1563]\tLoss   0.13\tAcc  95.74\tTime/batch 0.057\n",
      "Epoch: [112][ 399/1563]\tLoss   0.13\tAcc  95.78\tTime/batch 0.057\n",
      "Epoch: [112][ 449/1563]\tLoss   0.13\tAcc  95.79\tTime/batch 0.057\n",
      "Epoch: [112][ 499/1563]\tLoss   0.13\tAcc  95.68\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [112][ 549/1563]\tLoss   0.13\tAcc  95.60\tTime/batch 0.057\n",
      "Epoch: [112][ 599/1563]\tLoss   0.13\tAcc  95.61\tTime/batch 0.057\n",
      "Epoch: [112][ 649/1563]\tLoss   0.13\tAcc  95.63\tTime/batch 0.057\n",
      "Epoch: [112][ 699/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [112][ 749/1563]\tLoss   0.13\tAcc  95.63\tTime/batch 0.057\n",
      "Epoch: [112][ 799/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [112][ 849/1563]\tLoss   0.13\tAcc  95.69\tTime/batch 0.057\n",
      "Epoch: [112][ 899/1563]\tLoss   0.13\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [112][ 949/1563]\tLoss   0.13\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [112][ 999/1563]\tLoss   0.13\tAcc  95.69\tTime/batch 0.057\n",
      "Epoch: [112][1049/1563]\tLoss   0.13\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [112][1099/1563]\tLoss   0.13\tAcc  95.68\tTime/batch 0.057\n",
      "Epoch: [112][1149/1563]\tLoss   0.13\tAcc  95.64\tTime/batch 0.057\n",
      "Epoch: [112][1199/1563]\tLoss   0.13\tAcc  95.63\tTime/batch 0.057\n",
      "Epoch: [112][1249/1563]\tLoss   0.13\tAcc  95.68\tTime/batch 0.057\n",
      "Epoch: [112][1299/1563]\tLoss   0.13\tAcc  95.65\tTime/batch 0.057\n",
      "Epoch: [112][1349/1563]\tLoss   0.13\tAcc  95.65\tTime/batch 0.057\n",
      "Epoch: [112][1399/1563]\tLoss   0.13\tAcc  95.67\tTime/batch 0.057\n",
      "Epoch: [112][1449/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [112][1499/1563]\tLoss   0.13\tAcc  95.68\tTime/batch 0.057\n",
      "Epoch: [112][1549/1563]\tLoss   0.13\tAcc  95.66\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [113][  49/1563]\tLoss   0.12\tAcc  95.69\tTime/batch 0.058\n",
      "Epoch: [113][  99/1563]\tLoss   0.12\tAcc  95.69\tTime/batch 0.057\n",
      "Epoch: [113][ 149/1563]\tLoss   0.12\tAcc  95.69\tTime/batch 0.057\n",
      "Epoch: [113][ 199/1563]\tLoss   0.12\tAcc  95.78\tTime/batch 0.057\n",
      "Epoch: [113][ 249/1563]\tLoss   0.12\tAcc  95.72\tTime/batch 0.057\n",
      "Epoch: [113][ 299/1563]\tLoss   0.12\tAcc  95.83\tTime/batch 0.057\n",
      "Epoch: [113][ 349/1563]\tLoss   0.12\tAcc  95.83\tTime/batch 0.057\n",
      "Epoch: [113][ 399/1563]\tLoss   0.12\tAcc  95.84\tTime/batch 0.057\n",
      "Epoch: [113][ 449/1563]\tLoss   0.12\tAcc  95.84\tTime/batch 0.057\n",
      "Epoch: [113][ 499/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.057\n",
      "Epoch: [113][ 549/1563]\tLoss   0.12\tAcc  95.69\tTime/batch 0.057\n",
      "Epoch: [113][ 599/1563]\tLoss   0.12\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [113][ 649/1563]\tLoss   0.12\tAcc  95.71\tTime/batch 0.057\n",
      "Epoch: [113][ 699/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.056\n",
      "Epoch: [113][ 749/1563]\tLoss   0.12\tAcc  95.74\tTime/batch 0.056\n",
      "Epoch: [113][ 799/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.056\n",
      "Epoch: [113][ 849/1563]\tLoss   0.12\tAcc  95.77\tTime/batch 0.056\n",
      "Epoch: [113][ 899/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.056\n",
      "Epoch: [113][ 949/1563]\tLoss   0.12\tAcc  95.74\tTime/batch 0.056\n",
      "Epoch: [113][ 999/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.056\n",
      "Epoch: [113][1049/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.056\n",
      "Epoch: [113][1099/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.056\n",
      "Epoch: [113][1149/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.056\n",
      "Epoch: [113][1199/1563]\tLoss   0.12\tAcc  95.76\tTime/batch 0.056\n",
      "Epoch: [113][1249/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.056\n",
      "Epoch: [113][1299/1563]\tLoss   0.12\tAcc  95.72\tTime/batch 0.056\n",
      "Epoch: [113][1349/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.056\n",
      "Epoch: [113][1399/1563]\tLoss   0.12\tAcc  95.74\tTime/batch 0.057\n",
      "Epoch: [113][1449/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.057\n",
      "Epoch: [113][1499/1563]\tLoss   0.12\tAcc  95.67\tTime/batch 0.057\n",
      "Epoch: [113][1549/1563]\tLoss   0.12\tAcc  95.63\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [114][  49/1563]\tLoss   0.10\tAcc  96.31\tTime/batch 0.058\n",
      "Epoch: [114][  99/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [114][ 149/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [114][ 199/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [114][ 249/1563]\tLoss   0.12\tAcc  95.81\tTime/batch 0.057\n",
      "Epoch: [114][ 299/1563]\tLoss   0.12\tAcc  95.77\tTime/batch 0.057\n",
      "Epoch: [114][ 349/1563]\tLoss   0.12\tAcc  95.84\tTime/batch 0.057\n",
      "Epoch: [114][ 399/1563]\tLoss   0.12\tAcc  95.87\tTime/batch 0.057\n",
      "Epoch: [114][ 449/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [114][ 499/1563]\tLoss   0.12\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [114][ 549/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [114][ 599/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [114][ 649/1563]\tLoss   0.12\tAcc  95.91\tTime/batch 0.057\n",
      "Epoch: [114][ 699/1563]\tLoss   0.12\tAcc  95.93\tTime/batch 0.057\n",
      "Epoch: [114][ 749/1563]\tLoss   0.12\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [114][ 799/1563]\tLoss   0.12\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [114][ 849/1563]\tLoss   0.12\tAcc  95.85\tTime/batch 0.057\n",
      "Epoch: [114][ 899/1563]\tLoss   0.12\tAcc  95.85\tTime/batch 0.057\n",
      "Epoch: [114][ 949/1563]\tLoss   0.12\tAcc  95.81\tTime/batch 0.057\n",
      "Epoch: [114][ 999/1563]\tLoss   0.12\tAcc  95.76\tTime/batch 0.057\n",
      "Epoch: [114][1049/1563]\tLoss   0.12\tAcc  95.76\tTime/batch 0.057\n",
      "Epoch: [114][1099/1563]\tLoss   0.12\tAcc  95.74\tTime/batch 0.057\n",
      "Epoch: [114][1149/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.057\n",
      "Epoch: [114][1199/1563]\tLoss   0.12\tAcc  95.74\tTime/batch 0.057\n",
      "Epoch: [114][1249/1563]\tLoss   0.12\tAcc  95.72\tTime/batch 0.057\n",
      "Epoch: [114][1299/1563]\tLoss   0.12\tAcc  95.71\tTime/batch 0.057\n",
      "Epoch: [114][1349/1563]\tLoss   0.12\tAcc  95.71\tTime/batch 0.057\n",
      "Epoch: [114][1399/1563]\tLoss   0.12\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [114][1449/1563]\tLoss   0.12\tAcc  95.61\tTime/batch 0.057\n",
      "Epoch: [114][1499/1563]\tLoss   0.12\tAcc  95.62\tTime/batch 0.057\n",
      "Epoch: [114][1549/1563]\tLoss   0.12\tAcc  95.65\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [115][  49/1563]\tLoss   0.12\tAcc  96.19\tTime/batch 0.058\n",
      "Epoch: [115][  99/1563]\tLoss   0.12\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [115][ 149/1563]\tLoss   0.12\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [115][ 199/1563]\tLoss   0.12\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [115][ 249/1563]\tLoss   0.12\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [115][ 299/1563]\tLoss   0.12\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [115][ 349/1563]\tLoss   0.12\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [115][ 399/1563]\tLoss   0.12\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [115][ 449/1563]\tLoss   0.12\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [115][ 499/1563]\tLoss   0.12\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [115][ 549/1563]\tLoss   0.12\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [115][ 599/1563]\tLoss   0.12\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [115][ 649/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [115][ 699/1563]\tLoss   0.12\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [115][ 749/1563]\tLoss   0.12\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [115][ 799/1563]\tLoss   0.12\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [115][ 849/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [115][ 899/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [115][ 949/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [115][ 999/1563]\tLoss   0.12\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [115][1049/1563]\tLoss   0.12\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [115][1099/1563]\tLoss   0.12\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [115][1149/1563]\tLoss   0.12\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [115][1199/1563]\tLoss   0.12\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [115][1249/1563]\tLoss   0.12\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [115][1299/1563]\tLoss   0.12\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [115][1349/1563]\tLoss   0.12\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [115][1399/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [115][1449/1563]\tLoss   0.12\tAcc  95.93\tTime/batch 0.057\n",
      "Epoch: [115][1499/1563]\tLoss   0.12\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [115][1549/1563]\tLoss   0.12\tAcc  95.91\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [116][  49/1563]\tLoss   0.13\tAcc  95.88\tTime/batch 0.058\n",
      "Epoch: [116][  99/1563]\tLoss   0.12\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [116][ 149/1563]\tLoss   0.12\tAcc  96.33\tTime/batch 0.057\n",
      "Epoch: [116][ 199/1563]\tLoss   0.12\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [116][ 249/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [116][ 299/1563]\tLoss   0.12\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [116][ 349/1563]\tLoss   0.12\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [116][ 399/1563]\tLoss   0.12\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [116][ 449/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [116][ 499/1563]\tLoss   0.12\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [116][ 549/1563]\tLoss   0.12\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [116][ 599/1563]\tLoss   0.12\tAcc  96.02\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [116][ 649/1563]\tLoss   0.12\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [116][ 699/1563]\tLoss   0.12\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [116][ 749/1563]\tLoss   0.12\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [116][ 799/1563]\tLoss   0.12\tAcc  95.93\tTime/batch 0.057\n",
      "Epoch: [116][ 849/1563]\tLoss   0.12\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [116][ 899/1563]\tLoss   0.12\tAcc  95.91\tTime/batch 0.057\n",
      "Epoch: [116][ 949/1563]\tLoss   0.12\tAcc  95.87\tTime/batch 0.057\n",
      "Epoch: [116][ 999/1563]\tLoss   0.12\tAcc  95.88\tTime/batch 0.057\n",
      "Epoch: [116][1049/1563]\tLoss   0.12\tAcc  95.89\tTime/batch 0.057\n",
      "Epoch: [116][1099/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [116][1149/1563]\tLoss   0.12\tAcc  95.93\tTime/batch 0.057\n",
      "Epoch: [116][1199/1563]\tLoss   0.12\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [116][1249/1563]\tLoss   0.12\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [116][1299/1563]\tLoss   0.12\tAcc  95.91\tTime/batch 0.057\n",
      "Epoch: [116][1349/1563]\tLoss   0.12\tAcc  95.88\tTime/batch 0.057\n",
      "Epoch: [116][1399/1563]\tLoss   0.12\tAcc  95.85\tTime/batch 0.057\n",
      "Epoch: [116][1449/1563]\tLoss   0.12\tAcc  95.86\tTime/batch 0.057\n",
      "Epoch: [116][1499/1563]\tLoss   0.12\tAcc  95.85\tTime/batch 0.057\n",
      "Epoch: [116][1549/1563]\tLoss   0.12\tAcc  95.85\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [117][  49/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.058\n",
      "Epoch: [117][  99/1563]\tLoss   0.12\tAcc  95.84\tTime/batch 0.057\n",
      "Epoch: [117][ 149/1563]\tLoss   0.12\tAcc  95.79\tTime/batch 0.057\n",
      "Epoch: [117][ 199/1563]\tLoss   0.12\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [117][ 249/1563]\tLoss   0.12\tAcc  95.65\tTime/batch 0.057\n",
      "Epoch: [117][ 299/1563]\tLoss   0.12\tAcc  95.53\tTime/batch 0.057\n",
      "Epoch: [117][ 349/1563]\tLoss   0.12\tAcc  95.46\tTime/batch 0.057\n",
      "Epoch: [117][ 399/1563]\tLoss   0.12\tAcc  95.55\tTime/batch 0.057\n",
      "Epoch: [117][ 449/1563]\tLoss   0.12\tAcc  95.47\tTime/batch 0.057\n",
      "Epoch: [117][ 499/1563]\tLoss   0.13\tAcc  95.49\tTime/batch 0.057\n",
      "Epoch: [117][ 549/1563]\tLoss   0.12\tAcc  95.64\tTime/batch 0.057\n",
      "Epoch: [117][ 599/1563]\tLoss   0.12\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [117][ 649/1563]\tLoss   0.12\tAcc  95.72\tTime/batch 0.057\n",
      "Epoch: [117][ 699/1563]\tLoss   0.12\tAcc  95.72\tTime/batch 0.057\n",
      "Epoch: [117][ 749/1563]\tLoss   0.12\tAcc  95.79\tTime/batch 0.057\n",
      "Epoch: [117][ 799/1563]\tLoss   0.12\tAcc  95.78\tTime/batch 0.057\n",
      "Epoch: [117][ 849/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.057\n",
      "Epoch: [117][ 899/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.057\n",
      "Epoch: [117][ 949/1563]\tLoss   0.12\tAcc  95.73\tTime/batch 0.057\n",
      "Epoch: [117][ 999/1563]\tLoss   0.12\tAcc  95.72\tTime/batch 0.057\n",
      "Epoch: [117][1049/1563]\tLoss   0.12\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [117][1099/1563]\tLoss   0.12\tAcc  95.70\tTime/batch 0.057\n",
      "Epoch: [117][1149/1563]\tLoss   0.12\tAcc  95.74\tTime/batch 0.057\n",
      "Epoch: [117][1199/1563]\tLoss   0.12\tAcc  95.71\tTime/batch 0.057\n",
      "Epoch: [117][1249/1563]\tLoss   0.12\tAcc  95.76\tTime/batch 0.057\n",
      "Epoch: [117][1299/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.057\n",
      "Epoch: [117][1349/1563]\tLoss   0.12\tAcc  95.78\tTime/batch 0.057\n",
      "Epoch: [117][1399/1563]\tLoss   0.12\tAcc  95.78\tTime/batch 0.057\n",
      "Epoch: [117][1449/1563]\tLoss   0.12\tAcc  95.78\tTime/batch 0.057\n",
      "Epoch: [117][1499/1563]\tLoss   0.12\tAcc  95.77\tTime/batch 0.057\n",
      "Epoch: [117][1549/1563]\tLoss   0.12\tAcc  95.78\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [118][  49/1563]\tLoss   0.12\tAcc  96.06\tTime/batch 0.058\n",
      "Epoch: [118][  99/1563]\tLoss   0.11\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [118][ 149/1563]\tLoss   0.11\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [118][ 199/1563]\tLoss   0.11\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [118][ 249/1563]\tLoss   0.11\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [118][ 299/1563]\tLoss   0.12\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [118][ 349/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [118][ 399/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [118][ 449/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [118][ 499/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [118][ 549/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [118][ 599/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [118][ 649/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [118][ 699/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [118][ 749/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [118][ 799/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [118][ 849/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [118][ 899/1563]\tLoss   0.12\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [118][ 949/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [118][ 999/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [118][1049/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [118][1099/1563]\tLoss   0.12\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [118][1149/1563]\tLoss   0.12\tAcc  95.96\tTime/batch 0.057\n",
      "Epoch: [118][1199/1563]\tLoss   0.12\tAcc  95.93\tTime/batch 0.057\n",
      "Epoch: [118][1249/1563]\tLoss   0.12\tAcc  95.93\tTime/batch 0.057\n",
      "Epoch: [118][1299/1563]\tLoss   0.12\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [118][1349/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [118][1399/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [118][1449/1563]\tLoss   0.12\tAcc  95.89\tTime/batch 0.057\n",
      "Epoch: [118][1499/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [118][1549/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [119][  49/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [119][  99/1563]\tLoss   0.11\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [119][ 149/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [119][ 199/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.056\n",
      "Epoch: [119][ 249/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.056\n",
      "Epoch: [119][ 299/1563]\tLoss   0.11\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [119][ 349/1563]\tLoss   0.12\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [119][ 399/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [119][ 449/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [119][ 499/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [119][ 549/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [119][ 599/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [119][ 649/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [119][ 699/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [119][ 749/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [119][ 799/1563]\tLoss   0.12\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [119][ 849/1563]\tLoss   0.12\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [119][ 899/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [119][ 949/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [119][ 999/1563]\tLoss   0.12\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [119][1049/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [119][1099/1563]\tLoss   0.12\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [119][1149/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [119][1199/1563]\tLoss   0.12\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [119][1249/1563]\tLoss   0.12\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [119][1299/1563]\tLoss   0.12\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [119][1349/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [119][1399/1563]\tLoss   0.12\tAcc  95.89\tTime/batch 0.057\n",
      "Epoch: [119][1449/1563]\tLoss   0.12\tAcc  95.88\tTime/batch 0.057\n",
      "Epoch: [119][1499/1563]\tLoss   0.12\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [119][1549/1563]\tLoss   0.12\tAcc  95.89\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [120][  49/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.059\n",
      "Epoch: [120][  99/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.059\n",
      "Epoch: [120][ 149/1563]\tLoss   0.11\tAcc  96.33\tTime/batch 0.058\n",
      "Epoch: [120][ 199/1563]\tLoss   0.11\tAcc  96.39\tTime/batch 0.058\n",
      "Epoch: [120][ 249/1563]\tLoss   0.11\tAcc  96.42\tTime/batch 0.058\n",
      "Epoch: [120][ 299/1563]\tLoss   0.11\tAcc  96.32\tTime/batch 0.058\n",
      "Epoch: [120][ 349/1563]\tLoss   0.11\tAcc  96.32\tTime/batch 0.058\n",
      "Epoch: [120][ 399/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.058\n",
      "Epoch: [120][ 449/1563]\tLoss   0.11\tAcc  96.24\tTime/batch 0.058\n",
      "Epoch: [120][ 499/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.058\n",
      "Epoch: [120][ 549/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.058\n",
      "Epoch: [120][ 599/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.058\n",
      "Epoch: [120][ 649/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.058\n",
      "Epoch: [120][ 699/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [120][ 749/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.058\n",
      "Epoch: [120][ 799/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.058\n",
      "Epoch: [120][ 849/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.058\n",
      "Epoch: [120][ 899/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.058\n",
      "Epoch: [120][ 949/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [120][ 999/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [120][1049/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [120][1099/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [120][1149/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [120][1199/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [120][1249/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [120][1299/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [120][1349/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [120][1399/1563]\tLoss   0.12\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [120][1449/1563]\tLoss   0.12\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [120][1499/1563]\tLoss   0.12\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [120][1549/1563]\tLoss   0.12\tAcc  96.00\tTime/batch 0.057\n",
      "epoch 120\n",
      "Accuracy of the network on the 10000 test images: 91.3 %\n",
      "Sparsity of the update phase: 69.1 %\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [121][  49/1563]\tLoss   0.12\tAcc  95.75\tTime/batch 0.058\n",
      "Epoch: [121][  99/1563]\tLoss   0.11\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [121][ 149/1563]\tLoss   0.12\tAcc  95.79\tTime/batch 0.057\n",
      "Epoch: [121][ 199/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [121][ 249/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [121][ 299/1563]\tLoss   0.11\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [121][ 349/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [121][ 399/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [121][ 449/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [121][ 499/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [121][ 549/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [121][ 599/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [121][ 649/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [121][ 699/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [121][ 749/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [121][ 799/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [121][ 849/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [121][ 899/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [121][ 949/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [121][ 999/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.058\n",
      "Epoch: [121][1049/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.058\n",
      "Epoch: [121][1099/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.058\n",
      "Epoch: [121][1149/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.058\n",
      "Epoch: [121][1199/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.058\n",
      "Epoch: [121][1249/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.058\n",
      "Epoch: [121][1299/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.058\n",
      "Epoch: [121][1349/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.058\n",
      "Epoch: [121][1399/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.058\n",
      "Epoch: [121][1449/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.058\n",
      "Epoch: [121][1499/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.058\n",
      "Epoch: [121][1549/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.058\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [122][  49/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.058\n",
      "Epoch: [122][  99/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.058\n",
      "Epoch: [122][ 149/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [122][ 199/1563]\tLoss   0.10\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [122][ 249/1563]\tLoss   0.10\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [122][ 299/1563]\tLoss   0.10\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [122][ 349/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [122][ 399/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [122][ 449/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [122][ 499/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [122][ 549/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [122][ 599/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [122][ 649/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [122][ 699/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [122][ 749/1563]\tLoss   0.11\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [122][ 799/1563]\tLoss   0.11\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [122][ 849/1563]\tLoss   0.12\tAcc  95.87\tTime/batch 0.057\n",
      "Epoch: [122][ 899/1563]\tLoss   0.11\tAcc  95.90\tTime/batch 0.057\n",
      "Epoch: [122][ 949/1563]\tLoss   0.11\tAcc  95.92\tTime/batch 0.057\n",
      "Epoch: [122][ 999/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [122][1049/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [122][1099/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [122][1149/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [122][1199/1563]\tLoss   0.11\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [122][1249/1563]\tLoss   0.11\tAcc  95.96\tTime/batch 0.057\n",
      "Epoch: [122][1299/1563]\tLoss   0.11\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [122][1349/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [122][1399/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [122][1449/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [122][1499/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [122][1549/1563]\tLoss   0.11\tAcc  95.98\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [123][  49/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.058\n",
      "Epoch: [123][  99/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [123][ 149/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [123][ 199/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [123][ 249/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [123][ 299/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [123][ 349/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [123][ 399/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [123][ 449/1563]\tLoss   0.11\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [123][ 499/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [123][ 549/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [123][ 599/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [123][ 649/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [123][ 699/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [123][ 749/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [123][ 799/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [123][ 849/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [123][ 899/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [123][ 949/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [123][ 999/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [123][1049/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [123][1099/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [123][1149/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [123][1199/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [123][1249/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [123][1299/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [123][1349/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [123][1399/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [123][1449/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [123][1499/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [123][1549/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [124][  49/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.058\n",
      "Epoch: [124][  99/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.058\n",
      "Epoch: [124][ 149/1563]\tLoss   0.10\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [124][ 199/1563]\tLoss   0.10\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [124][ 249/1563]\tLoss   0.10\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [124][ 299/1563]\tLoss   0.10\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [124][ 349/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [124][ 399/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [124][ 449/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [124][ 499/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [124][ 549/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [124][ 599/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [124][ 649/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [124][ 699/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [124][ 749/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [124][ 799/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [124][ 849/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [124][ 899/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [124][ 949/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [124][ 999/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [124][1049/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [124][1099/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [124][1149/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [124][1199/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [124][1249/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [124][1299/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [124][1349/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [124][1399/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [124][1449/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [124][1499/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [124][1549/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [125][  49/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [125][  99/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [125][ 149/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [125][ 199/1563]\tLoss   0.10\tAcc  96.17\tTime/batch 0.056\n",
      "Epoch: [125][ 249/1563]\tLoss   0.10\tAcc  96.21\tTime/batch 0.056\n",
      "Epoch: [125][ 299/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [125][ 349/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [125][ 399/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [125][ 449/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [125][ 499/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [125][ 549/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [125][ 599/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [125][ 649/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [125][ 699/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.057\n",
      "Epoch: [125][ 749/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [125][ 799/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [125][ 849/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [125][ 899/1563]\tLoss   0.11\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [125][ 949/1563]\tLoss   0.11\tAcc  95.96\tTime/batch 0.057\n",
      "Epoch: [125][ 999/1563]\tLoss   0.11\tAcc  95.96\tTime/batch 0.057\n",
      "Epoch: [125][1049/1563]\tLoss   0.11\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [125][1099/1563]\tLoss   0.11\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [125][1149/1563]\tLoss   0.11\tAcc  95.95\tTime/batch 0.057\n",
      "Epoch: [125][1199/1563]\tLoss   0.11\tAcc  95.97\tTime/batch 0.057\n",
      "Epoch: [125][1249/1563]\tLoss   0.11\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [125][1299/1563]\tLoss   0.11\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [125][1349/1563]\tLoss   0.11\tAcc  95.98\tTime/batch 0.057\n",
      "Epoch: [125][1399/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [125][1449/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [125][1499/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [125][1549/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [126][  49/1563]\tLoss   0.08\tAcc  96.88\tTime/batch 0.058\n",
      "Epoch: [126][  99/1563]\tLoss   0.09\tAcc  96.81\tTime/batch 0.057\n",
      "Epoch: [126][ 149/1563]\tLoss   0.10\tAcc  96.33\tTime/batch 0.057\n",
      "Epoch: [126][ 199/1563]\tLoss   0.10\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [126][ 249/1563]\tLoss   0.10\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [126][ 299/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [126][ 349/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [126][ 399/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [126][ 449/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [126][ 499/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [126][ 549/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [126][ 599/1563]\tLoss   0.11\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [126][ 649/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [126][ 699/1563]\tLoss   0.11\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [126][ 749/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [126][ 799/1563]\tLoss   0.11\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [126][ 849/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [126][ 899/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [126][ 949/1563]\tLoss   0.11\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [126][ 999/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [126][1049/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [126][1099/1563]\tLoss   0.11\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [126][1149/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [126][1199/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [126][1249/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [126][1299/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [126][1349/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "Epoch: [126][1399/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [126][1449/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [126][1499/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [126][1549/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [127][  49/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.058\n",
      "Epoch: [127][  99/1563]\tLoss   0.10\tAcc  96.31\tTime/batch 0.058\n",
      "Epoch: [127][ 149/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [127][ 199/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [127][ 249/1563]\tLoss   0.11\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [127][ 299/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [127][ 349/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [127][ 399/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][ 449/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][ 499/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][ 549/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [127][ 599/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [127][ 649/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [127][ 699/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [127][ 749/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [127][ 799/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [127][ 849/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [127][ 899/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [127][ 949/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][ 999/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][1049/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [127][1099/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][1149/1563]\tLoss   0.11\tAcc  96.24\tTime/batch 0.057\n",
      "Epoch: [127][1199/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [127][1249/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [127][1299/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [127][1349/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [127][1399/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [127][1449/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [127][1499/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [127][1549/1563]\tLoss   0.11\tAcc  96.11\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [128][  49/1563]\tLoss   0.10\tAcc  96.88\tTime/batch 0.058\n",
      "Epoch: [128][  99/1563]\tLoss   0.10\tAcc  97.12\tTime/batch 0.057\n",
      "Epoch: [128][ 149/1563]\tLoss   0.10\tAcc  96.88\tTime/batch 0.057\n",
      "Epoch: [128][ 199/1563]\tLoss   0.10\tAcc  96.84\tTime/batch 0.057\n",
      "Epoch: [128][ 249/1563]\tLoss   0.10\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [128][ 299/1563]\tLoss   0.10\tAcc  96.68\tTime/batch 0.057\n",
      "Epoch: [128][ 349/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [128][ 399/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.057\n",
      "Epoch: [128][ 449/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [128][ 499/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [128][ 549/1563]\tLoss   0.11\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [128][ 599/1563]\tLoss   0.11\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [128][ 649/1563]\tLoss   0.11\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [128][ 699/1563]\tLoss   0.11\tAcc  96.35\tTime/batch 0.057\n",
      "Epoch: [128][ 749/1563]\tLoss   0.11\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [128][ 799/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [128][ 849/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [128][ 899/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [128][ 949/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [128][ 999/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [128][1049/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [128][1099/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [128][1149/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [128][1199/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [128][1249/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [128][1299/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [128][1349/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [128][1399/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [128][1449/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [128][1499/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [128][1549/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [129][  49/1563]\tLoss   0.12\tAcc  96.00\tTime/batch 0.058\n",
      "Epoch: [129][  99/1563]\tLoss   0.11\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [129][ 149/1563]\tLoss   0.11\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [129][ 199/1563]\tLoss   0.11\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [129][ 249/1563]\tLoss   0.11\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [129][ 299/1563]\tLoss   0.11\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [129][ 349/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [129][ 399/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [129][ 449/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [129][ 499/1563]\tLoss   0.11\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [129][ 549/1563]\tLoss   0.11\tAcc  96.31\tTime/batch 0.057\n",
      "Epoch: [129][ 599/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [129][ 649/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [129][ 699/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [129][ 749/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [129][ 799/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [129][ 849/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [129][ 899/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [129][ 949/1563]\tLoss   0.11\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [129][ 999/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [129][1049/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [129][1099/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [129][1149/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [129][1199/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [129][1249/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [129][1299/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [129][1349/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [129][1399/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [129][1449/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [129][1499/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [129][1549/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [130][  49/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.058\n",
      "Epoch: [130][  99/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [130][ 149/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.057\n",
      "Epoch: [130][ 199/1563]\tLoss   0.10\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [130][ 249/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [130][ 299/1563]\tLoss   0.11\tAcc  96.16\tTime/batch 0.057\n",
      "Epoch: [130][ 349/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [130][ 399/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [130][ 449/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [130][ 499/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [130][ 549/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [130][ 599/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [130][ 649/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [130][ 699/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [130][ 749/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [130][ 799/1563]\tLoss   0.11\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [130][ 849/1563]\tLoss   0.11\tAcc  96.24\tTime/batch 0.057\n",
      "Epoch: [130][ 899/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [130][ 949/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [130][ 999/1563]\tLoss   0.11\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [130][1049/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [130][1099/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [130][1149/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [130][1199/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [130][1249/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [130][1299/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [130][1349/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [130][1399/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [130][1449/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [130][1499/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [130][1549/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "epoch 130\n",
      "Accuracy of the network on the 10000 test images: 91.0 %\n",
      "Sparsity of the update phase: 69.0 %\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [131][  49/1563]\tLoss   0.08\tAcc  97.00\tTime/batch 0.058\n",
      "Epoch: [131][  99/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [131][ 149/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [131][ 199/1563]\tLoss   0.10\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [131][ 249/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [131][ 299/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.056\n",
      "Epoch: [131][ 349/1563]\tLoss   0.11\tAcc  96.04\tTime/batch 0.056\n",
      "Epoch: [131][ 399/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.056\n",
      "Epoch: [131][ 449/1563]\tLoss   0.11\tAcc  96.16\tTime/batch 0.056\n",
      "Epoch: [131][ 499/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.056\n",
      "Epoch: [131][ 549/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.056\n",
      "Epoch: [131][ 599/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.056\n",
      "Epoch: [131][ 649/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.056\n",
      "Epoch: [131][ 699/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.056\n",
      "Epoch: [131][ 749/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [131][ 799/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [131][ 849/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [131][ 899/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [131][ 949/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [131][ 999/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [131][1049/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [131][1099/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [131][1149/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [131][1199/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [131][1249/1563]\tLoss   0.10\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [131][1299/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [131][1349/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [131][1399/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [131][1449/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [131][1499/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [131][1549/1563]\tLoss   0.11\tAcc  96.24\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [132][  49/1563]\tLoss   0.11\tAcc  96.50\tTime/batch 0.058\n",
      "Epoch: [132][  99/1563]\tLoss   0.10\tAcc  96.72\tTime/batch 0.058\n",
      "Epoch: [132][ 149/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [132][ 199/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [132][ 249/1563]\tLoss   0.11\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [132][ 299/1563]\tLoss   0.11\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [132][ 349/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [132][ 399/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "Epoch: [132][ 449/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [132][ 499/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [132][ 549/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [132][ 599/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [132][ 649/1563]\tLoss   0.11\tAcc  96.24\tTime/batch 0.057\n",
      "Epoch: [132][ 699/1563]\tLoss   0.11\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [132][ 749/1563]\tLoss   0.11\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [132][ 799/1563]\tLoss   0.11\tAcc  96.33\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [132][ 849/1563]\tLoss   0.11\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [132][ 899/1563]\tLoss   0.11\tAcc  96.33\tTime/batch 0.057\n",
      "Epoch: [132][ 949/1563]\tLoss   0.11\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [132][ 999/1563]\tLoss   0.11\tAcc  96.33\tTime/batch 0.057\n",
      "Epoch: [132][1049/1563]\tLoss   0.11\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [132][1099/1563]\tLoss   0.11\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [132][1149/1563]\tLoss   0.11\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [132][1199/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [132][1249/1563]\tLoss   0.11\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [132][1299/1563]\tLoss   0.11\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [132][1349/1563]\tLoss   0.11\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [132][1399/1563]\tLoss   0.11\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [132][1449/1563]\tLoss   0.11\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [132][1499/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [132][1549/1563]\tLoss   0.11\tAcc  96.29\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [133][  49/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.058\n",
      "Epoch: [133][  99/1563]\tLoss   0.09\tAcc  96.75\tTime/batch 0.057\n",
      "Epoch: [133][ 149/1563]\tLoss   0.09\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [133][ 199/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [133][ 249/1563]\tLoss   0.10\tAcc  96.31\tTime/batch 0.057\n",
      "Epoch: [133][ 299/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [133][ 349/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [133][ 399/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [133][ 449/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [133][ 499/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [133][ 549/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [133][ 599/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [133][ 649/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [133][ 699/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [133][ 749/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [133][ 799/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [133][ 849/1563]\tLoss   0.10\tAcc  96.35\tTime/batch 0.057\n",
      "Epoch: [133][ 899/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [133][ 949/1563]\tLoss   0.10\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [133][ 999/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [133][1049/1563]\tLoss   0.10\tAcc  96.37\tTime/batch 0.057\n",
      "Epoch: [133][1099/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [133][1149/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [133][1199/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [133][1249/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [133][1299/1563]\tLoss   0.10\tAcc  96.35\tTime/batch 0.057\n",
      "Epoch: [133][1349/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [133][1399/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [133][1449/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [133][1499/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [133][1549/1563]\tLoss   0.10\tAcc  96.33\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [134][  49/1563]\tLoss   0.09\tAcc  96.50\tTime/batch 0.058\n",
      "Epoch: [134][  99/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.058\n",
      "Epoch: [134][ 149/1563]\tLoss   0.11\tAcc  95.50\tTime/batch 0.057\n",
      "Epoch: [134][ 199/1563]\tLoss   0.11\tAcc  95.61\tTime/batch 0.057\n",
      "Epoch: [134][ 249/1563]\tLoss   0.11\tAcc  95.66\tTime/batch 0.057\n",
      "Epoch: [134][ 299/1563]\tLoss   0.11\tAcc  95.71\tTime/batch 0.057\n",
      "Epoch: [134][ 349/1563]\tLoss   0.11\tAcc  95.75\tTime/batch 0.057\n",
      "Epoch: [134][ 399/1563]\tLoss   0.11\tAcc  95.81\tTime/batch 0.057\n",
      "Epoch: [134][ 449/1563]\tLoss   0.11\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [134][ 499/1563]\tLoss   0.11\tAcc  95.88\tTime/batch 0.057\n",
      "Epoch: [134][ 549/1563]\tLoss   0.11\tAcc  95.91\tTime/batch 0.057\n",
      "Epoch: [134][ 599/1563]\tLoss   0.11\tAcc  95.99\tTime/batch 0.057\n",
      "Epoch: [134][ 649/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [134][ 699/1563]\tLoss   0.11\tAcc  96.01\tTime/batch 0.057\n",
      "Epoch: [134][ 749/1563]\tLoss   0.11\tAcc  96.03\tTime/batch 0.057\n",
      "Epoch: [134][ 799/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [134][ 849/1563]\tLoss   0.11\tAcc  96.02\tTime/batch 0.057\n",
      "Epoch: [134][ 899/1563]\tLoss   0.11\tAcc  96.05\tTime/batch 0.057\n",
      "Epoch: [134][ 949/1563]\tLoss   0.11\tAcc  96.08\tTime/batch 0.057\n",
      "Epoch: [134][ 999/1563]\tLoss   0.11\tAcc  96.07\tTime/batch 0.057\n",
      "Epoch: [134][1049/1563]\tLoss   0.11\tAcc  96.09\tTime/batch 0.057\n",
      "Epoch: [134][1099/1563]\tLoss   0.11\tAcc  96.12\tTime/batch 0.057\n",
      "Epoch: [134][1149/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [134][1199/1563]\tLoss   0.11\tAcc  96.14\tTime/batch 0.057\n",
      "Epoch: [134][1249/1563]\tLoss   0.11\tAcc  96.15\tTime/batch 0.057\n",
      "Epoch: [134][1299/1563]\tLoss   0.11\tAcc  96.17\tTime/batch 0.057\n",
      "Epoch: [134][1349/1563]\tLoss   0.11\tAcc  96.18\tTime/batch 0.057\n",
      "Epoch: [134][1399/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [134][1449/1563]\tLoss   0.11\tAcc  96.20\tTime/batch 0.057\n",
      "Epoch: [134][1499/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [134][1549/1563]\tLoss   0.11\tAcc  96.21\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [135][  49/1563]\tLoss   0.10\tAcc  96.88\tTime/batch 0.058\n",
      "Epoch: [135][  99/1563]\tLoss   0.09\tAcc  97.06\tTime/batch 0.057\n",
      "Epoch: [135][ 149/1563]\tLoss   0.10\tAcc  96.75\tTime/batch 0.057\n",
      "Epoch: [135][ 199/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [135][ 249/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [135][ 299/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.057\n",
      "Epoch: [135][ 349/1563]\tLoss   0.10\tAcc  96.73\tTime/batch 0.057\n",
      "Epoch: [135][ 399/1563]\tLoss   0.10\tAcc  96.72\tTime/batch 0.057\n",
      "Epoch: [135][ 449/1563]\tLoss   0.10\tAcc  96.68\tTime/batch 0.057\n",
      "Epoch: [135][ 499/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.057\n",
      "Epoch: [135][ 549/1563]\tLoss   0.10\tAcc  96.65\tTime/batch 0.057\n",
      "Epoch: [135][ 599/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.057\n",
      "Epoch: [135][ 649/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.057\n",
      "Epoch: [135][ 699/1563]\tLoss   0.10\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [135][ 749/1563]\tLoss   0.10\tAcc  96.65\tTime/batch 0.057\n",
      "Epoch: [135][ 799/1563]\tLoss   0.10\tAcc  96.69\tTime/batch 0.057\n",
      "Epoch: [135][ 849/1563]\tLoss   0.10\tAcc  96.70\tTime/batch 0.057\n",
      "Epoch: [135][ 899/1563]\tLoss   0.10\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [135][ 949/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.057\n",
      "Epoch: [135][ 999/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [135][1049/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [135][1099/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.057\n",
      "Epoch: [135][1149/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [135][1199/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [135][1249/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [135][1299/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.056\n",
      "Epoch: [135][1349/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.056\n",
      "Epoch: [135][1399/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [135][1449/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.056\n",
      "Epoch: [135][1499/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [135][1549/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.056\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [136][  49/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.058\n",
      "Epoch: [136][  99/1563]\tLoss   0.10\tAcc  96.31\tTime/batch 0.057\n",
      "Epoch: [136][ 149/1563]\tLoss   0.10\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [136][ 199/1563]\tLoss   0.10\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [136][ 249/1563]\tLoss   0.11\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [136][ 299/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [136][ 349/1563]\tLoss   0.10\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [136][ 399/1563]\tLoss   0.11\tAcc  96.13\tTime/batch 0.057\n",
      "Epoch: [136][ 449/1563]\tLoss   0.11\tAcc  96.10\tTime/batch 0.057\n",
      "Epoch: [136][ 499/1563]\tLoss   0.11\tAcc  96.19\tTime/batch 0.057\n",
      "Epoch: [136][ 549/1563]\tLoss   0.10\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [136][ 599/1563]\tLoss   0.10\tAcc  96.31\tTime/batch 0.057\n",
      "Epoch: [136][ 649/1563]\tLoss   0.10\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [136][ 699/1563]\tLoss   0.10\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [136][ 749/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [136][ 799/1563]\tLoss   0.10\tAcc  96.26\tTime/batch 0.057\n",
      "Epoch: [136][ 849/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [136][ 899/1563]\tLoss   0.10\tAcc  96.30\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [136][ 949/1563]\tLoss   0.10\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [136][ 999/1563]\tLoss   0.10\tAcc  96.28\tTime/batch 0.057\n",
      "Epoch: [136][1049/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [136][1099/1563]\tLoss   0.10\tAcc  96.27\tTime/batch 0.057\n",
      "Epoch: [136][1149/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [136][1199/1563]\tLoss   0.10\tAcc  96.24\tTime/batch 0.057\n",
      "Epoch: [136][1249/1563]\tLoss   0.10\tAcc  96.24\tTime/batch 0.057\n",
      "Epoch: [136][1299/1563]\tLoss   0.10\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [136][1349/1563]\tLoss   0.10\tAcc  96.23\tTime/batch 0.057\n",
      "Epoch: [136][1399/1563]\tLoss   0.11\tAcc  96.22\tTime/batch 0.057\n",
      "Epoch: [136][1449/1563]\tLoss   0.11\tAcc  96.24\tTime/batch 0.057\n",
      "Epoch: [136][1499/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "Epoch: [136][1549/1563]\tLoss   0.10\tAcc  96.25\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [137][  49/1563]\tLoss   0.11\tAcc  96.31\tTime/batch 0.058\n",
      "Epoch: [137][  99/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [137][ 149/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [137][ 199/1563]\tLoss   0.09\tAcc  96.78\tTime/batch 0.057\n",
      "Epoch: [137][ 249/1563]\tLoss   0.09\tAcc  96.71\tTime/batch 0.057\n",
      "Epoch: [137][ 299/1563]\tLoss   0.10\tAcc  96.70\tTime/batch 0.057\n",
      "Epoch: [137][ 349/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [137][ 399/1563]\tLoss   0.09\tAcc  96.79\tTime/batch 0.057\n",
      "Epoch: [137][ 449/1563]\tLoss   0.09\tAcc  96.72\tTime/batch 0.057\n",
      "Epoch: [137][ 499/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [137][ 549/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [137][ 599/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [137][ 649/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [137][ 699/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [137][ 749/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [137][ 799/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [137][ 849/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [137][ 899/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [137][ 949/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [137][ 999/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [137][1049/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [137][1099/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [137][1149/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [137][1199/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [137][1249/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [137][1299/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [137][1349/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [137][1399/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [137][1449/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "Epoch: [137][1499/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "Epoch: [137][1549/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [138][  49/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.058\n",
      "Epoch: [138][  99/1563]\tLoss   0.10\tAcc  96.81\tTime/batch 0.058\n",
      "Epoch: [138][ 149/1563]\tLoss   0.09\tAcc  97.04\tTime/batch 0.058\n",
      "Epoch: [138][ 199/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.057\n",
      "Epoch: [138][ 249/1563]\tLoss   0.10\tAcc  96.74\tTime/batch 0.057\n",
      "Epoch: [138][ 299/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [138][ 349/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [138][ 399/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [138][ 449/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [138][ 499/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [138][ 549/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [138][ 599/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [138][ 649/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [138][ 699/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [138][ 749/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [138][ 799/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [138][ 849/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.056\n",
      "Epoch: [138][ 899/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [138][ 949/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [138][ 999/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.056\n",
      "Epoch: [138][1049/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.056\n",
      "Epoch: [138][1099/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.056\n",
      "Epoch: [138][1149/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.056\n",
      "Epoch: [138][1199/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [138][1249/1563]\tLoss   0.10\tAcc  96.36\tTime/batch 0.056\n",
      "Epoch: [138][1299/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [138][1349/1563]\tLoss   0.10\tAcc  96.37\tTime/batch 0.056\n",
      "Epoch: [138][1399/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [138][1449/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [138][1499/1563]\tLoss   0.10\tAcc  96.35\tTime/batch 0.056\n",
      "Epoch: [138][1549/1563]\tLoss   0.10\tAcc  96.35\tTime/batch 0.056\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [139][  49/1563]\tLoss   0.11\tAcc  96.06\tTime/batch 0.058\n",
      "Epoch: [139][  99/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [139][ 149/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [139][ 199/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [139][ 249/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [139][ 299/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [139][ 349/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [139][ 399/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [139][ 449/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "Epoch: [139][ 499/1563]\tLoss   0.10\tAcc  96.35\tTime/batch 0.057\n",
      "Epoch: [139][ 549/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [139][ 599/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [139][ 649/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [139][ 699/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [139][ 749/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [139][ 799/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [139][ 849/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [139][ 899/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [139][ 949/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [139][ 999/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [139][1049/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [139][1099/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [139][1149/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "Epoch: [139][1199/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [139][1249/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [139][1299/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [139][1349/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [139][1399/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "Epoch: [139][1449/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [139][1499/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [139][1549/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [140][  49/1563]\tLoss   0.09\tAcc  97.12\tTime/batch 0.058\n",
      "Epoch: [140][  99/1563]\tLoss   0.09\tAcc  96.88\tTime/batch 0.057\n",
      "Epoch: [140][ 149/1563]\tLoss   0.10\tAcc  96.71\tTime/batch 0.057\n",
      "Epoch: [140][ 199/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [140][ 249/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [140][ 299/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [140][ 349/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [140][ 399/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.057\n",
      "Epoch: [140][ 449/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [140][ 499/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [140][ 549/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [140][ 599/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [140][ 649/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [140][ 699/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [140][ 749/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [140][ 799/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [140][ 849/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [140][ 899/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [140][ 949/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [140][ 999/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [140][1049/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [140][1099/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [140][1149/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [140][1199/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [140][1249/1563]\tLoss   0.10\tAcc  96.37\tTime/batch 0.057\n",
      "Epoch: [140][1299/1563]\tLoss   0.10\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [140][1349/1563]\tLoss   0.10\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [140][1399/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [140][1449/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [140][1499/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [140][1549/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "epoch 140\n",
      "Accuracy of the network on the 10000 test images: 91.3 %\n",
      "Sparsity of the update phase: 69.6 %\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [141][  49/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.058\n",
      "Epoch: [141][  99/1563]\tLoss   0.09\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [141][ 149/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [141][ 199/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.057\n",
      "Epoch: [141][ 249/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [141][ 299/1563]\tLoss   0.10\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [141][ 349/1563]\tLoss   0.10\tAcc  96.68\tTime/batch 0.057\n",
      "Epoch: [141][ 399/1563]\tLoss   0.10\tAcc  96.60\tTime/batch 0.057\n",
      "Epoch: [141][ 449/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [141][ 499/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [141][ 549/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [141][ 599/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [141][ 649/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [141][ 699/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [141][ 749/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [141][ 799/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [141][ 849/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [141][ 899/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [141][ 949/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.057\n",
      "Epoch: [141][ 999/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [141][1049/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [141][1099/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [141][1149/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [141][1199/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [141][1249/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [141][1299/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [141][1349/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [141][1399/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [141][1449/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [141][1499/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [141][1549/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [142][  49/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.058\n",
      "Epoch: [142][  99/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.058\n",
      "Epoch: [142][ 149/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.058\n",
      "Epoch: [142][ 199/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.058\n",
      "Epoch: [142][ 249/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [142][ 299/1563]\tLoss   0.11\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [142][ 349/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [142][ 399/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [142][ 449/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [142][ 499/1563]\tLoss   0.10\tAcc  96.42\tTime/batch 0.057\n",
      "Epoch: [142][ 549/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [142][ 599/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [142][ 649/1563]\tLoss   0.10\tAcc  96.35\tTime/batch 0.057\n",
      "Epoch: [142][ 699/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [142][ 749/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [142][ 799/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [142][ 849/1563]\tLoss   0.10\tAcc  96.37\tTime/batch 0.057\n",
      "Epoch: [142][ 899/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [142][ 949/1563]\tLoss   0.10\tAcc  96.34\tTime/batch 0.057\n",
      "Epoch: [142][ 999/1563]\tLoss   0.11\tAcc  96.31\tTime/batch 0.057\n",
      "Epoch: [142][1049/1563]\tLoss   0.11\tAcc  96.30\tTime/batch 0.057\n",
      "Epoch: [142][1099/1563]\tLoss   0.10\tAcc  96.31\tTime/batch 0.057\n",
      "Epoch: [142][1149/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [142][1199/1563]\tLoss   0.10\tAcc  96.32\tTime/batch 0.057\n",
      "Epoch: [142][1249/1563]\tLoss   0.10\tAcc  96.36\tTime/batch 0.057\n",
      "Epoch: [142][1299/1563]\tLoss   0.10\tAcc  96.37\tTime/batch 0.057\n",
      "Epoch: [142][1349/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.057\n",
      "Epoch: [142][1399/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [142][1449/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [142][1499/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "Epoch: [142][1549/1563]\tLoss   0.10\tAcc  96.40\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [143][  49/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.058\n",
      "Epoch: [143][  99/1563]\tLoss   0.09\tAcc  96.69\tTime/batch 0.057\n",
      "Epoch: [143][ 149/1563]\tLoss   0.09\tAcc  96.65\tTime/batch 0.057\n",
      "Epoch: [143][ 199/1563]\tLoss   0.09\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [143][ 249/1563]\tLoss   0.09\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [143][ 299/1563]\tLoss   0.09\tAcc  96.78\tTime/batch 0.057\n",
      "Epoch: [143][ 349/1563]\tLoss   0.09\tAcc  96.71\tTime/batch 0.057\n",
      "Epoch: [143][ 399/1563]\tLoss   0.10\tAcc  96.68\tTime/batch 0.057\n",
      "Epoch: [143][ 449/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [143][ 499/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.057\n",
      "Epoch: [143][ 549/1563]\tLoss   0.10\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [143][ 599/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [143][ 649/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.057\n",
      "Epoch: [143][ 699/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [143][ 749/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [143][ 799/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [143][ 849/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [143][ 899/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [143][ 949/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [143][ 999/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [143][1049/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [143][1099/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [143][1149/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [143][1199/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "Epoch: [143][1249/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [143][1299/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.057\n",
      "Epoch: [143][1349/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [143][1399/1563]\tLoss   0.10\tAcc  96.41\tTime/batch 0.057\n",
      "Epoch: [143][1449/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [143][1499/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "Epoch: [143][1549/1563]\tLoss   0.10\tAcc  96.39\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [144][  49/1563]\tLoss   0.10\tAcc  96.69\tTime/batch 0.058\n",
      "Epoch: [144][  99/1563]\tLoss   0.10\tAcc  96.88\tTime/batch 0.058\n",
      "Epoch: [144][ 149/1563]\tLoss   0.10\tAcc  96.75\tTime/batch 0.058\n",
      "Epoch: [144][ 199/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.058\n",
      "Epoch: [144][ 249/1563]\tLoss   0.10\tAcc  96.65\tTime/batch 0.058\n",
      "Epoch: [144][ 299/1563]\tLoss   0.10\tAcc  96.68\tTime/batch 0.058\n",
      "Epoch: [144][ 349/1563]\tLoss   0.10\tAcc  96.70\tTime/batch 0.058\n",
      "Epoch: [144][ 399/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.057\n",
      "Epoch: [144][ 449/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [144][ 499/1563]\tLoss   0.10\tAcc  96.67\tTime/batch 0.057\n",
      "Epoch: [144][ 549/1563]\tLoss   0.10\tAcc  96.65\tTime/batch 0.057\n",
      "Epoch: [144][ 599/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.057\n",
      "Epoch: [144][ 649/1563]\tLoss   0.10\tAcc  96.65\tTime/batch 0.057\n",
      "Epoch: [144][ 699/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.057\n",
      "Epoch: [144][ 749/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.057\n",
      "Epoch: [144][ 799/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.057\n",
      "Epoch: [144][ 849/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.057\n",
      "Epoch: [144][ 899/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [144][ 949/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [144][ 999/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [144][1049/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [144][1099/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [144][1149/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [144][1199/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [144][1249/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [144][1299/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [144][1349/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [144][1399/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [144][1449/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [144][1499/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [144][1549/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [145][  49/1563]\tLoss   0.11\tAcc  95.75\tTime/batch 0.058\n",
      "Epoch: [145][  99/1563]\tLoss   0.10\tAcc  96.00\tTime/batch 0.057\n",
      "Epoch: [145][ 149/1563]\tLoss   0.10\tAcc  96.29\tTime/batch 0.057\n",
      "Epoch: [145][ 199/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.057\n",
      "Epoch: [145][ 249/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [145][ 299/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [145][ 349/1563]\tLoss   0.09\tAcc  96.68\tTime/batch 0.057\n",
      "Epoch: [145][ 399/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.057\n",
      "Epoch: [145][ 449/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.057\n",
      "Epoch: [145][ 499/1563]\tLoss   0.10\tAcc  96.65\tTime/batch 0.057\n",
      "Epoch: [145][ 549/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [145][ 599/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.057\n",
      "Epoch: [145][ 649/1563]\tLoss   0.10\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [145][ 699/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.057\n",
      "Epoch: [145][ 749/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [145][ 799/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.057\n",
      "Epoch: [145][ 849/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [145][ 899/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [145][ 949/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [145][ 999/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [145][1049/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [145][1099/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [145][1149/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [145][1199/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [145][1249/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [145][1299/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [145][1349/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [145][1399/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [145][1449/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [145][1499/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [145][1549/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [146][  49/1563]\tLoss   0.10\tAcc  95.88\tTime/batch 0.058\n",
      "Epoch: [146][  99/1563]\tLoss   0.09\tAcc  96.69\tTime/batch 0.057\n",
      "Epoch: [146][ 149/1563]\tLoss   0.09\tAcc  96.73\tTime/batch 0.057\n",
      "Epoch: [146][ 199/1563]\tLoss   0.09\tAcc  96.66\tTime/batch 0.057\n",
      "Epoch: [146][ 249/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [146][ 299/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [146][ 349/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [146][ 399/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [146][ 449/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [146][ 499/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [146][ 549/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [146][ 599/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [146][ 649/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [146][ 699/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [146][ 749/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [146][ 799/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [146][ 849/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [146][ 899/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [146][ 949/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [146][ 999/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [146][1049/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [146][1099/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [146][1149/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [146][1199/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [146][1249/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [146][1299/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [146][1349/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [146][1399/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.057\n",
      "Epoch: [146][1449/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "Epoch: [146][1499/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.057\n",
      "Epoch: [146][1549/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [147][  49/1563]\tLoss   0.10\tAcc  95.94\tTime/batch 0.057\n",
      "Epoch: [147][  99/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.056\n",
      "Epoch: [147][ 149/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.056\n",
      "Epoch: [147][ 199/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [147][ 249/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.056\n",
      "Epoch: [147][ 299/1563]\tLoss   0.09\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [147][ 349/1563]\tLoss   0.09\tAcc  96.60\tTime/batch 0.056\n",
      "Epoch: [147][ 399/1563]\tLoss   0.09\tAcc  96.58\tTime/batch 0.056\n",
      "Epoch: [147][ 449/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.056\n",
      "Epoch: [147][ 499/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.056\n",
      "Epoch: [147][ 549/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [147][ 599/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [147][ 649/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [147][ 699/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [147][ 749/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.056\n",
      "Epoch: [147][ 799/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [147][ 849/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.056\n",
      "Epoch: [147][ 899/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.056\n",
      "Epoch: [147][ 949/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.056\n",
      "Epoch: [147][ 999/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.056\n",
      "Epoch: [147][1049/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.056\n",
      "Epoch: [147][1099/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [147][1149/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.056\n",
      "Epoch: [147][1199/1563]\tLoss   0.10\tAcc  96.43\tTime/batch 0.056\n",
      "Epoch: [147][1249/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.056\n",
      "Epoch: [147][1299/1563]\tLoss   0.10\tAcc  96.47\tTime/batch 0.056\n",
      "Epoch: [147][1349/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.056\n",
      "Epoch: [147][1399/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [147][1449/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [147][1499/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [147][1549/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [148][  49/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [148][  99/1563]\tLoss   0.10\tAcc  96.69\tTime/batch 0.056\n",
      "Epoch: [148][ 149/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.056\n",
      "Epoch: [148][ 199/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.056\n",
      "Epoch: [148][ 249/1563]\tLoss   0.09\tAcc  96.67\tTime/batch 0.056\n",
      "Epoch: [148][ 299/1563]\tLoss   0.10\tAcc  96.64\tTime/batch 0.056\n",
      "Epoch: [148][ 349/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [148][ 399/1563]\tLoss   0.10\tAcc  96.38\tTime/batch 0.056\n",
      "Epoch: [148][ 449/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.056\n",
      "Epoch: [148][ 499/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.056\n",
      "Epoch: [148][ 549/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.056\n",
      "Epoch: [148][ 599/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.056\n",
      "Epoch: [148][ 649/1563]\tLoss   0.10\tAcc  96.44\tTime/batch 0.056\n",
      "Epoch: [148][ 699/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.056\n",
      "Epoch: [148][ 749/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.056\n",
      "Epoch: [148][ 799/1563]\tLoss   0.10\tAcc  96.45\tTime/batch 0.056\n",
      "Epoch: [148][ 849/1563]\tLoss   0.10\tAcc  96.48\tTime/batch 0.056\n",
      "Epoch: [148][ 899/1563]\tLoss   0.10\tAcc  96.46\tTime/batch 0.056\n",
      "Epoch: [148][ 949/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.056\n",
      "Epoch: [148][ 999/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.056\n",
      "Epoch: [148][1049/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [148][1099/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [148][1149/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.057\n",
      "Epoch: [148][1199/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [148][1249/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [148][1299/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.057\n",
      "Epoch: [148][1349/1563]\tLoss   0.10\tAcc  96.57\tTime/batch 0.057\n",
      "Epoch: [148][1399/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [148][1449/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [148][1499/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [148][1549/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [149][  49/1563]\tLoss   0.09\tAcc  96.88\tTime/batch 0.056\n",
      "Epoch: [149][  99/1563]\tLoss   0.09\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [149][ 149/1563]\tLoss   0.09\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [149][ 199/1563]\tLoss   0.09\tAcc  96.62\tTime/batch 0.057\n",
      "Epoch: [149][ 249/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.056\n",
      "Epoch: [149][ 299/1563]\tLoss   0.10\tAcc  96.59\tTime/batch 0.057\n",
      "Epoch: [149][ 349/1563]\tLoss   0.10\tAcc  96.58\tTime/batch 0.057\n",
      "Epoch: [149][ 399/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [149][ 449/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.056\n",
      "Epoch: [149][ 499/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [149][ 549/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [149][ 599/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [149][ 649/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.056\n",
      "Epoch: [149][ 699/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.056\n",
      "Epoch: [149][ 749/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.056\n",
      "Epoch: [149][ 799/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [149][ 849/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [149][ 899/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [149][ 949/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [149][ 999/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [149][1049/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [149][1099/1563]\tLoss   0.10\tAcc  96.52\tTime/batch 0.057\n",
      "Epoch: [149][1149/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.057\n",
      "Epoch: [149][1199/1563]\tLoss   0.10\tAcc  96.55\tTime/batch 0.057\n",
      "Epoch: [149][1249/1563]\tLoss   0.10\tAcc  96.56\tTime/batch 0.057\n",
      "Epoch: [149][1299/1563]\tLoss   0.10\tAcc  96.54\tTime/batch 0.056\n",
      "Epoch: [149][1349/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.056\n",
      "Epoch: [149][1399/1563]\tLoss   0.10\tAcc  96.49\tTime/batch 0.057\n",
      "Epoch: [149][1449/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [149][1499/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "Epoch: [149][1549/1563]\tLoss   0.10\tAcc  96.51\tTime/batch 0.057\n",
      "current learning rate = 0.0025000000000000005\n",
      "Epoch: [150][  49/1563]\tLoss   0.08\tAcc  97.00\tTime/batch 0.056\n",
      "Epoch: [150][  99/1563]\tLoss   0.08\tAcc  97.03\tTime/batch 0.056\n",
      "Epoch: [150][ 149/1563]\tLoss   0.09\tAcc  96.92\tTime/batch 0.056\n",
      "Epoch: [150][ 199/1563]\tLoss   0.09\tAcc  96.67\tTime/batch 0.056\n",
      "Epoch: [150][ 249/1563]\tLoss   0.09\tAcc  96.78\tTime/batch 0.055\n",
      "Epoch: [150][ 299/1563]\tLoss   0.09\tAcc  96.78\tTime/batch 0.055\n",
      "Epoch: [150][ 349/1563]\tLoss   0.09\tAcc  96.77\tTime/batch 0.056\n",
      "Epoch: [150][ 399/1563]\tLoss   0.09\tAcc  96.63\tTime/batch 0.056\n",
      "Epoch: [150][ 449/1563]\tLoss   0.09\tAcc  96.61\tTime/batch 0.056\n",
      "Epoch: [150][ 499/1563]\tLoss   0.09\tAcc  96.63\tTime/batch 0.056\n",
      "Epoch: [150][ 549/1563]\tLoss   0.09\tAcc  96.73\tTime/batch 0.055\n",
      "Epoch: [150][ 599/1563]\tLoss   0.09\tAcc  96.68\tTime/batch 0.055\n",
      "Epoch: [150][ 649/1563]\tLoss   0.09\tAcc  96.66\tTime/batch 0.055\n",
      "Epoch: [150][ 699/1563]\tLoss   0.09\tAcc  96.70\tTime/batch 0.055\n",
      "Epoch: [150][ 749/1563]\tLoss   0.09\tAcc  96.73\tTime/batch 0.055\n",
      "Epoch: [150][ 799/1563]\tLoss   0.09\tAcc  96.70\tTime/batch 0.055\n",
      "Epoch: [150][ 849/1563]\tLoss   0.09\tAcc  96.70\tTime/batch 0.055\n",
      "Epoch: [150][ 899/1563]\tLoss   0.09\tAcc  96.70\tTime/batch 0.055\n",
      "Epoch: [150][ 949/1563]\tLoss   0.09\tAcc  96.69\tTime/batch 0.055\n",
      "Epoch: [150][ 999/1563]\tLoss   0.09\tAcc  96.71\tTime/batch 0.055\n",
      "Epoch: [150][1049/1563]\tLoss   0.09\tAcc  96.70\tTime/batch 0.055\n",
      "Epoch: [150][1099/1563]\tLoss   0.09\tAcc  96.72\tTime/batch 0.055\n",
      "Epoch: [150][1149/1563]\tLoss   0.09\tAcc  96.69\tTime/batch 0.055\n",
      "Epoch: [150][1199/1563]\tLoss   0.09\tAcc  96.67\tTime/batch 0.055\n",
      "Epoch: [150][1249/1563]\tLoss   0.09\tAcc  96.66\tTime/batch 0.055\n",
      "Epoch: [150][1299/1563]\tLoss   0.09\tAcc  96.67\tTime/batch 0.055\n",
      "Epoch: [150][1349/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.055\n",
      "Epoch: [150][1399/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.055\n",
      "Epoch: [150][1449/1563]\tLoss   0.10\tAcc  96.63\tTime/batch 0.055\n",
      "Epoch: [150][1499/1563]\tLoss   0.10\tAcc  96.62\tTime/batch 0.055\n",
      "Epoch: [150][1549/1563]\tLoss   0.10\tAcc  96.61\tTime/batch 0.055\n",
      "epoch 150\n",
      "Accuracy of the network on the 10000 test images: 90.9 %\n",
      "Sparsity of the update phase: 69.8 %\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [151][  49/1563]\tLoss   0.09\tAcc  96.94\tTime/batch 0.057\n",
      "Epoch: [151][  99/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.057\n",
      "Epoch: [151][ 149/1563]\tLoss   0.09\tAcc  96.71\tTime/batch 0.057\n",
      "Epoch: [151][ 199/1563]\tLoss   0.09\tAcc  96.69\tTime/batch 0.056\n",
      "Epoch: [151][ 249/1563]\tLoss   0.09\tAcc  96.71\tTime/batch 0.056\n",
      "Epoch: [151][ 299/1563]\tLoss   0.09\tAcc  96.89\tTime/batch 0.056\n",
      "Epoch: [151][ 349/1563]\tLoss   0.09\tAcc  96.87\tTime/batch 0.056\n",
      "Epoch: [151][ 399/1563]\tLoss   0.09\tAcc  96.75\tTime/batch 0.056\n",
      "Epoch: [151][ 449/1563]\tLoss   0.09\tAcc  96.82\tTime/batch 0.056\n",
      "Epoch: [151][ 499/1563]\tLoss   0.09\tAcc  96.86\tTime/batch 0.056\n",
      "Epoch: [151][ 549/1563]\tLoss   0.09\tAcc  96.81\tTime/batch 0.056\n",
      "Epoch: [151][ 599/1563]\tLoss   0.09\tAcc  96.84\tTime/batch 0.056\n",
      "Epoch: [151][ 649/1563]\tLoss   0.09\tAcc  96.84\tTime/batch 0.056\n",
      "Epoch: [151][ 699/1563]\tLoss   0.09\tAcc  96.90\tTime/batch 0.056\n",
      "Epoch: [151][ 749/1563]\tLoss   0.09\tAcc  96.95\tTime/batch 0.056\n",
      "Epoch: [151][ 799/1563]\tLoss   0.09\tAcc  96.96\tTime/batch 0.056\n",
      "Epoch: [151][ 849/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.056\n",
      "Epoch: [151][ 899/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.056\n",
      "Epoch: [151][ 949/1563]\tLoss   0.09\tAcc  96.99\tTime/batch 0.056\n",
      "Epoch: [151][ 999/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.057\n",
      "Epoch: [151][1049/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.057\n",
      "Epoch: [151][1099/1563]\tLoss   0.09\tAcc  96.95\tTime/batch 0.057\n",
      "Epoch: [151][1149/1563]\tLoss   0.09\tAcc  96.96\tTime/batch 0.057\n",
      "Epoch: [151][1199/1563]\tLoss   0.09\tAcc  96.96\tTime/batch 0.057\n",
      "Epoch: [151][1249/1563]\tLoss   0.09\tAcc  96.93\tTime/batch 0.057\n",
      "Epoch: [151][1299/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.057\n",
      "Epoch: [151][1349/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.057\n",
      "Epoch: [151][1399/1563]\tLoss   0.09\tAcc  96.90\tTime/batch 0.057\n",
      "Epoch: [151][1449/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.057\n",
      "Epoch: [151][1499/1563]\tLoss   0.09\tAcc  96.90\tTime/batch 0.057\n",
      "Epoch: [151][1549/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [152][  49/1563]\tLoss   0.09\tAcc  96.75\tTime/batch 0.057\n",
      "Epoch: [152][  99/1563]\tLoss   0.10\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [152][ 149/1563]\tLoss   0.09\tAcc  96.79\tTime/batch 0.056\n",
      "Epoch: [152][ 199/1563]\tLoss   0.09\tAcc  96.75\tTime/batch 0.056\n",
      "Epoch: [152][ 249/1563]\tLoss   0.09\tAcc  96.85\tTime/batch 0.056\n",
      "Epoch: [152][ 299/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.056\n",
      "Epoch: [152][ 349/1563]\tLoss   0.09\tAcc  96.96\tTime/batch 0.056\n",
      "Epoch: [152][ 399/1563]\tLoss   0.09\tAcc  96.95\tTime/batch 0.056\n",
      "Epoch: [152][ 449/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.056\n",
      "Epoch: [152][ 499/1563]\tLoss   0.08\tAcc  97.09\tTime/batch 0.056\n",
      "Epoch: [152][ 549/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][ 599/1563]\tLoss   0.09\tAcc  97.03\tTime/batch 0.056\n",
      "Epoch: [152][ 649/1563]\tLoss   0.09\tAcc  96.97\tTime/batch 0.056\n",
      "Epoch: [152][ 699/1563]\tLoss   0.09\tAcc  96.98\tTime/batch 0.056\n",
      "Epoch: [152][ 749/1563]\tLoss   0.08\tAcc  97.03\tTime/batch 0.056\n",
      "Epoch: [152][ 799/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][ 849/1563]\tLoss   0.09\tAcc  97.00\tTime/batch 0.056\n",
      "Epoch: [152][ 899/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][ 949/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][ 999/1563]\tLoss   0.09\tAcc  97.04\tTime/batch 0.056\n",
      "Epoch: [152][1049/1563]\tLoss   0.09\tAcc  97.07\tTime/batch 0.056\n",
      "Epoch: [152][1099/1563]\tLoss   0.09\tAcc  97.08\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [152][1149/1563]\tLoss   0.09\tAcc  97.07\tTime/batch 0.056\n",
      "Epoch: [152][1199/1563]\tLoss   0.09\tAcc  97.05\tTime/batch 0.056\n",
      "Epoch: [152][1249/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][1299/1563]\tLoss   0.09\tAcc  97.00\tTime/batch 0.056\n",
      "Epoch: [152][1349/1563]\tLoss   0.09\tAcc  97.01\tTime/batch 0.056\n",
      "Epoch: [152][1399/1563]\tLoss   0.09\tAcc  97.00\tTime/batch 0.056\n",
      "Epoch: [152][1449/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][1499/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [152][1549/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [153][  49/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.058\n",
      "Epoch: [153][  99/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [153][ 149/1563]\tLoss   0.07\tAcc  97.73\tTime/batch 0.057\n",
      "Epoch: [153][ 199/1563]\tLoss   0.08\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [153][ 249/1563]\tLoss   0.08\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [153][ 299/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [153][ 349/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [153][ 399/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [153][ 449/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [153][ 499/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [153][ 549/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [153][ 599/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [153][ 649/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [153][ 699/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [153][ 749/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [153][ 799/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [153][ 849/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [153][ 899/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [153][ 949/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.057\n",
      "Epoch: [153][ 999/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.057\n",
      "Epoch: [153][1049/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [153][1099/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.057\n",
      "Epoch: [153][1149/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [153][1199/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [153][1249/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [153][1299/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.057\n",
      "Epoch: [153][1349/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.057\n",
      "Epoch: [153][1399/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.057\n",
      "Epoch: [153][1449/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.057\n",
      "Epoch: [153][1499/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.057\n",
      "Epoch: [153][1549/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [154][  49/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.058\n",
      "Epoch: [154][  99/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [154][ 149/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [154][ 199/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [154][ 249/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [154][ 299/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.058\n",
      "Epoch: [154][ 349/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.058\n",
      "Epoch: [154][ 399/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.058\n",
      "Epoch: [154][ 449/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.058\n",
      "Epoch: [154][ 499/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][ 549/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][ 599/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.058\n",
      "Epoch: [154][ 649/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.058\n",
      "Epoch: [154][ 699/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.058\n",
      "Epoch: [154][ 749/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "Epoch: [154][ 799/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][ 849/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.058\n",
      "Epoch: [154][ 899/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.058\n",
      "Epoch: [154][ 949/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "Epoch: [154][ 999/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "Epoch: [154][1049/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.058\n",
      "Epoch: [154][1099/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][1149/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][1199/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [154][1249/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.058\n",
      "Epoch: [154][1299/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.058\n",
      "Epoch: [154][1349/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [154][1399/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][1449/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [154][1499/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.058\n",
      "Epoch: [154][1549/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [155][  49/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [155][  99/1563]\tLoss   0.08\tAcc  96.81\tTime/batch 0.057\n",
      "Epoch: [155][ 149/1563]\tLoss   0.09\tAcc  96.83\tTime/batch 0.056\n",
      "Epoch: [155][ 199/1563]\tLoss   0.08\tAcc  97.00\tTime/batch 0.056\n",
      "Epoch: [155][ 249/1563]\tLoss   0.08\tAcc  97.05\tTime/batch 0.056\n",
      "Epoch: [155][ 299/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.056\n",
      "Epoch: [155][ 349/1563]\tLoss   0.09\tAcc  97.03\tTime/batch 0.056\n",
      "Epoch: [155][ 399/1563]\tLoss   0.09\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [155][ 449/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.056\n",
      "Epoch: [155][ 499/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.056\n",
      "Epoch: [155][ 549/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.056\n",
      "Epoch: [155][ 599/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.056\n",
      "Epoch: [155][ 649/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.056\n",
      "Epoch: [155][ 699/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.056\n",
      "Epoch: [155][ 749/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.056\n",
      "Epoch: [155][ 799/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.056\n",
      "Epoch: [155][ 849/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.056\n",
      "Epoch: [155][ 899/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.056\n",
      "Epoch: [155][ 949/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.056\n",
      "Epoch: [155][ 999/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.056\n",
      "Epoch: [155][1049/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.056\n",
      "Epoch: [155][1099/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.056\n",
      "Epoch: [155][1149/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.056\n",
      "Epoch: [155][1199/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.056\n",
      "Epoch: [155][1249/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.056\n",
      "Epoch: [155][1299/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.056\n",
      "Epoch: [155][1349/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.056\n",
      "Epoch: [155][1399/1563]\tLoss   0.08\tAcc  97.13\tTime/batch 0.056\n",
      "Epoch: [155][1449/1563]\tLoss   0.08\tAcc  97.13\tTime/batch 0.056\n",
      "Epoch: [155][1499/1563]\tLoss   0.08\tAcc  97.13\tTime/batch 0.056\n",
      "Epoch: [155][1549/1563]\tLoss   0.08\tAcc  97.13\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [156][  49/1563]\tLoss   0.08\tAcc  97.50\tTime/batch 0.058\n",
      "Epoch: [156][  99/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [156][ 149/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [156][ 199/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [156][ 249/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [156][ 299/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [156][ 349/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [156][ 399/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [156][ 449/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [156][ 499/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [156][ 549/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [156][ 599/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [156][ 649/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [156][ 699/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [156][ 749/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [156][ 799/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [156][ 849/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [156][ 899/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [156][ 949/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [156][ 999/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.057\n",
      "Epoch: [156][1049/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [156][1099/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [156][1149/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [156][1199/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [156][1249/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.056\n",
      "Epoch: [156][1299/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.056\n",
      "Epoch: [156][1349/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.056\n",
      "Epoch: [156][1399/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.056\n",
      "Epoch: [156][1449/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.056\n",
      "Epoch: [156][1499/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.056\n",
      "Epoch: [156][1549/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [157][  49/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.058\n",
      "Epoch: [157][  99/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [157][ 149/1563]\tLoss   0.08\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [157][ 199/1563]\tLoss   0.07\tAcc  97.72\tTime/batch 0.057\n",
      "Epoch: [157][ 249/1563]\tLoss   0.07\tAcc  97.64\tTime/batch 0.057\n",
      "Epoch: [157][ 299/1563]\tLoss   0.08\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [157][ 349/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [157][ 399/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [157][ 449/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [157][ 499/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [157][ 549/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [157][ 599/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [157][ 649/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [157][ 699/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [157][ 749/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [157][ 799/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [157][ 849/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [157][ 899/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [157][ 949/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [157][ 999/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [157][1049/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [157][1099/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [157][1149/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [157][1199/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [157][1249/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [157][1299/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [157][1349/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [157][1399/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [157][1449/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [157][1499/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [157][1549/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [158][  49/1563]\tLoss   0.09\tAcc  97.31\tTime/batch 0.058\n",
      "Epoch: [158][  99/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.058\n",
      "Epoch: [158][ 149/1563]\tLoss   0.09\tAcc  97.08\tTime/batch 0.058\n",
      "Epoch: [158][ 199/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.058\n",
      "Epoch: [158][ 249/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.058\n",
      "Epoch: [158][ 299/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.058\n",
      "Epoch: [158][ 349/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [158][ 399/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [158][ 449/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [158][ 499/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [158][ 549/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [158][ 599/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [158][ 649/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.057\n",
      "Epoch: [158][ 699/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [158][ 749/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [158][ 799/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [158][ 849/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [158][ 899/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [158][ 949/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [158][ 999/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.057\n",
      "Epoch: [158][1049/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [158][1099/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [158][1149/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [158][1199/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [158][1249/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [158][1299/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [158][1349/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [158][1399/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [158][1449/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [158][1499/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [158][1549/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [159][  49/1563]\tLoss   0.07\tAcc  97.88\tTime/batch 0.058\n",
      "Epoch: [159][  99/1563]\tLoss   0.08\tAcc  97.75\tTime/batch 0.057\n",
      "Epoch: [159][ 149/1563]\tLoss   0.08\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [159][ 199/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [159][ 249/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [159][ 299/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [159][ 349/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [159][ 399/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [159][ 449/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [159][ 499/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [159][ 549/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [159][ 599/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [159][ 649/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [159][ 699/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [159][ 749/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [159][ 799/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [159][ 849/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [159][ 899/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [159][ 949/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [159][ 999/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [159][1049/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.056\n",
      "Epoch: [159][1099/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [159][1149/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [159][1199/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [159][1249/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [159][1299/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [159][1349/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [159][1399/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [159][1449/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [159][1499/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [159][1549/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [160][  49/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [160][  99/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.056\n",
      "Epoch: [160][ 149/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.056\n",
      "Epoch: [160][ 199/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.056\n",
      "Epoch: [160][ 249/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [160][ 299/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.056\n",
      "Epoch: [160][ 349/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [160][ 399/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [160][ 449/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [160][ 499/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [160][ 549/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [160][ 599/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.056\n",
      "Epoch: [160][ 649/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [160][ 699/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [160][ 749/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [160][ 799/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [160][ 849/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [160][ 899/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [160][ 949/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [160][ 999/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [160][1049/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [160][1099/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [160][1149/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [160][1199/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [160][1249/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [160][1299/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [160][1349/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [160][1399/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [160][1449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [160][1499/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [160][1549/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "epoch 160\n",
      "Accuracy of the network on the 10000 test images: 91.2 %\n",
      "Sparsity of the update phase: 69.8 %\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [161][  49/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.058\n",
      "Epoch: [161][  99/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.058\n",
      "Epoch: [161][ 149/1563]\tLoss   0.08\tAcc  96.85\tTime/batch 0.058\n",
      "Epoch: [161][ 199/1563]\tLoss   0.08\tAcc  97.09\tTime/batch 0.058\n",
      "Epoch: [161][ 249/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.058\n",
      "Epoch: [161][ 299/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [161][ 349/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.058\n",
      "Epoch: [161][ 399/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.058\n",
      "Epoch: [161][ 449/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.058\n",
      "Epoch: [161][ 499/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.058\n",
      "Epoch: [161][ 549/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [161][ 599/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.058\n",
      "Epoch: [161][ 649/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.058\n",
      "Epoch: [161][ 699/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.058\n",
      "Epoch: [161][ 749/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.058\n",
      "Epoch: [161][ 799/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.058\n",
      "Epoch: [161][ 849/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.058\n",
      "Epoch: [161][ 899/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.058\n",
      "Epoch: [161][ 949/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.058\n",
      "Epoch: [161][ 999/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "Epoch: [161][1049/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.058\n",
      "Epoch: [161][1099/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.058\n",
      "Epoch: [161][1149/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.058\n",
      "Epoch: [161][1199/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.058\n",
      "Epoch: [161][1249/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.058\n",
      "Epoch: [161][1299/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.058\n",
      "Epoch: [161][1349/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "Epoch: [161][1399/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.058\n",
      "Epoch: [161][1449/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [161][1499/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [161][1549/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.058\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [162][  49/1563]\tLoss   0.08\tAcc  97.56\tTime/batch 0.058\n",
      "Epoch: [162][  99/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [162][ 149/1563]\tLoss   0.08\tAcc  96.98\tTime/batch 0.057\n",
      "Epoch: [162][ 199/1563]\tLoss   0.08\tAcc  97.03\tTime/batch 0.056\n",
      "Epoch: [162][ 249/1563]\tLoss   0.08\tAcc  97.04\tTime/batch 0.056\n",
      "Epoch: [162][ 299/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.056\n",
      "Epoch: [162][ 349/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.056\n",
      "Epoch: [162][ 399/1563]\tLoss   0.08\tAcc  97.14\tTime/batch 0.056\n",
      "Epoch: [162][ 449/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.056\n",
      "Epoch: [162][ 499/1563]\tLoss   0.08\tAcc  97.03\tTime/batch 0.056\n",
      "Epoch: [162][ 549/1563]\tLoss   0.08\tAcc  97.06\tTime/batch 0.056\n",
      "Epoch: [162][ 599/1563]\tLoss   0.08\tAcc  97.07\tTime/batch 0.056\n",
      "Epoch: [162][ 649/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.056\n",
      "Epoch: [162][ 699/1563]\tLoss   0.08\tAcc  97.09\tTime/batch 0.056\n",
      "Epoch: [162][ 749/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.056\n",
      "Epoch: [162][ 799/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.057\n",
      "Epoch: [162][ 849/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "Epoch: [162][ 899/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "Epoch: [162][ 949/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "Epoch: [162][ 999/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "Epoch: [162][1049/1563]\tLoss   0.08\tAcc  97.09\tTime/batch 0.057\n",
      "Epoch: [162][1099/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.057\n",
      "Epoch: [162][1149/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.057\n",
      "Epoch: [162][1199/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "Epoch: [162][1249/1563]\tLoss   0.08\tAcc  97.10\tTime/batch 0.057\n",
      "Epoch: [162][1299/1563]\tLoss   0.08\tAcc  97.09\tTime/batch 0.057\n",
      "Epoch: [162][1349/1563]\tLoss   0.08\tAcc  97.07\tTime/batch 0.057\n",
      "Epoch: [162][1399/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.057\n",
      "Epoch: [162][1449/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.057\n",
      "Epoch: [162][1499/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [162][1549/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [163][  49/1563]\tLoss   0.08\tAcc  97.75\tTime/batch 0.057\n",
      "Epoch: [163][  99/1563]\tLoss   0.09\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [163][ 149/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [163][ 199/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [163][ 249/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [163][ 299/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.056\n",
      "Epoch: [163][ 349/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [163][ 399/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [163][ 449/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [163][ 499/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [163][ 549/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [163][ 599/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.056\n",
      "Epoch: [163][ 649/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.056\n",
      "Epoch: [163][ 699/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [163][ 749/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [163][ 799/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [163][ 849/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [163][ 899/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [163][ 949/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [163][ 999/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [163][1049/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [163][1099/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [163][1149/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [163][1199/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [163][1249/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [163][1299/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [163][1349/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [163][1399/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [163][1449/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [163][1499/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [163][1549/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [164][  49/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.058\n",
      "Epoch: [164][  99/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [164][ 149/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [164][ 199/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [164][ 249/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [164][ 299/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [164][ 349/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [164][ 399/1563]\tLoss   0.08\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [164][ 449/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [164][ 499/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [164][ 549/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [164][ 599/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [164][ 649/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [164][ 699/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [164][ 749/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [164][ 799/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [164][ 849/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [164][ 899/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [164][ 949/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [164][ 999/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [164][1049/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [164][1099/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [164][1149/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [164][1199/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [164][1249/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [164][1299/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [164][1349/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [164][1399/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [164][1449/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [164][1499/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [164][1549/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [165][  49/1563]\tLoss   0.06\tAcc  98.19\tTime/batch 0.057\n",
      "Epoch: [165][  99/1563]\tLoss   0.07\tAcc  97.97\tTime/batch 0.057\n",
      "Epoch: [165][ 149/1563]\tLoss   0.07\tAcc  97.94\tTime/batch 0.057\n",
      "Epoch: [165][ 199/1563]\tLoss   0.07\tAcc  97.91\tTime/batch 0.057\n",
      "Epoch: [165][ 249/1563]\tLoss   0.07\tAcc  97.75\tTime/batch 0.057\n",
      "Epoch: [165][ 299/1563]\tLoss   0.08\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [165][ 349/1563]\tLoss   0.08\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [165][ 399/1563]\tLoss   0.08\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [165][ 449/1563]\tLoss   0.08\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [165][ 499/1563]\tLoss   0.08\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [165][ 549/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [165][ 599/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [165][ 649/1563]\tLoss   0.08\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [165][ 699/1563]\tLoss   0.08\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [165][ 749/1563]\tLoss   0.08\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [165][ 799/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [165][ 849/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [165][ 899/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [165][ 949/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [165][ 999/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [165][1049/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [165][1099/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [165][1149/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [165][1199/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [165][1249/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [165][1299/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [165][1349/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [165][1399/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [165][1449/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [165][1499/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [165][1549/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [166][  49/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [166][  99/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [166][ 149/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [166][ 199/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [166][ 249/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [166][ 299/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.057\n",
      "Epoch: [166][ 349/1563]\tLoss   0.08\tAcc  97.20\tTime/batch 0.056\n",
      "Epoch: [166][ 399/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.056\n",
      "Epoch: [166][ 449/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.056\n",
      "Epoch: [166][ 499/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.056\n",
      "Epoch: [166][ 549/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [166][ 599/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [166][ 649/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [166][ 699/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [166][ 749/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [166][ 799/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [166][ 849/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [166][ 899/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [166][ 949/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [166][ 999/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [166][1049/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [166][1099/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [166][1149/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [166][1199/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [166][1249/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [166][1299/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [166][1349/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [166][1399/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [166][1449/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [166][1499/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [166][1549/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [167][  49/1563]\tLoss   0.09\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [167][  99/1563]\tLoss   0.08\tAcc  97.69\tTime/batch 0.056\n",
      "Epoch: [167][ 149/1563]\tLoss   0.08\tAcc  97.69\tTime/batch 0.056\n",
      "Epoch: [167][ 199/1563]\tLoss   0.08\tAcc  97.61\tTime/batch 0.056\n",
      "Epoch: [167][ 249/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.056\n",
      "Epoch: [167][ 299/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [167][ 349/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.056\n",
      "Epoch: [167][ 399/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [167][ 449/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [167][ 499/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [167][ 549/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [167][ 599/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [167][ 649/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [167][ 699/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [167][ 749/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [167][ 799/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.056\n",
      "Epoch: [167][ 849/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.056\n",
      "Epoch: [167][ 899/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [167][ 949/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [167][ 999/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.056\n",
      "Epoch: [167][1049/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [167][1099/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [167][1149/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [167][1199/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [167][1249/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [167][1299/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [167][1349/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [167][1399/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [167][1449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [167][1499/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [167][1549/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [168][  49/1563]\tLoss   0.08\tAcc  96.88\tTime/batch 0.058\n",
      "Epoch: [168][  99/1563]\tLoss   0.07\tAcc  97.19\tTime/batch 0.058\n",
      "Epoch: [168][ 149/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.058\n",
      "Epoch: [168][ 199/1563]\tLoss   0.08\tAcc  96.95\tTime/batch 0.058\n",
      "Epoch: [168][ 249/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.058\n",
      "Epoch: [168][ 299/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.058\n",
      "Epoch: [168][ 349/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [168][ 399/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [168][ 449/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [168][ 499/1563]\tLoss   0.08\tAcc  97.21\tTime/batch 0.057\n",
      "Epoch: [168][ 549/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [168][ 599/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [168][ 649/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [168][ 699/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [168][ 749/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [168][ 799/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [168][ 849/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [168][ 899/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [168][ 949/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [168][ 999/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [168][1049/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [168][1099/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [168][1149/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [168][1199/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [168][1249/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [168][1299/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [168][1349/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [168][1399/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [168][1449/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [168][1499/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [168][1549/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [169][  49/1563]\tLoss   0.09\tAcc  96.94\tTime/batch 0.057\n",
      "Epoch: [169][  99/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [169][ 149/1563]\tLoss   0.08\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [169][ 199/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [169][ 249/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [169][ 299/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [169][ 349/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [169][ 399/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [169][ 449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [169][ 499/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [169][ 549/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [169][ 599/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [169][ 649/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [169][ 699/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [169][ 749/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [169][ 799/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [169][ 849/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [169][ 899/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [169][ 949/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [169][ 999/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [169][1049/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [169][1099/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [169][1149/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [169][1199/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [169][1249/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [169][1299/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [169][1349/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [169][1399/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [169][1449/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [169][1499/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [169][1549/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [170][  49/1563]\tLoss   0.08\tAcc  97.50\tTime/batch 0.058\n",
      "Epoch: [170][  99/1563]\tLoss   0.07\tAcc  97.72\tTime/batch 0.057\n",
      "Epoch: [170][ 149/1563]\tLoss   0.07\tAcc  97.73\tTime/batch 0.057\n",
      "Epoch: [170][ 199/1563]\tLoss   0.07\tAcc  97.64\tTime/batch 0.057\n",
      "Epoch: [170][ 249/1563]\tLoss   0.07\tAcc  97.61\tTime/batch 0.057\n",
      "Epoch: [170][ 299/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [170][ 349/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [170][ 399/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [170][ 449/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [170][ 499/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [170][ 549/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [170][ 599/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [170][ 649/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [170][ 699/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [170][ 749/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [170][ 799/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [170][ 849/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [170][ 899/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.056\n",
      "Epoch: [170][ 949/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.056\n",
      "Epoch: [170][ 999/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.056\n",
      "Epoch: [170][1049/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.056\n",
      "Epoch: [170][1099/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.056\n",
      "Epoch: [170][1149/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.056\n",
      "Epoch: [170][1199/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [170][1249/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [170][1299/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [170][1349/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [170][1399/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [170][1449/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [170][1499/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [170][1549/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "epoch 170\n",
      "Accuracy of the network on the 10000 test images: 91.4 %\n",
      "Sparsity of the update phase: 69.8 %\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [171][  49/1563]\tLoss   0.08\tAcc  97.06\tTime/batch 0.058\n",
      "Epoch: [171][  99/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.057\n",
      "Epoch: [171][ 149/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [171][ 199/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [171][ 249/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [171][ 299/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [171][ 349/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [171][ 399/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [171][ 449/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [171][ 499/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [171][ 549/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [171][ 599/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [171][ 649/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [171][ 699/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [171][ 749/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [171][ 799/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [171][ 849/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [171][ 899/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [171][ 949/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [171][ 999/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [171][1049/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [171][1099/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [171][1149/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [171][1199/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [171][1249/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [171][1299/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [171][1349/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [171][1399/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [171][1449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [171][1499/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [171][1549/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [172][  49/1563]\tLoss   0.08\tAcc  97.00\tTime/batch 0.057\n",
      "Epoch: [172][  99/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [172][ 149/1563]\tLoss   0.07\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [172][ 199/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [172][ 249/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [172][ 299/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [172][ 349/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [172][ 399/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [172][ 449/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [172][ 499/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [172][ 549/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [172][ 599/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [172][ 649/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [172][ 699/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [172][ 749/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [172][ 799/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [172][ 849/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [172][ 899/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [172][ 949/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [172][ 999/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [172][1049/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [172][1099/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [172][1149/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [172][1199/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [172][1249/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [172][1299/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [172][1349/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [172][1399/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [172][1449/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [172][1499/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [172][1549/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [173][  49/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.058\n",
      "Epoch: [173][  99/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [173][ 149/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.056\n",
      "Epoch: [173][ 199/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.056\n",
      "Epoch: [173][ 249/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.056\n",
      "Epoch: [173][ 299/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [173][ 349/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [173][ 399/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.056\n",
      "Epoch: [173][ 449/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [173][ 499/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [173][ 549/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [173][ 599/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [173][ 649/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [173][ 699/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [173][ 749/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [173][ 799/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [173][ 849/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [173][ 899/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [173][ 949/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [173][ 999/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [173][1049/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [173][1099/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [173][1149/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [173][1199/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [173][1249/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [173][1299/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [173][1349/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [173][1399/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [173][1449/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [173][1499/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [173][1549/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [174][  49/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [174][  99/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [174][ 149/1563]\tLoss   0.07\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [174][ 199/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [174][ 249/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [174][ 299/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [174][ 349/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [174][ 399/1563]\tLoss   0.07\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [174][ 449/1563]\tLoss   0.07\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [174][ 499/1563]\tLoss   0.07\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [174][ 549/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [174][ 599/1563]\tLoss   0.07\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [174][ 649/1563]\tLoss   0.07\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [174][ 699/1563]\tLoss   0.07\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [174][ 749/1563]\tLoss   0.07\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [174][ 799/1563]\tLoss   0.07\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [174][ 849/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [174][ 899/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [174][ 949/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [174][ 999/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [174][1049/1563]\tLoss   0.07\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [174][1099/1563]\tLoss   0.07\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [174][1149/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [174][1199/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [174][1249/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [174][1299/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [174][1349/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [174][1399/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [174][1449/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [174][1499/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [174][1549/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [175][  49/1563]\tLoss   0.10\tAcc  96.50\tTime/batch 0.057\n",
      "Epoch: [175][  99/1563]\tLoss   0.09\tAcc  96.53\tTime/batch 0.057\n",
      "Epoch: [175][ 149/1563]\tLoss   0.08\tAcc  96.96\tTime/batch 0.056\n",
      "Epoch: [175][ 199/1563]\tLoss   0.09\tAcc  96.77\tTime/batch 0.056\n",
      "Epoch: [175][ 249/1563]\tLoss   0.09\tAcc  96.83\tTime/batch 0.056\n",
      "Epoch: [175][ 299/1563]\tLoss   0.09\tAcc  96.91\tTime/batch 0.056\n",
      "Epoch: [175][ 349/1563]\tLoss   0.08\tAcc  96.96\tTime/batch 0.056\n",
      "Epoch: [175][ 399/1563]\tLoss   0.08\tAcc  96.89\tTime/batch 0.056\n",
      "Epoch: [175][ 449/1563]\tLoss   0.08\tAcc  96.92\tTime/batch 0.056\n",
      "Epoch: [175][ 499/1563]\tLoss   0.08\tAcc  96.97\tTime/batch 0.056\n",
      "Epoch: [175][ 549/1563]\tLoss   0.08\tAcc  96.98\tTime/batch 0.056\n",
      "Epoch: [175][ 599/1563]\tLoss   0.08\tAcc  97.05\tTime/batch 0.057\n",
      "Epoch: [175][ 649/1563]\tLoss   0.08\tAcc  97.11\tTime/batch 0.057\n",
      "Epoch: [175][ 699/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [175][ 749/1563]\tLoss   0.08\tAcc  97.13\tTime/batch 0.057\n",
      "Epoch: [175][ 799/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [175][ 849/1563]\tLoss   0.08\tAcc  97.13\tTime/batch 0.057\n",
      "Epoch: [175][ 899/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [175][ 949/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.057\n",
      "Epoch: [175][ 999/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [175][1049/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [175][1099/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [175][1149/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [175][1199/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [175][1249/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [175][1299/1563]\tLoss   0.08\tAcc  97.18\tTime/batch 0.057\n",
      "Epoch: [175][1349/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [175][1399/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [175][1449/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [175][1499/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [175][1549/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [176][  49/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [176][  99/1563]\tLoss   0.09\tAcc  96.84\tTime/batch 0.057\n",
      "Epoch: [176][ 149/1563]\tLoss   0.08\tAcc  97.02\tTime/batch 0.056\n",
      "Epoch: [176][ 199/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.056\n",
      "Epoch: [176][ 249/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.056\n",
      "Epoch: [176][ 299/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.056\n",
      "Epoch: [176][ 349/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.056\n",
      "Epoch: [176][ 399/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [176][ 449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [176][ 499/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [176][ 549/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [176][ 599/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [176][ 649/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [176][ 699/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [176][ 749/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [176][ 799/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [176][ 849/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [176][ 899/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [176][ 949/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [176][ 999/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [176][1049/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [176][1099/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [176][1149/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [176][1199/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [176][1249/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [176][1299/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [176][1349/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [176][1399/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [176][1449/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [176][1499/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [176][1549/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [177][  49/1563]\tLoss   0.08\tAcc  97.12\tTime/batch 0.057\n",
      "Epoch: [177][  99/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [177][ 149/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [177][ 199/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [177][ 249/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [177][ 299/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [177][ 349/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [177][ 399/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [177][ 449/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [177][ 499/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [177][ 549/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [177][ 599/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [177][ 649/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [177][ 699/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [177][ 749/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [177][ 799/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [177][ 849/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [177][ 899/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [177][ 949/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [177][ 999/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [177][1049/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [177][1099/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [177][1149/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [177][1199/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [177][1249/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [177][1299/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [177][1349/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [177][1399/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [177][1449/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [177][1499/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [177][1549/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [178][  49/1563]\tLoss   0.09\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [178][  99/1563]\tLoss   0.08\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [178][ 149/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [178][ 199/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [178][ 249/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [178][ 299/1563]\tLoss   0.08\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [178][ 349/1563]\tLoss   0.08\tAcc  97.54\tTime/batch 0.056\n",
      "Epoch: [178][ 399/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [178][ 449/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.056\n",
      "Epoch: [178][ 499/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [178][ 549/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [178][ 599/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [178][ 649/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [178][ 699/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [178][ 749/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [178][ 799/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [178][ 849/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [178][ 899/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [178][ 949/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [178][ 999/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [178][1049/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [178][1099/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [178][1149/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [178][1199/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [178][1249/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [178][1299/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [178][1349/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [178][1399/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [178][1449/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [178][1499/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [178][1549/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [179][  49/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [179][  99/1563]\tLoss   0.08\tAcc  97.03\tTime/batch 0.057\n",
      "Epoch: [179][ 149/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.056\n",
      "Epoch: [179][ 199/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.056\n",
      "Epoch: [179][ 249/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [179][ 299/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [179][ 349/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.056\n",
      "Epoch: [179][ 399/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [179][ 449/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [179][ 499/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [179][ 549/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [179][ 599/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [179][ 649/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.056\n",
      "Epoch: [179][ 699/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [179][ 749/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [179][ 799/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [179][ 849/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.056\n",
      "Epoch: [179][ 899/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [179][ 949/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [179][ 999/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [179][1049/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [179][1099/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [179][1149/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [179][1199/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [179][1249/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.056\n",
      "Epoch: [179][1299/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.056\n",
      "Epoch: [179][1349/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [179][1399/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.056\n",
      "Epoch: [179][1449/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [179][1499/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [179][1549/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [180][  49/1563]\tLoss   0.08\tAcc  96.88\tTime/batch 0.057\n",
      "Epoch: [180][  99/1563]\tLoss   0.09\tAcc  96.88\tTime/batch 0.057\n",
      "Epoch: [180][ 149/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [180][ 199/1563]\tLoss   0.08\tAcc  97.06\tTime/batch 0.057\n",
      "Epoch: [180][ 249/1563]\tLoss   0.08\tAcc  96.95\tTime/batch 0.057\n",
      "Epoch: [180][ 299/1563]\tLoss   0.08\tAcc  97.07\tTime/batch 0.057\n",
      "Epoch: [180][ 349/1563]\tLoss   0.08\tAcc  97.09\tTime/batch 0.057\n",
      "Epoch: [180][ 399/1563]\tLoss   0.08\tAcc  97.15\tTime/batch 0.057\n",
      "Epoch: [180][ 449/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.056\n",
      "Epoch: [180][ 499/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [180][ 549/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.056\n",
      "Epoch: [180][ 599/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.056\n",
      "Epoch: [180][ 649/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [180][ 699/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [180][ 749/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.056\n",
      "Epoch: [180][ 799/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [180][ 849/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [180][ 899/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [180][ 949/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [180][ 999/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.056\n",
      "Epoch: [180][1049/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [180][1099/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [180][1149/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [180][1199/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [180][1249/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [180][1299/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.056\n",
      "Epoch: [180][1349/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.056\n",
      "Epoch: [180][1399/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [180][1449/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [180][1499/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [180][1549/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.056\n",
      "epoch 180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 91.0 %\n",
      "Sparsity of the update phase: 70.0 %\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [181][  49/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [181][  99/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [181][ 149/1563]\tLoss   0.08\tAcc  97.23\tTime/batch 0.057\n",
      "Epoch: [181][ 199/1563]\tLoss   0.07\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [181][ 249/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [181][ 299/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [181][ 349/1563]\tLoss   0.08\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [181][ 399/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [181][ 449/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [181][ 499/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [181][ 549/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [181][ 599/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [181][ 649/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [181][ 699/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [181][ 749/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [181][ 799/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [181][ 849/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [181][ 899/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [181][ 949/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [181][ 999/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [181][1049/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [181][1099/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [181][1149/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [181][1199/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [181][1249/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [181][1299/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [181][1349/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [181][1399/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [181][1449/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [181][1499/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [181][1549/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [182][  49/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [182][  99/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [182][ 149/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.056\n",
      "Epoch: [182][ 199/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [182][ 249/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.056\n",
      "Epoch: [182][ 299/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.056\n",
      "Epoch: [182][ 349/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.056\n",
      "Epoch: [182][ 399/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.056\n",
      "Epoch: [182][ 449/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.056\n",
      "Epoch: [182][ 499/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [182][ 549/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [182][ 599/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [182][ 649/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [182][ 699/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [182][ 749/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [182][ 799/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [182][ 849/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [182][ 899/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [182][ 949/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [182][ 999/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [182][1049/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [182][1099/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [182][1149/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [182][1199/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [182][1249/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [182][1299/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [182][1349/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [182][1399/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [182][1449/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.056\n",
      "Epoch: [182][1499/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [182][1549/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [183][  49/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [183][  99/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.057\n",
      "Epoch: [183][ 149/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [183][ 199/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.056\n",
      "Epoch: [183][ 249/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.056\n",
      "Epoch: [183][ 299/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.056\n",
      "Epoch: [183][ 349/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [183][ 399/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [183][ 449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [183][ 499/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [183][ 549/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [183][ 599/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [183][ 649/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [183][ 699/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [183][ 749/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [183][ 799/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [183][ 849/1563]\tLoss   0.07\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [183][ 899/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [183][ 949/1563]\tLoss   0.07\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [183][ 999/1563]\tLoss   0.07\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [183][1049/1563]\tLoss   0.07\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [183][1099/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [183][1149/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [183][1199/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [183][1249/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [183][1299/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [183][1349/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [183][1399/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [183][1449/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [183][1499/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [183][1549/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [184][  49/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.058\n",
      "Epoch: [184][  99/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.057\n",
      "Epoch: [184][ 149/1563]\tLoss   0.07\tAcc  97.67\tTime/batch 0.057\n",
      "Epoch: [184][ 199/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.057\n",
      "Epoch: [184][ 249/1563]\tLoss   0.07\tAcc  97.64\tTime/batch 0.057\n",
      "Epoch: [184][ 299/1563]\tLoss   0.07\tAcc  97.68\tTime/batch 0.057\n",
      "Epoch: [184][ 349/1563]\tLoss   0.07\tAcc  97.79\tTime/batch 0.057\n",
      "Epoch: [184][ 399/1563]\tLoss   0.07\tAcc  97.71\tTime/batch 0.057\n",
      "Epoch: [184][ 449/1563]\tLoss   0.07\tAcc  97.68\tTime/batch 0.057\n",
      "Epoch: [184][ 499/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.057\n",
      "Epoch: [184][ 549/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [184][ 599/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [184][ 649/1563]\tLoss   0.07\tAcc  97.61\tTime/batch 0.057\n",
      "Epoch: [184][ 699/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [184][ 749/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [184][ 799/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [184][ 849/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [184][ 899/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [184][ 949/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [184][ 999/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [184][1049/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [184][1099/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [184][1149/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [184][1199/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [184][1249/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [184][1299/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [184][1349/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [184][1399/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [184][1449/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [184][1499/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [184][1549/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [185][  49/1563]\tLoss   0.08\tAcc  97.62\tTime/batch 0.058\n",
      "Epoch: [185][  99/1563]\tLoss   0.07\tAcc  97.69\tTime/batch 0.058\n",
      "Epoch: [185][ 149/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.058\n",
      "Epoch: [185][ 199/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [185][ 249/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [185][ 299/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [185][ 349/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [185][ 399/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [185][ 449/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [185][ 499/1563]\tLoss   0.07\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [185][ 549/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [185][ 599/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [185][ 649/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [185][ 699/1563]\tLoss   0.07\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [185][ 749/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [185][ 799/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [185][ 849/1563]\tLoss   0.07\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [185][ 899/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [185][ 949/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [185][ 999/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [185][1049/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [185][1099/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [185][1149/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [185][1199/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [185][1249/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [185][1299/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [185][1349/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [185][1399/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [185][1449/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [185][1499/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [185][1549/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [186][  49/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [186][  99/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.056\n",
      "Epoch: [186][ 149/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.056\n",
      "Epoch: [186][ 199/1563]\tLoss   0.07\tAcc  97.64\tTime/batch 0.056\n",
      "Epoch: [186][ 249/1563]\tLoss   0.07\tAcc  97.64\tTime/batch 0.056\n",
      "Epoch: [186][ 299/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [186][ 349/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [186][ 399/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.056\n",
      "Epoch: [186][ 449/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [186][ 499/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.056\n",
      "Epoch: [186][ 549/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.056\n",
      "Epoch: [186][ 599/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [186][ 649/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [186][ 699/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.056\n",
      "Epoch: [186][ 749/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.056\n",
      "Epoch: [186][ 799/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [186][ 849/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [186][ 899/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [186][ 949/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [186][ 999/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [186][1049/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [186][1099/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [186][1149/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [186][1199/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [186][1249/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [186][1299/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [186][1349/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [186][1399/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [186][1449/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [186][1499/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [186][1549/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [187][  49/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [187][  99/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "Epoch: [187][ 149/1563]\tLoss   0.07\tAcc  97.73\tTime/batch 0.056\n",
      "Epoch: [187][ 199/1563]\tLoss   0.07\tAcc  97.67\tTime/batch 0.056\n",
      "Epoch: [187][ 249/1563]\tLoss   0.07\tAcc  97.69\tTime/batch 0.056\n",
      "Epoch: [187][ 299/1563]\tLoss   0.07\tAcc  97.65\tTime/batch 0.056\n",
      "Epoch: [187][ 349/1563]\tLoss   0.07\tAcc  97.67\tTime/batch 0.056\n",
      "Epoch: [187][ 399/1563]\tLoss   0.07\tAcc  97.65\tTime/batch 0.056\n",
      "Epoch: [187][ 449/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.056\n",
      "Epoch: [187][ 499/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.056\n",
      "Epoch: [187][ 549/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [187][ 599/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.056\n",
      "Epoch: [187][ 649/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.056\n",
      "Epoch: [187][ 699/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.056\n",
      "Epoch: [187][ 749/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [187][ 799/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.056\n",
      "Epoch: [187][ 849/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.056\n",
      "Epoch: [187][ 899/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [187][ 949/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [187][ 999/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.056\n",
      "Epoch: [187][1049/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.056\n",
      "Epoch: [187][1099/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.056\n",
      "Epoch: [187][1149/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [187][1199/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [187][1249/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.056\n",
      "Epoch: [187][1299/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [187][1349/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [187][1399/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [187][1449/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [187][1499/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.056\n",
      "Epoch: [187][1549/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [188][  49/1563]\tLoss   0.09\tAcc  96.88\tTime/batch 0.057\n",
      "Epoch: [188][  99/1563]\tLoss   0.09\tAcc  96.94\tTime/batch 0.057\n",
      "Epoch: [188][ 149/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [188][ 199/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [188][ 249/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [188][ 299/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][ 349/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [188][ 399/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [188][ 449/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [188][ 499/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][ 549/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][ 599/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [188][ 649/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][ 699/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][ 749/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [188][ 799/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][ 849/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][ 899/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][ 949/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][ 999/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [188][1049/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][1099/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][1149/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [188][1199/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [188][1249/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][1299/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [188][1349/1563]\tLoss   0.08\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [188][1399/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [188][1449/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [188][1499/1563]\tLoss   0.08\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [188][1549/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [189][  49/1563]\tLoss   0.08\tAcc  97.06\tTime/batch 0.058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [189][  99/1563]\tLoss   0.08\tAcc  97.16\tTime/batch 0.058\n",
      "Epoch: [189][ 149/1563]\tLoss   0.08\tAcc  97.02\tTime/batch 0.058\n",
      "Epoch: [189][ 199/1563]\tLoss   0.08\tAcc  97.08\tTime/batch 0.058\n",
      "Epoch: [189][ 249/1563]\tLoss   0.08\tAcc  97.17\tTime/batch 0.057\n",
      "Epoch: [189][ 299/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [189][ 349/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [189][ 399/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [189][ 449/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [189][ 499/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [189][ 549/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [189][ 599/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [189][ 649/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [189][ 699/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [189][ 749/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [189][ 799/1563]\tLoss   0.08\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [189][ 849/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [189][ 899/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [189][ 949/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [189][ 999/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [189][1049/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [189][1099/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [189][1149/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [189][1199/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [189][1249/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [189][1299/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [189][1349/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [189][1399/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [189][1449/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [189][1499/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [189][1549/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [190][  49/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.058\n",
      "Epoch: [190][  99/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [190][ 149/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [190][ 199/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [190][ 249/1563]\tLoss   0.08\tAcc  97.22\tTime/batch 0.057\n",
      "Epoch: [190][ 299/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [190][ 349/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [190][ 399/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [190][ 449/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [190][ 499/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [190][ 549/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [190][ 599/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [190][ 649/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [190][ 699/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [190][ 749/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [190][ 799/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [190][ 849/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.057\n",
      "Epoch: [190][ 899/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [190][ 949/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [190][ 999/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [190][1049/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [190][1099/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [190][1149/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [190][1199/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [190][1249/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [190][1299/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [190][1349/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [190][1399/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [190][1449/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.057\n",
      "Epoch: [190][1499/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [190][1549/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "epoch 190\n",
      "Accuracy of the network on the 10000 test images: 91.2 %\n",
      "Sparsity of the update phase: 70.1 %\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [191][  49/1563]\tLoss   0.07\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [191][  99/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.058\n",
      "Epoch: [191][ 149/1563]\tLoss   0.07\tAcc  97.67\tTime/batch 0.057\n",
      "Epoch: [191][ 199/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.057\n",
      "Epoch: [191][ 249/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [191][ 299/1563]\tLoss   0.08\tAcc  97.27\tTime/batch 0.057\n",
      "Epoch: [191][ 349/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [191][ 399/1563]\tLoss   0.08\tAcc  97.19\tTime/batch 0.057\n",
      "Epoch: [191][ 449/1563]\tLoss   0.08\tAcc  97.24\tTime/batch 0.057\n",
      "Epoch: [191][ 499/1563]\tLoss   0.08\tAcc  97.28\tTime/batch 0.057\n",
      "Epoch: [191][ 549/1563]\tLoss   0.08\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [191][ 599/1563]\tLoss   0.08\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [191][ 649/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [191][ 699/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [191][ 749/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [191][ 799/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [191][ 849/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [191][ 899/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [191][ 949/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [191][ 999/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [191][1049/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [191][1099/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [191][1149/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [191][1199/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [191][1249/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [191][1299/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [191][1349/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [191][1399/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [191][1449/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [191][1499/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [191][1549/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [192][  49/1563]\tLoss   0.08\tAcc  97.25\tTime/batch 0.058\n",
      "Epoch: [192][  99/1563]\tLoss   0.08\tAcc  97.06\tTime/batch 0.057\n",
      "Epoch: [192][ 149/1563]\tLoss   0.07\tAcc  97.08\tTime/batch 0.057\n",
      "Epoch: [192][ 199/1563]\tLoss   0.07\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [192][ 249/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [192][ 299/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [192][ 349/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [192][ 399/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [192][ 449/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [192][ 499/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [192][ 549/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [192][ 599/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [192][ 649/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [192][ 699/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [192][ 749/1563]\tLoss   0.07\tAcc  97.63\tTime/batch 0.057\n",
      "Epoch: [192][ 799/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [192][ 849/1563]\tLoss   0.07\tAcc  97.61\tTime/batch 0.057\n",
      "Epoch: [192][ 899/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [192][ 949/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [192][ 999/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [192][1049/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [192][1099/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [192][1149/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [192][1199/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "Epoch: [192][1249/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [192][1299/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "Epoch: [192][1349/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [192][1399/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [192][1449/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [192][1499/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [192][1549/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [193][  49/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [193][  99/1563]\tLoss   0.07\tAcc  97.72\tTime/batch 0.058\n",
      "Epoch: [193][ 149/1563]\tLoss   0.08\tAcc  97.58\tTime/batch 0.058\n",
      "Epoch: [193][ 199/1563]\tLoss   0.07\tAcc  97.61\tTime/batch 0.058\n",
      "Epoch: [193][ 249/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.058\n",
      "Epoch: [193][ 299/1563]\tLoss   0.08\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [193][ 349/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [193][ 399/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [193][ 449/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [193][ 499/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [193][ 549/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [193][ 599/1563]\tLoss   0.07\tAcc  97.61\tTime/batch 0.057\n",
      "Epoch: [193][ 649/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [193][ 699/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [193][ 749/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [193][ 799/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [193][ 849/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [193][ 899/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [193][ 949/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [193][ 999/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [193][1049/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [193][1099/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [193][1149/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [193][1199/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [193][1249/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [193][1299/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [193][1349/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [193][1399/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [193][1449/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [193][1499/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [193][1549/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [194][  49/1563]\tLoss   0.07\tAcc  97.94\tTime/batch 0.058\n",
      "Epoch: [194][  99/1563]\tLoss   0.08\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [194][ 149/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [194][ 199/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [194][ 249/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [194][ 299/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [194][ 349/1563]\tLoss   0.07\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [194][ 399/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [194][ 449/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [194][ 499/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [194][ 549/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [194][ 599/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [194][ 649/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [194][ 699/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [194][ 749/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [194][ 799/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [194][ 849/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.057\n",
      "Epoch: [194][ 899/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [194][ 949/1563]\tLoss   0.08\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [194][ 999/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [194][1049/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.057\n",
      "Epoch: [194][1099/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [194][1149/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [194][1199/1563]\tLoss   0.08\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [194][1249/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [194][1299/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [194][1349/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [194][1399/1563]\tLoss   0.08\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [194][1449/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [194][1499/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [194][1549/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [195][  49/1563]\tLoss   0.06\tAcc  98.06\tTime/batch 0.058\n",
      "Epoch: [195][  99/1563]\tLoss   0.07\tAcc  97.78\tTime/batch 0.057\n",
      "Epoch: [195][ 149/1563]\tLoss   0.07\tAcc  97.81\tTime/batch 0.057\n",
      "Epoch: [195][ 199/1563]\tLoss   0.07\tAcc  97.84\tTime/batch 0.057\n",
      "Epoch: [195][ 249/1563]\tLoss   0.07\tAcc  97.76\tTime/batch 0.057\n",
      "Epoch: [195][ 299/1563]\tLoss   0.07\tAcc  97.75\tTime/batch 0.057\n",
      "Epoch: [195][ 349/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.057\n",
      "Epoch: [195][ 399/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [195][ 449/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [195][ 499/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [195][ 549/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [195][ 599/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [195][ 649/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [195][ 699/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [195][ 749/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [195][ 799/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [195][ 849/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.058\n",
      "Epoch: [195][ 899/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.058\n",
      "Epoch: [195][ 949/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.058\n",
      "Epoch: [195][ 999/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.058\n",
      "Epoch: [195][1049/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.058\n",
      "Epoch: [195][1099/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.059\n",
      "Epoch: [195][1149/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.059\n",
      "Epoch: [195][1199/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.059\n",
      "Epoch: [195][1249/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.059\n",
      "Epoch: [195][1299/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.059\n",
      "Epoch: [195][1349/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.059\n",
      "Epoch: [195][1399/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.059\n",
      "Epoch: [195][1449/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.059\n",
      "Epoch: [195][1499/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.059\n",
      "Epoch: [195][1549/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.059\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [196][  49/1563]\tLoss   0.06\tAcc  98.06\tTime/batch 0.058\n",
      "Epoch: [196][  99/1563]\tLoss   0.07\tAcc  97.78\tTime/batch 0.058\n",
      "Epoch: [196][ 149/1563]\tLoss   0.07\tAcc  97.71\tTime/batch 0.058\n",
      "Epoch: [196][ 199/1563]\tLoss   0.07\tAcc  97.73\tTime/batch 0.058\n",
      "Epoch: [196][ 249/1563]\tLoss   0.07\tAcc  97.70\tTime/batch 0.058\n",
      "Epoch: [196][ 299/1563]\tLoss   0.07\tAcc  97.72\tTime/batch 0.057\n",
      "Epoch: [196][ 349/1563]\tLoss   0.07\tAcc  97.68\tTime/batch 0.057\n",
      "Epoch: [196][ 399/1563]\tLoss   0.07\tAcc  97.66\tTime/batch 0.057\n",
      "Epoch: [196][ 449/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [196][ 499/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [196][ 549/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [196][ 599/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [196][ 649/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [196][ 699/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [196][ 749/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [196][ 799/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [196][ 849/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.058\n",
      "Epoch: [196][ 899/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.058\n",
      "Epoch: [196][ 949/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.058\n",
      "Epoch: [196][ 999/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.058\n",
      "Epoch: [196][1049/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.058\n",
      "Epoch: [196][1099/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [196][1149/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [196][1199/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [196][1249/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [196][1299/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [196][1349/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [196][1399/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [196][1449/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [196][1499/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [196][1549/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [197][  49/1563]\tLoss   0.08\tAcc  97.00\tTime/batch 0.059\n",
      "Epoch: [197][  99/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.059\n",
      "Epoch: [197][ 149/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [197][ 199/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.059\n",
      "Epoch: [197][ 249/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.058\n",
      "Epoch: [197][ 299/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.058\n",
      "Epoch: [197][ 349/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.058\n",
      "Epoch: [197][ 399/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.058\n",
      "Epoch: [197][ 449/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.058\n",
      "Epoch: [197][ 499/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.058\n",
      "Epoch: [197][ 549/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.058\n",
      "Epoch: [197][ 599/1563]\tLoss   0.08\tAcc  97.33\tTime/batch 0.058\n",
      "Epoch: [197][ 649/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.058\n",
      "Epoch: [197][ 699/1563]\tLoss   0.08\tAcc  97.34\tTime/batch 0.058\n",
      "Epoch: [197][ 749/1563]\tLoss   0.08\tAcc  97.37\tTime/batch 0.058\n",
      "Epoch: [197][ 799/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [197][ 849/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [197][ 899/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [197][ 949/1563]\tLoss   0.08\tAcc  97.32\tTime/batch 0.057\n",
      "Epoch: [197][ 999/1563]\tLoss   0.08\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [197][1049/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [197][1099/1563]\tLoss   0.08\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [197][1149/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [197][1199/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [197][1249/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [197][1299/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [197][1349/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [197][1399/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [197][1449/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [197][1499/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.057\n",
      "Epoch: [197][1549/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [198][  49/1563]\tLoss   0.08\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [198][  99/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [198][ 149/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [198][ 199/1563]\tLoss   0.07\tAcc  97.78\tTime/batch 0.057\n",
      "Epoch: [198][ 249/1563]\tLoss   0.07\tAcc  97.86\tTime/batch 0.057\n",
      "Epoch: [198][ 299/1563]\tLoss   0.07\tAcc  97.77\tTime/batch 0.057\n",
      "Epoch: [198][ 349/1563]\tLoss   0.07\tAcc  97.68\tTime/batch 0.056\n",
      "Epoch: [198][ 399/1563]\tLoss   0.07\tAcc  97.68\tTime/batch 0.056\n",
      "Epoch: [198][ 449/1563]\tLoss   0.07\tAcc  97.68\tTime/batch 0.056\n",
      "Epoch: [198][ 499/1563]\tLoss   0.07\tAcc  97.64\tTime/batch 0.056\n",
      "Epoch: [198][ 549/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.056\n",
      "Epoch: [198][ 599/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.056\n",
      "Epoch: [198][ 649/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [198][ 699/1563]\tLoss   0.07\tAcc  97.59\tTime/batch 0.057\n",
      "Epoch: [198][ 749/1563]\tLoss   0.07\tAcc  97.62\tTime/batch 0.057\n",
      "Epoch: [198][ 799/1563]\tLoss   0.07\tAcc  97.60\tTime/batch 0.057\n",
      "Epoch: [198][ 849/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [198][ 899/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [198][ 949/1563]\tLoss   0.07\tAcc  97.58\tTime/batch 0.057\n",
      "Epoch: [198][ 999/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [198][1049/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [198][1099/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.057\n",
      "Epoch: [198][1149/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [198][1199/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [198][1249/1563]\tLoss   0.07\tAcc  97.57\tTime/batch 0.057\n",
      "Epoch: [198][1299/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [198][1349/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [198][1399/1563]\tLoss   0.07\tAcc  97.55\tTime/batch 0.057\n",
      "Epoch: [198][1449/1563]\tLoss   0.07\tAcc  97.54\tTime/batch 0.057\n",
      "Epoch: [198][1499/1563]\tLoss   0.07\tAcc  97.53\tTime/batch 0.057\n",
      "Epoch: [198][1549/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [199][  49/1563]\tLoss   0.08\tAcc  96.94\tTime/batch 0.058\n",
      "Epoch: [199][  99/1563]\tLoss   0.08\tAcc  96.84\tTime/batch 0.057\n",
      "Epoch: [199][ 149/1563]\tLoss   0.08\tAcc  97.06\tTime/batch 0.057\n",
      "Epoch: [199][ 199/1563]\tLoss   0.08\tAcc  97.30\tTime/batch 0.057\n",
      "Epoch: [199][ 249/1563]\tLoss   0.08\tAcc  97.29\tTime/batch 0.057\n",
      "Epoch: [199][ 299/1563]\tLoss   0.08\tAcc  97.26\tTime/batch 0.057\n",
      "Epoch: [199][ 349/1563]\tLoss   0.08\tAcc  97.31\tTime/batch 0.057\n",
      "Epoch: [199][ 399/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [199][ 449/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [199][ 499/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [199][ 549/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [199][ 599/1563]\tLoss   0.07\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [199][ 649/1563]\tLoss   0.07\tAcc  97.35\tTime/batch 0.057\n",
      "Epoch: [199][ 699/1563]\tLoss   0.07\tAcc  97.37\tTime/batch 0.057\n",
      "Epoch: [199][ 749/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [199][ 799/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [199][ 849/1563]\tLoss   0.07\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [199][ 899/1563]\tLoss   0.07\tAcc  97.36\tTime/batch 0.057\n",
      "Epoch: [199][ 949/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [199][ 999/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [199][1049/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [199][1099/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [199][1149/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.056\n",
      "Epoch: [199][1199/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.056\n",
      "Epoch: [199][1249/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [199][1299/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.056\n",
      "Epoch: [199][1349/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.056\n",
      "Epoch: [199][1399/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.056\n",
      "Epoch: [199][1449/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.056\n",
      "Epoch: [199][1499/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.056\n",
      "Epoch: [199][1549/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.056\n",
      "current learning rate = 0.00025000000000000006\n",
      "Epoch: [200][  49/1563]\tLoss   0.07\tAcc  97.88\tTime/batch 0.058\n",
      "Epoch: [200][  99/1563]\tLoss   0.07\tAcc  97.56\tTime/batch 0.058\n",
      "Epoch: [200][ 149/1563]\tLoss   0.07\tAcc  97.65\tTime/batch 0.057\n",
      "Epoch: [200][ 199/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [200][ 249/1563]\tLoss   0.07\tAcc  97.51\tTime/batch 0.057\n",
      "Epoch: [200][ 299/1563]\tLoss   0.07\tAcc  97.52\tTime/batch 0.057\n",
      "Epoch: [200][ 349/1563]\tLoss   0.07\tAcc  97.46\tTime/batch 0.057\n",
      "Epoch: [200][ 399/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [200][ 449/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [200][ 499/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [200][ 549/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.057\n",
      "Epoch: [200][ 599/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [200][ 649/1563]\tLoss   0.07\tAcc  97.42\tTime/batch 0.057\n",
      "Epoch: [200][ 699/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [200][ 749/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.057\n",
      "Epoch: [200][ 799/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.057\n",
      "Epoch: [200][ 849/1563]\tLoss   0.07\tAcc  97.39\tTime/batch 0.058\n",
      "Epoch: [200][ 899/1563]\tLoss   0.07\tAcc  97.38\tTime/batch 0.058\n",
      "Epoch: [200][ 949/1563]\tLoss   0.07\tAcc  97.40\tTime/batch 0.058\n",
      "Epoch: [200][ 999/1563]\tLoss   0.07\tAcc  97.41\tTime/batch 0.058\n",
      "Epoch: [200][1049/1563]\tLoss   0.07\tAcc  97.43\tTime/batch 0.058\n",
      "Epoch: [200][1099/1563]\tLoss   0.07\tAcc  97.44\tTime/batch 0.058\n",
      "Epoch: [200][1149/1563]\tLoss   0.07\tAcc  97.45\tTime/batch 0.057\n",
      "Epoch: [200][1199/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [200][1249/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [200][1299/1563]\tLoss   0.07\tAcc  97.47\tTime/batch 0.057\n",
      "Epoch: [200][1349/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [200][1399/1563]\tLoss   0.07\tAcc  97.50\tTime/batch 0.057\n",
      "Epoch: [200][1449/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [200][1499/1563]\tLoss   0.07\tAcc  97.49\tTime/batch 0.057\n",
      "Epoch: [200][1549/1563]\tLoss   0.07\tAcc  97.48\tTime/batch 0.057\n",
      "epoch 200\n",
      "Accuracy of the network on the 10000 test images: 91.3 %\n",
      "Sparsity of the update phase: 70.1 %\n",
      "Saving the trained model.\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 91.3 %\n",
      "Sparsity of the update phase: 70.1 %\n",
      "Accuracy of plane : 93.0 %\n",
      "Accuracy of   car : 95.0 %\n",
      "Accuracy of  bird : 90.6 %\n",
      "Accuracy of   cat : 85.3 %\n",
      "Accuracy of  deer : 92.1 %\n",
      "Accuracy of   dog : 91.7 %\n",
      "Accuracy of  frog : 92.6 %\n",
      "Accuracy of horse : 93.2 %\n",
      "Accuracy of  ship : 95.0 %\n",
      "Accuracy of truck : 91.9 %\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Available GPUs: {}\".format(torch.cuda.device_count()))\n",
    "\n",
    "print(\"Create {} model.\".format(_ARCH))\n",
    "net = generate_model(_ARCH)\n",
    "# print(net)\n",
    "\n",
    "if path:\n",
    "    print(\"@ Load trained model from {}.\".format(path))\n",
    "    net.load_state_dict(torch.load(path))\n",
    "\n",
    "print(\"Loading the data.\")\n",
    "trainloader, testloader, classes = load_cifar10()\n",
    "if test:\n",
    "    print(\"Mode: Test only.\")\n",
    "    test_accu(testloader, net, device)\n",
    "else:\n",
    "    print(\"Start training.\")\n",
    "    train_model(trainloader, testloader, net, device)\n",
    "    test_accu(testloader, net, device)\n",
    "    per_class_test_accu(testloader, classes, net, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
